{"What is the title of the paper with the id 4090?": {"IJCAI2023>>program>>Main Track>>4097>>authors>>authors_1>>Sidney Tio": 0.18219423294067383, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.18360674381256104, "IJCAI2023>>program>>Journal Track>>J5941>>title>>Ordinal Maximin Share Approximation for Goods (Extended Abstract)": 0.18461096286773682, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.18485206365585327, "IJCAI2023>>program>>Main Track>>4026>>authors>>authors_3>>Timothy Parker": 0.18588590621948242, "IJCAI2023>>program>>Journal Track>>J5933>>title>>Constraint Solving Approaches to the Business-to-Business Meeting Scheduling Problem (Extended Abstract)": 0.18660986423492432, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.18815040588378906, "IJCAI2023>>program>>Main Track>>4015>>authors>>authors_5>>Tuomas Sandholm": 0.19059771299362183, "IJCAI2023>>program>>Main Track>>4401>>authors>>authors_4>>Johannes Oetsch": 0.19076615571975708, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC8>>authors>>authors_5>>Gerard de Melo": 0.19089853763580322, "IJCAI2023>>program>>Journal Track>>J5944>>title>>A False Sense of Security (Extended Abstract)": 0.1913914680480957, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.19147300720214844, "IJCAI2023>>program>>Main Track>>4195>>authors>>authors_4>>Zhankun Xiong": 0.19158244132995605, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC19>>title>>Task Allocation on Networks with Execution Uncertainty": 0.19223010540008545, "IJCAI2023>>program>>Main Track>>4407>>authors>>authors_4>>Xuanhua Shi": 0.19224625825881958, "IJCAI2023>>program>>Main Track>>4118>>authors>>authors_6>>John Thangarajah": 0.19253182411193848, "IJCAI2023>>program>>Main Track>>4078>>authors>>authors_3>>Stefan Szeider": 0.19258415699005127, "IJCAI2023>>program>>Journal Track>>J5940>>authors>>authors_3>>Georgios Paliouras": 0.19296717643737793}, "Who are the authors of the paper titled 'Singularformer: Learning to Decompose Self-Attention to Linearize the Complexity of Transformer'?": {"IJCAI2023>>program>>Main Track>>1593>>authors>>authors_4>>Shu-Tao Xia": 0.19989925622940063, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_4>>Devarajan Sridharan": 0.2010401487350464, "IJCAI2023>>program>>Main Track>>2638>>authors>>authors_4>>Tao Lin": 0.20181655883789062, "IJCAI2023>>program>>Main Track>>1510>>authors>>authors_2>>Junlin Xian": 0.20195680856704712, "IJCAI2023>>program>>Main Track>>1817>>authors>>authors_2>>Sarit Kraus": 0.2023404836654663, "IJCAI2023>>program>>Main Track>>658>>authors>>authors_1>>Supeng Wang": 0.2026636004447937, "IJCAI2023>>program>>Main Track>>1798>>authors>>authors_3>>Qing Lin": 0.20318299531936646, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_2>>Richard Klein": 0.20366650819778442, "IJCAI2023>>program>>Main Track>>1272>>authors>>authors_2>>Tom Schaul": 0.20394206047058105, "IJCAI2023>>program>>Main Track>>924>>authors>>authors_3>>Lin Wang": 0.20402586460113525, "IJCAI2023>>program>>Main Track>>1763>>authors>>authors_1>>Shuolin Li": 0.2043812870979309, "IJCAI2023>>program>>Main Track>>880>>authors>>authors_3>>Cheng-Lin Liu": 0.20451557636260986, "IJCAI2023>>program>>Main Track>>1310>>authors>>authors_1>>Tianlin Li": 0.20465636253356934, "IJCAI2023>>program>>Survey Track>>SV5569>>authors>>authors_6>>Jianxin Li": 0.20513969659805298, "IJCAI2023>>program>>Survey Track>>SV5608>>authors>>authors_1>>Oren Salzman": 0.20537954568862915, "IJCAI2023>>program>>Main Track>>1384>>authors>>authors_3>>Jieru Lin": 0.20562082529067993, "IJCAI2023>>program>>Main Track>>1983>>authors>>authors_8>>Zhe Lin": 0.2056732177734375, "IJCAI2023>>program>>Main Track>>3352>>authors>>authors_5>>Xiaorui Lin": 0.2056870460510254, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_6>>Mingxuan Wang": 0.20572060346603394, "IJCAI2023>>program>>Main Track>>71>>authors>>authors_4>>Linrui Gong": 0.2057972550392151}, "What is the main aim of the proposed Transformer variant named Singularformer?": {"IJCAI2023>>program>>Main Track>>4090>>abstract>>Transformers achieve excellent performance in a variety of domains since they can capture long-distance dependencies through the self-attention mechanism. However, self-attention is computationally costly due to its quadratic complexity and high memory consumption. In this paper, we propose a novel Transformer variant (Singularformer) that uses neural networks to learn the singular value decomposition process of the attention matrix to design a linear-complexity and memory-efficient global self-attention mechanism. Specifically, we decompose the attention matrix into the product of three matrix factors based on singular value decomposition and design neural networks to learn these matrix factors, then the associative law of matrix multiplication is used to linearize the calculation of self-attention. The above procedure allows us to compute self-attention as two-dimensional reduction processes in the first and second token dimensional spaces, followed by a multi-head self-attention computational process on the first dimensional reduced token features. Experimental results on 8 real-world datasets demonstrate that Singularformer performs favorably against the other Transformer variants with lower time and space complexity. Our source code is publicly available at https://github.com/CSUBioGroup/Singularformer.": 0.13499081134796143, "IJCAI2023>>program>>Main Track>>4090>>title>>Singularformer: Learning to Decompose Self-Attention to Linearize the Complexity of Transformer": 0.16673898696899414}, "What are the advantages of the proposed Transformer variant according to experimental results?": {"IJCAI2023>>program>>Survey Track>>SV5460>>abstract>>Recent advances in Transformers have come with a huge requirement on computing resources, highlighting the importance of developing efficient training techniques to make Transformer training faster, at lower cost, and to higher accuracy by the efficient use of computation and memory resources. This survey provides the first systematic overview of the efficient training of Transformers, covering the recent progress in acceleration arithmetic and hardware, with a focus on the former. We analyze and compare methods that save computation and memory costs for intermediate tensors during training, together with techniques on hardware/algorithm co-design. We finally discuss challenges and promising areas for future research.": 0.16826266050338745, "IJCAI2023>>program>>Main Track>>2490>>abstract>>Transformers achieve promising performance in document understanding because of their high effectiveness and still suffer from quadratic computational complexity dependency on the sequence length. General efficient transformers are challenging to be directly adapted to model document. They are unable to handle the layout representation in documents, e.g. word, line and paragraph, on different granularity levels and seem hard to achieve a good trade-off between efficiency and performance. To tackle the concerns, we propose Fast-StrucTexT, an efficient multi-modal framework based on the StrucTexT algorithm with an hourglass transformer architecture, for visual document understanding. Specifically, we design a modality-guided dynamic token merging block to make the model learn multi-granularity representation and prunes redundant tokens. Additionally, we present a multi-modal interaction module called Symmetry Cross-Attention (SCA) to consider multi-modal fusion and efficiently guide the token mergence. The SCA allows one modality input as query to calculate cross attention with another modality in a dual phase. Extensive experiments on FUNSD, SROIE, and CORD datasets demonstrate that our model achieves the state-of-the-art performance and almost 1.9x faster inference time than the state-of-the-art methods.": 0.1685277223587036}, "In which category does the Singularformer paper fall under?": {"IJCAI2023>>program>>Main Track>>4090>>abstract>>Transformers achieve excellent performance in a variety of domains since they can capture long-distance dependencies through the self-attention mechanism. However, self-attention is computationally costly due to its quadratic complexity and high memory consumption. In this paper, we propose a novel Transformer variant (Singularformer) that uses neural networks to learn the singular value decomposition process of the attention matrix to design a linear-complexity and memory-efficient global self-attention mechanism. Specifically, we decompose the attention matrix into the product of three matrix factors based on singular value decomposition and design neural networks to learn these matrix factors, then the associative law of matrix multiplication is used to linearize the calculation of self-attention. The above procedure allows us to compute self-attention as two-dimensional reduction processes in the first and second token dimensional spaces, followed by a multi-head self-attention computational process on the first dimensional reduced token features. Experimental results on 8 real-world datasets demonstrate that Singularformer performs favorably against the other Transformer variants with lower time and space complexity. Our source code is publicly available at https://github.com/CSUBioGroup/Singularformer.": 0.17503362894058228, "IJCAI2023>>program>>Main Track>>4090>>title>>Singularformer: Learning to Decompose Self-Attention to Linearize the Complexity of Transformer": 0.18582582473754883, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC9>>title>>A Non-Factoid Question-Answering Taxonomy": 0.191362202167511, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC9>>authors>>authors_3>>Falk Scholer": 0.192391037940979, "IJCAI2023>>program>>Survey Track>>SV5579>>title>>Transformers in Time Series: A Survey": 0.19296342134475708}, "What is the title of the paper presented in the Main Track 2045 of IJCAI2023 program?": {"IJCAI2023>>program>>Main Track>>2045>>authors>>authors_1>>Jiahao Liu": 0.09800130128860474, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.1010705828666687, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.10284149646759033, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.10335969924926758, "IJCAI2023>>program>>Main Track>>5155>>authors>>authors_4>>Jing Jiang": 0.10339361429214478, "IJCAI2023>>program>>Main Track>>4025>>authors>>authors_6>>Yinghui Xing": 0.10423672199249268, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_2>>Jiang Wu": 0.10475432872772217, "IJCAI2023>>program>>Main Track>>3655>>authors>>authors_1>>Jiaming Liu": 0.10484164953231812, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_4>>Jing Xiao": 0.1049606204032898, "IJCAI2023>>program>>Main Track>>2120>>authors>>authors_5>>Jian Xu": 0.10521656274795532, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_5>>Yipeng Zhou": 0.10559660196304321, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.10603046417236328, "IJCAI2023>>program>>Main Track>>3654>>authors>>authors_4>>Jiaying Liu": 0.1060914397239685, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Professional title>>Program Chair": 0.10611593723297119, "IJCAI2023>>program>>Main Track>>1065>>authors>>authors_1>>Hua Jiang": 0.10615402460098267, "IJCAI2023>>program>>Main Track>>4195>>authors>>authors_3>>Xuan Liu": 0.10622382164001465, "IJCAI2023>>program>>Main Track>>3525>>authors>>authors_3>>Jiacheng Li": 0.10631567239761353, "IJCAI2023>>program>>Main Track>>4025>>authors>>authors_1>>Xiuwei Zhang": 0.10640019178390503, "IJCAI2023>>program>>Main Track>>2099>>authors>>authors_5>>Jiqiang Liu": 0.10680955648422241, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.10693824291229248}, "Who are the authors of the paper presented in the Main Track 2045?": {"IJCAI2023>>program>>Main Track>>2045>>authors>>authors_1>>Jiahao Liu": 0.13867294788360596, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_5>>Yipeng Zhou": 0.13946032524108887, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_2>>Jiang Wu": 0.14029240608215332, "IJCAI2023>>program>>Main Track>>204>>authors>>authors_2>>Takayuki Osogami": 0.14061832427978516, "IJCAI2023>>program>>Main Track>>534>>authors>>authors_2>>Ferdinando Fioretto": 0.14110857248306274, "IJCAI2023>>program>>Main Track>>1045>>authors>>authors_1>>Takayuki Osogami": 0.14156591892242432, "IJCAI2023>>program>>Main Track>>2038>>authors>>authors_5>>Xi Wu": 0.1429821252822876, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_4>>Miao Hu": 0.14425897598266602, "IJCAI2023>>program>>Main Track>>3095>>authors>>authors_4>>Stefan Szeider": 0.14459317922592163, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.14461225271224976, "IJCAI2023>>program>>Main Track>>193>>authors>>authors_3>>Ferdinando Fioretto": 0.1453438401222229, "IJCAI2023>>program>>Main Track>>2459>>authors>>authors_3>>Thomas Schiex": 0.14567720890045166, "IJCAI2023>>program>>Main Track>>1378>>authors>>authors_3>>Ferdinando Fioretto": 0.145721435546875, "IJCAI2023>>program>>Main Track>>1379>>authors>>authors_3>>Ferdinando Fioretto": 0.14604121446609497, "IJCAI2023>>program>>Main Track>>3140>>authors>>authors_3>>Matthew E. Taylor": 0.14652961492538452, "IJCAI2023>>program>>Main Track>>3655>>authors>>authors_2>>Yangqiming Wang": 0.14659512042999268, "IJCAI2023>>program>>Main Track>>2120>>authors>>authors_5>>Jian Xu": 0.14660859107971191, "IJCAI2023>>program>>Main Track>>1685>>authors>>authors_2>>Qiwei Tian": 0.14669901132583618, "IJCAI2023>>program>>Main Track>>3655>>authors>>authors_1>>Jiaming Liu": 0.14694291353225708, "IJCAI2023>>program>>Main Track>>4350>>authors>>authors_2>>Francesco Foscarin": 0.1470961570739746}, "What is the main problem that the paper 'FedDWA: Personalized Federated Learning with Dynamic Weight Adjustment' addresses?": {"IJCAI2023>>program>>Main Track>>2045>>title>>FedDWA: Personalized Federated Learning with Dynamic Weight Adjustment": 0.10552960634231567, "IJCAI2023>>program>>Main Track>>2045>>abstract>>Different from conventional federated learning, personalized federated learning (PFL) is able to train a customized model for each individual client according to its unique requirement. The mainstream approach is to adopt a kind of weighted aggregation method to generate personalized models, in which weights are determined by the loss value or model parameters among different clients. However, such kinds of methods require clients to download others’ models. It not only sheer increases communication traffic but also potentially infringes data privacy. In this paper, we propose a new PFL algorithm called FedDWA (Federated Learning with Dynamic Weight Adjustment) to address the above problem, which leverages the parameter server (PS) to compute personalized aggregation weights based on collected models from clients. In this way, FedDWA can capture similarities between clients with much less communication overhead. More specifically, we formulate the PFL problem as an optimization problem by minimizing the distance between personalized models and  guidance models, so as to  customize aggregation weights for each client. Guidance models are obtained by  the local one-step ahead adaptation on individual clients. Finally,  we conduct extensive experiments using five real datasets and the results demonstrate that FedDWA can significantly reduce the communication traffic and achieve much higher model accuracy than the state-of-the-art approaches.": 0.11261999607086182}, "What is the proposed solution in the paper to reduce communication traffic in personalized federated learning?": {"IJCAI2023>>program>>Main Track>>3414>>abstract>>Federated recommendation is a new Internet service architecture that aims to provide privacy-preserving recommendation services in federated settings. Existing solutions are used to combine distributed recommendation algorithms and privacy-preserving mechanisms. Thus it inherently takes the form of heavyweight models at the server and hinders the deployment of on-device intelligent models to end-users. This paper proposes a novel Personalized Federated Recommendation (PFedRec) framework to learn many user-specific lightweight models to be deployed on smart devices rather than a heavyweight model on a server. Moreover, we propose a new dual personalization mechanism to effectively learn fine-grained personalization on both users and items. The overall learning process is formulated into a unified federated optimization framework. Specifically, unlike previous methods that share exactly the same item embeddings across users in a federated system, dual personalization allows mild finetuning of item embeddings for each user to generate user-specific views for item representations which can be integrated into existing federated recommendation methods to gain improvements immediately. Experiments on multiple benchmark datasets have demonstrated the effectiveness of PFedRec and the dual personalization mechanism. Moreover, we provide visualizations and in-depth analysis of the personalization techniques in item embedding, which shed novel insights on the design of recommender systems in federated settings. The code is available.": 0.15227633714675903}, "What is the primary keyword associated with the paper presented in the Main Track 2045?": {"IJCAI2023>>program>>Main Track>>2045>>keywords>>keywords_1>>Machine Learning -> ML: Federated learning": 0.1461150050163269, "IJCAI2023>>program>>Main Track>>4025>>keywords>>keywords_1>>Machine Learning -> ML: Classification": 0.14711827039718628, "IJCAI2023>>program>>Main Track>>704>>keywords>>keywords_3>>Machine Learning -> ML: Optimization": 0.147844135761261, "IJCAI2023>>program>>Main Track>>1604>>keywords>>keywords_1>>Machine Learning -> ML: Feature extraction, selection and dimensionality reduction": 0.1480422019958496, "IJCAI2023>>program>>Main Track>>2005>>keywords>>keywords_1>>Machine Learning -> ML: Optimization": 0.14828389883041382, "IJCAI2023>>program>>Main Track>>1028>>keywords>>keywords_1>>Machine Learning -> ML: Optimization": 0.14871537685394287, "IJCAI2023>>program>>Main Track>>2094>>keywords>>keywords_2>>Computer Vision -> CV: Motion and tracking": 0.14890068769454956, "IJCAI2023>>program>>Main Track>>4505>>keywords>>keywords_2>>Machine Learning -> ML: Attention models": 0.14926809072494507, "IJCAI2023>>program>>Main Track>>4152>>keywords>>keywords_2>>Machine Learning -> ML: Optimization": 0.14933240413665771, "IJCAI2023>>program>>Main Track>>460>>keywords>>keywords_1>>Computer Vision -> CV: Motion and tracking": 0.14947229623794556, "IJCAI2023>>program>>Main Track>>5051>>keywords>>keywords_1>>Machine Learning -> ML: Attention models": 0.14994525909423828, "IJCAI2023>>program>>Main Track>>1009>>keywords>>keywords_1>>Machine Learning -> ML: Optimization": 0.15121430158615112, "IJCAI2023>>program>>Main Track>>5225>>keywords>>keywords_2>>Machine Learning -> ML: Attention models": 0.15165114402770996, "IJCAI2023>>program>>Main Track>>1953>>keywords>>keywords_1>>Computer Vision -> CV: Motion and tracking": 0.1516810655593872, "IJCAI2023>>program>>Main Track>>5155>>keywords>>keywords_2>>Machine Learning -> ML: Time series and data streams": 0.1517791748046875, "IJCAI2023>>program>>Main Track>>541>>keywords>>keywords_1>>Machine Learning -> ML: Other": 0.1521567702293396, "IJCAI2023>>program>>Main Track>>345>>keywords>>keywords_2>>Computer Vision -> CV: Motion and tracking": 0.15243107080459595, "IJCAI2023>>program>>Main Track>>3357>>keywords>>keywords_1>>Computer Vision -> CV: Motion and tracking": 0.15247678756713867}, "What is the title of the paper with ID 1588?": {"IJCAI2023>>program>>Journal Track>>J5688>>authors>>authors_2>>Martin Schmid": 0.17355388402938843, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.1737857460975647, "IJCAI2023>>program>>Main Track>>658>>authors>>authors_1>>Supeng Wang": 0.1738240122795105, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_2>>Zhijie Wang": 0.17389178276062012, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_6>>Peter Nightingale": 0.17522543668746948, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_2>>Richard Klein": 0.1755937933921814, "IJCAI2023>>program>>Main Track>>1598>>authors>>authors_2>>Victor Lagerkvist": 0.17566096782684326, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_6>>Ji Liu": 0.17594283819198608, "IJCAI2023>>program>>Main Track>>1598>>authors>>authors_1>>Leif Eriksson": 0.17659419775009155, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_7>>Xun Chen": 0.17669272422790527, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.17737025022506714, "IJCAI2023>>program>>Main Track>>1758>>authors>>authors_1>>Teng Huang": 0.17785924673080444, "IJCAI2023>>program>>Survey Track>>SV5487>>authors>>authors_6>>Ruben Mayer": 0.1783813238143921, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_1>>Sriram Ganapathi Subramanian": 0.17854076623916626, "IJCAI2023>>program>>Main Track>>4168>>authors>>authors_4>>Sheng-Jun Huang": 0.17871242761611938, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_3>>Kongqiao Wang": 0.17877280712127686, "IJCAI2023>>program>>Journal Track>>J5942>>authors>>authors_3>>Peter Nightingale": 0.1790788769721985, "IJCAI2023>>program>>Journal Track>>J5942>>authors>>authors_6>>Mateu Villaret": 0.17921441793441772, "IJCAI2023>>program>>Journal Track>>J5933>>authors>>authors_7>>Mateu Villaret": 0.17930662631988525, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.1802273988723755}, "Who are the authors of the paper titled 'Accurate MRI Reconstruction via Multi-Domain Recurrent Networks'?": {"IJCAI2023>>program>>Main Track>>1588>>title>>Accurate MRI Reconstruction via Multi-Domain Recurrent Networks": 0.0903121829032898, "IJCAI2023>>program>>Main Track>>1588>>abstract>>In recent years, deep convolutional neural networks (CNNs) have become dominant in MRI reconstruction from undersampled k-space. However, most existing CNNs methods reconstruct the undersampled images either in the spatial domain or in the frequency domain, and neglecting the correlation between these two domains. This hinders the further reconstruction performance improvement. To tackle this issue, in this work, we propose a new multi-domain recurrent network (MDR-Net) with multi-domain learning (MDL) blocks as its basic units to reconstruct the undersampled MR image progressively. Specifically, the MDL block interactively processes the local spatial features and the global frequency information to facilitate complementary learning, leading to fine-grained features generation. Furthermore, we introduce an effective frequency-based loss to narrow the frequency spectrum gap, compensating for over-smoothness caused by the widely used spatial reconstruction loss. Extensive experiments on public fastMRI datasets demonstrate that our MDR-Net consistently outperforms other competitive methods and is able to provide more details.": 0.15156680345535278, "IJCAI2023>>program>>Main Track>>596>>title>>Deep Unfolding Convolutional Dictionary Model for Multi-Contrast MRI Super-resolution and Reconstruction": 0.16043537855148315, "IJCAI2023>>program>>Main Track>>1798>>title>>Multi-Modality Deep Network for JPEG Artifacts Reduction": 0.1711546778678894, "IJCAI2023>>program>>Main Track>>298>>title>>3D Surface Super-resolution from Enhanced 2D Normal Images: A Multimodal-driven Variational AutoEncoder Approach": 0.17487436532974243, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC21>>title>>Efficient Global Robustness Certification of Neural Networks via Interleaving Twin-Network Encoding": 0.17666864395141602, "IJCAI2023>>program>>Main Track>>1813>>title>>A Dual Semantic-Aware Recurrent Global-Adaptive Network for Vision-and-Language Navigation": 0.1768081784248352, "IJCAI2023>>program>>Main Track>>2789>>title>>One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER": 0.1779261827468872, "IJCAI2023>>program>>Main Track>>902>>title>>Cross-Domain Facial Expression Recognition via Disentangling Identity Representation": 0.17950773239135742}, "What is the key issue addressed by the paper ID 1588 in the field of MRI reconstruction?": {"IJCAI2023>>program>>Main Track>>1588>>title>>Accurate MRI Reconstruction via Multi-Domain Recurrent Networks": 0.14002788066864014, "IJCAI2023>>program>>Main Track>>596>>title>>Deep Unfolding Convolutional Dictionary Model for Multi-Contrast MRI Super-resolution and Reconstruction": 0.16076308488845825, "IJCAI2023>>program>>Main Track>>1588>>abstract>>In recent years, deep convolutional neural networks (CNNs) have become dominant in MRI reconstruction from undersampled k-space. However, most existing CNNs methods reconstruct the undersampled images either in the spatial domain or in the frequency domain, and neglecting the correlation between these two domains. This hinders the further reconstruction performance improvement. To tackle this issue, in this work, we propose a new multi-domain recurrent network (MDR-Net) with multi-domain learning (MDL) blocks as its basic units to reconstruct the undersampled MR image progressively. Specifically, the MDL block interactively processes the local spatial features and the global frequency information to facilitate complementary learning, leading to fine-grained features generation. Furthermore, we introduce an effective frequency-based loss to narrow the frequency spectrum gap, compensating for over-smoothness caused by the widely used spatial reconstruction loss. Extensive experiments on public fastMRI datasets demonstrate that our MDR-Net consistently outperforms other competitive methods and is able to provide more details.": 0.16542255878448486}, "Which technique is proposed by the authors in the paper 'Accurate MRI Reconstruction via Multi-Domain Recurrent Networks' to tackle the identified issue?": {"IJCAI2023>>program>>Main Track>>1588>>title>>Accurate MRI Reconstruction via Multi-Domain Recurrent Networks": 0.0946151614189148, "IJCAI2023>>program>>Main Track>>1588>>abstract>>In recent years, deep convolutional neural networks (CNNs) have become dominant in MRI reconstruction from undersampled k-space. However, most existing CNNs methods reconstruct the undersampled images either in the spatial domain or in the frequency domain, and neglecting the correlation between these two domains. This hinders the further reconstruction performance improvement. To tackle this issue, in this work, we propose a new multi-domain recurrent network (MDR-Net) with multi-domain learning (MDL) blocks as its basic units to reconstruct the undersampled MR image progressively. Specifically, the MDL block interactively processes the local spatial features and the global frequency information to facilitate complementary learning, leading to fine-grained features generation. Furthermore, we introduce an effective frequency-based loss to narrow the frequency spectrum gap, compensating for over-smoothness caused by the widely used spatial reconstruction loss. Extensive experiments on public fastMRI datasets demonstrate that our MDR-Net consistently outperforms other competitive methods and is able to provide more details.": 0.11518043279647827}, "What are the keywords of the paper with ID 1588?": {"IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_1>>Planning": 0.16417306661605835, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_4>>Gradient Descent": 0.16497081518173218, "IJCAI2023>>program>>Main Track>>1698>>keywords>>keywords_1>>Machine Learning -> ML: Classification": 0.16788870096206665, "IJCAI2023>>program>>Main Track>>1758>>keywords>>keywords_1>>Machine Learning -> ML: Classification": 0.1689136028289795, "IJCAI2023>>program>>Journal Track>>J5920>>keywords>>keywords_2>>Data Mining -> General": 0.1690921187400818, "IJCAI2023>>program>>Main Track>>1588>>keywords>>keywords_1>>Computer Vision -> CV: Biomedical image analysis": 0.16950374841690063, "IJCAI2023>>program>>Main Track>>1604>>keywords>>keywords_1>>Machine Learning -> ML: Feature extraction, selection and dimensionality reduction": 0.1695844531059265, "IJCAI2023>>program>>Survey Track>>SV5608>>keywords>>keywords_1>>Survey -> Search": 0.1709078550338745, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_2>>Numeric Planning": 0.17107582092285156, "IJCAI2023>>calls>>Call For Papers>>Call For Papers_9>>Submission Process>>Keywords:>>When submitting abstracts, authors must choose up to three content area keywords (called “subject areas” in CMT). General categories should be used only if specific categories do not apply or do not accurately reflect the main contributions. The full list of keywords will be available on the submission site.": 0.17215663194656372, "IJCAI2023>>calls>>Main Track>>Accepted Papers List>>141>>keywords>>keywords_1>>Data Mining -> DM: Mining graphs": 0.17238247394561768, "IJCAI2023>>program>>Survey Track>>SV5557>>keywords>>keywords_1>>Survey -> Multidisciplinary Topics and Applications": 0.1724368929862976, "IJCAI2023>>program>>Survey Track>>SV5579>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.17269128561019897, "IJCAI2023>>program>>Survey Track>>SV5648>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.172796368598938, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_3>>Mixed Planning": 0.17288482189178467}, "What is the title of the paper with ID 2869 in the main track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.11342549324035645, "IJCAI2023>>program>>Main Track>>2816>>authors>>authors_1>>Jiangjiang Zhao": 0.11357200145721436, "IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.11417454481124878, "IJCAI2023>>program>>Main Track>>3636>>authors>>authors_6>>Hui Xiong": 0.11454927921295166, "IJCAI2023>>program>>Main Track>>2869>>authors>>authors_3>>Haichao Wang": 0.11463189125061035, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_8>>Jian Wu": 0.11490523815155029, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.1149517297744751, "IJCAI2023>>program>>Main Track>>3078>>authors>>authors_1>>Xin Li": 0.11505061388015747, "IJCAI2023>>program>>Main Track>>3364>>authors>>authors_1>>Junqiang Peng": 0.11509972810745239, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.11543983221054077, "IJCAI2023>>program>>Main Track>>1068>>authors>>authors_1>>Hua Jiang": 0.1155240535736084, "IJCAI2023>>program>>Main Track>>656>>authors>>authors_9>>Lijuan Wang": 0.11555415391921997, "IJCAI2023>>program>>Main Track>>2789>>authors>>authors_6>>Yong Jiang": 0.11557567119598389, "IJCAI2023>>program>>Main Track>>2883>>authors>>authors_5>>Jun Zhang": 0.11584210395812988, "IJCAI2023>>program>>Main Track>>863>>authors>>authors_8>>Jie Chen": 0.11585789918899536, "IJCAI2023>>program>>Main Track>>3395>>authors>>authors_1>>Haolong Xiang": 0.11612874269485474, "IJCAI2023>>program>>Main Track>>892>>authors>>authors_8>>Jie Chen": 0.11628282070159912, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_1>>Yiheng Zhu": 0.11629891395568848, "IJCAI2023>>program>>Main Track>>3863>>authors>>authors_7>>Hua Wu": 0.11632418632507324, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_3>>Michael Katz": 0.11639273166656494, "IJCAI2023>>program>>Main Track>>2841>>authors>>authors_3>>Zhizheng Wang": 0.11649614572525024}, "Who are the authors of the paper titled 'Teacher Assistant-Based Knowledge Distillation Extracting Multi-level Features on Single Channel Sleep EEG'?": {"IJCAI2023>>program>>Survey Track>>SV5614>>authors>>authors_2>>Elias B. Khalil": 0.18718820810317993, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.18824255466461182, "IJCAI2023>>program>>Survey Track>>SV5484>>authors>>authors_8>>Dacheng Tao": 0.1896573305130005, "IJCAI2023>>program>>Survey Track>>SV5608>>authors>>authors_5>>Shao-Hung Chan": 0.18997913599014282, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5772>>authors>>authors_4>>Kenny Tsu Wei Choo": 0.1904447078704834, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.19095373153686523, "IJCAI2023>>program>>Survey Track>>SV5648>>authors>>authors_5>>Pradeep K. Murukannaiah": 0.19113940000534058, "IJCAI2023>>program>>Survey Track>>SV5630>>authors>>authors_11>>Nitesh V. Chawla": 0.19137299060821533, "IJCAI2023>>program>>Survey Track>>SV5610>>authors>>authors_1>>Weiye Zhao": 0.19159084558486938, "IJCAI2023>>program>>Main Track>>1137>>authors>>authors_7>>Danny Chen": 0.19172418117523193, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_4>>Chengqi Zhao": 0.1920536756515503, "IJCAI2023>>program>>Survey Track>>SV5587>>authors>>authors_2>>Gabriel G. Castañé": 0.19221079349517822, "IJCAI2023>>program>>Demonstrations Track>>DM5705>>authors>>authors_5>>Kavitha Srinivas": 0.19250768423080444, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_3>>David Martins de Matos": 0.192621111869812, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_7>>Tong Xiao": 0.1926460862159729, "IJCAI2023>>program>>Journal Track>>J5939>>authors>>authors_1>>Elias Schede": 0.19275826215744019, "IJCAI2023>>program>>Survey Track>>SV5630>>authors>>authors_9>>Wei Wang": 0.19282770156860352, "IJCAI2023>>program>>Survey Track>>SV5487>>authors>>authors_5>>Sonja Schimmler": 0.19298219680786133}, "What is the main focus of the study presented in the paper with ID 2869 at IJCAI2023?": {"IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.1376529335975647, "IJCAI2023>>program>>Main Track>>1856>>title>>Towards a Better Understanding of Learning with Multiagent Teams": 0.13865810632705688, "IJCAI2023>>program>>Main Track>>3151>>title>>Learning Dissemination Strategies for External Sources in Opinion Dynamic Models with Cognitive Biases": 0.13900911808013916, "IJCAI2023>>program>>Main Track>>902>>title>>Cross-Domain Facial Expression Recognition via Disentangling Identity Representation": 0.13997888565063477, "IJCAI2023>>program>>Main Track>>1834>>title>>A Unifying Formal Approach to Importance Values in Boolean Functions": 0.1404842734336853, "IJCAI2023>>program>>Main Track>>4961>>title>>Capturing the Long-Distance Dependency in the Control Flow Graph via Structural-Guided Attention for Bug Localization": 0.14083558320999146, "IJCAI2023>>program>>Main Track>>2366>>title>>Enabling Abductive Learning to Exploit Knowledge Graph": 0.14137595891952515, "IJCAI2023>>program>>Main Track>>2459>>title>>Scalable Coupling of Deep Learning with Logical Reasoning": 0.14139342308044434, "IJCAI2023>>program>>Main Track>>4413>>title>>Sequential Attention Source Identification Based on Feature Representation": 0.14271795749664307, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC22>>title>>Algorithm-Hardware Co-Design for Efficient Brain-Inspired Hyperdimensional Learning on Edge": 0.1427430510520935, "IJCAI2023>>program>>Main Track>>1920>>title>>Towards Collaborative Plan Acquisition through Theory of Mind Modeling in Situated Dialogue": 0.14287251234054565, "IJCAI2023>>calls>>Call For Papers: Survey Track>>Call For Papers: Survey Track_4>>What Is a Suitable Topic?>>The IJCAI 2023 Survey Track provides an opportunity for established researchers in the AI community to give a broad talk on a well-established body of research, which provides a big-picture view of the topic rather than discussing a particular aspect. The topic should be of interest to current AI practitioners. Of particular interest are papers that describe how lessons learned from the topic can contribute to new ideas and visions that can stimulate the research community to pursue new directions, e.g., new problems.": 0.14331430196762085}, "What specific problem does SleepKD intend to solve?": {"IJCAI2023>>program>>Main Track>>2869>>abstract>>Sleep stage classification is of great significance to the diagnosis of sleep disorders. However, existing sleep stage classification models based on deep learning are usually relatively large in size (wider and deeper), which makes them hard to be deployed on wearable devices. Therefore, it is a challenge to lighten the existing sleep stage classification models. In this paper, we propose a novel general knowledge distillation framework for sleep stage classification tasks called SleepKD. Our SleepKD, composed of the multi-level module, teacher assistant module, and other knowledge distillation modules, aims to lighten large-scale sleep stage classification models. Specifically, the multi-level module is able to transfer the multi-level knowledge extracted from sleep signals by the teacher model (large-scale model) to the student model (lightweight model). Moreover, the teacher assistant module bridges the large gap between the teacher and student network, and further improves the distillation. We evaluate our method on two public sleep datasets (Sleep-EDF and ISRUC-III). Compared to the baseline methods, the results show that our knowledge distillation framework achieves state-of-the-art performance. SleepKD can significantly lighten the sleep model while maintaining its classification performance. The source code is available at https://github.com/HychaoWang/SleepKD.": 0.16059362888336182, "IJCAI2023>>program>>Main Track>>3139>>abstract>>We study single-player extensive-form games with imperfect recall, such as the Sleeping Beauty problem or the Absentminded Driver game. For such games, two natural equilibrium concepts have been proposed as alternative solution concepts to ex-ante optimality. One equilibrium concept uses generalized double halving (GDH) as a belief system and evidential decision theory (EDT), and another one uses generalized thirding (GT) as a belief system and causal decision theory (CDT). Our findings relate those three solution concepts of a game to solution concepts of a polynomial maximization problem: global optima, optimal points with respect to subsets of variables and Karush–Kuhn–Tucker (KKT) points. Based on these correspondences, we are able to settle various complexity-theoretic questions on the computation of such strategies. For ex-ante optimality and (EDT,GDH)-equilibria, we obtain NP-hardness and inapproximability, and for (CDT,GT)-equilibria we obtain CLS-completeness results.": 0.19704824686050415}, "In what areas is the study presented in the paper with ID 2869 at IJCAI2023 relevant?": {"IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.13409489393234253, "IJCAI2023>>calls>>Call For Papers>>Call For Papers_3>>Submissions to IJCAI 2023 should report significant, original, and previously unpublished results on any aspect of artificial intelligence. Papers on novel AI research problems, AI techniques for novel application domains, and papers that cross discipline boundaries within AI are especially encouraged.": 0.14474517107009888, "IJCAI2023>>calls>>Call For Papers: Survey Track>>Call For Papers: Survey Track_4>>What Is a Suitable Topic?>>The IJCAI 2023 Survey Track provides an opportunity for established researchers in the AI community to give a broad talk on a well-established body of research, which provides a big-picture view of the topic rather than discussing a particular aspect. The topic should be of interest to current AI practitioners. Of particular interest are papers that describe how lessons learned from the topic can contribute to new ideas and visions that can stimulate the research community to pursue new directions, e.g., new problems.": 0.14602410793304443, "IJCAI2023>>program>>Survey Track>>SV5579>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.14623260498046875, "IJCAI2023>>program>>Survey Track>>SV5639>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.14628589153289795, "IJCAI2023>>program>>Survey Track>>SV5592>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.14636343717575073, "IJCAI2023>>program>>Survey Track>>SV5648>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.14659738540649414, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC4>>title>>On the Versatile Uses of Partial Distance Correlation in Deep Learning": 0.14705806970596313, "IJCAI2023>>program>>Main Track>>2869>>keywords>>keywords_2>>Humans and AI -> HAI: Brain sciences": 0.14820057153701782, "IJCAI2023>>program>>Survey Track>>SV5557>>keywords>>keywords_1>>Survey -> Multidisciplinary Topics and Applications": 0.14882832765579224, "IJCAI2023>>program>>Survey Track>>SV5653>>keywords>>keywords_1>>Survey -> Multidisciplinary Topics and Applications": 0.14897137880325317, "IJCAI2023>>program>>Survey Track>>SV5526>>keywords>>keywords_2>>Survey -> Multidisciplinary Topics and Applications": 0.14909964799880981}, "What is the title of the program 1145 in the Main Track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>5155>>authors>>authors_4>>Jing Jiang": 0.09880679845809937, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Professional title>>Program Chair": 0.10066467523574829, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10219311714172363, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10223895311355591, "IJCAI2023>>program>>Main Track>>3654>>authors>>authors_4>>Jiaying Liu": 0.10239154100418091, "IJCAI2023>>program>>Main Track>>1065>>authors>>authors_1>>Hua Jiang": 0.10390490293502808, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.10522210597991943, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.10535001754760742, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_4>>Jing Xiao": 0.10608339309692383, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_1>>Jiahao Liu": 0.10695230960845947, "IJCAI2023>>program>>Main Track>>1412>>authors>>authors_5>>Jian Li": 0.1070868968963623, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_3>>Jianzong Wang": 0.10742568969726562, "IJCAI2023>>program>>Main Track>>3655>>authors>>authors_1>>Jiaming Liu": 0.10752624273300171, "IJCAI2023>>program>>Main Track>>3654>>authors>>authors_1>>Minghao Liu": 0.10897517204284668, "IJCAI2023>>program>>Main Track>>4215>>authors>>authors_3>>Chang Jiang": 0.10954511165618896, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.10956186056137085, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_1>>Chenghao Liu": 0.10956573486328125, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.11003488302230835, "IJCAI2023>>program>>Main Track>>3525>>authors>>authors_3>>Jiacheng Li": 0.11005717515945435, "IJCAI2023>>program>>Main Track>>3037>>authors>>authors_4>>Jianqiang Li": 0.11020088195800781}, "Who are the authors of the program 1145 in IJCAI2023?": {"IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.10128557682037354, "IJCAI2023>>program>>Main Track>>1065>>authors>>authors_1>>Hua Jiang": 0.10467648506164551, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10488265752792358, "IJCAI2023>>program>>Main Track>>1957>>authors>>authors_2>>David S. Aleixo": 0.10621672868728638, "IJCAI2023>>program>>Main Track>>2577>>authors>>authors_4>>Shajith Ikbal": 0.10639536380767822, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_4>>Mohammad Sharifi": 0.10651302337646484, "IJCAI2023>>program>>Main Track>>3654>>authors>>authors_1>>Minghao Liu": 0.10701882839202881, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_1>>Jiahao Liu": 0.10747623443603516, "IJCAI2023>>program>>Main Track>>2144>>authors>>authors_1>>Hao-Tian Li": 0.1074976921081543, "IJCAI2023>>program>>Main Track>>3832>>authors>>authors_4>>Ian Miguel": 0.10762333869934082, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_3>>Jianzong Wang": 0.1076546311378479, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.10767745971679688, "IJCAI2023>>program>>Main Track>>1412>>authors>>authors_5>>Jian Li": 0.10771608352661133, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_1>>Chenghao Liu": 0.10795211791992188, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_4>>Hao Wang": 0.1081153154373169, "IJCAI2023>>program>>Main Track>>4929>>authors>>authors_2>>Lianghao Xia": 0.1082230806350708, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.1082410216331482, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10835385322570801, "IJCAI2023>>program>>Main Track>>555>>authors>>authors_3>>Chun-Wei Chiang": 0.10868412256240845, "IJCAI2023>>program>>Main Track>>3655>>authors>>authors_1>>Jiaming Liu": 0.10889452695846558}, "What is the main focus of the paper presented in program 1145 at IJCAI 2023?": {"IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Professional title>>Program Chair": 0.11959224939346313, "IJCAI2023>>program>>Main Track>>2459>>title>>Scalable Coupling of Deep Learning with Logical Reasoning": 0.12155210971832275, "IJCAI2023>>program>>Main Track>>1834>>title>>A Unifying Formal Approach to Importance Values in Boolean Functions": 0.12237393856048584, "IJCAI2023>>program>>Main Track>>1920>>title>>Towards Collaborative Plan Acquisition through Theory of Mind Modeling in Situated Dialogue": 0.12391865253448486, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.12421298027038574, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC3>>keywords>>keywords_3>>Sister Conferences Best Papers -> Humans and AI": 0.124245285987854, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.12468135356903076, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.12508124113082886, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_1>>Jiahao Liu": 0.12515419721603394, "IJCAI2023>>calls>>Call For Papers: Survey Track>>Call For Papers: Survey Track_4>>What Is a Suitable Topic?>>The IJCAI 2023 Survey Track provides an opportunity for established researchers in the AI community to give a broad talk on a well-established body of research, which provides a big-picture view of the topic rather than discussing a particular aspect. The topic should be of interest to current AI practitioners. Of particular interest are papers that describe how lessons learned from the topic can contribute to new ideas and visions that can stimulate the research community to pursue new directions, e.g., new problems.": 0.12538659572601318, "IJCAI2023>>program>>Main Track>>4580>>authors>>authors_3>>Jorge A. Baier": 0.1254338026046753, "IJCAI2023>>program>>Main Track>>1875>>title>>Advancing Post-Hoc Case-Based Explanation with Feature Highlighting": 0.1256880760192871, "IJCAI2023>>program>>Workshops and Symposia>>Workshops>>W51>>Website>>https://ai4ts.github.io/ijcai2023": 0.126228928565979, "IJCAI2023>>program>>Main Track>>1134>>authors>>authors_1>>Jiayun Zhang": 0.12636876106262207}, "What new approach does the paper in program 1145 introduce in the field of natural language processing?": {"IJCAI2023>>program>>Main Track>>1145>>keywords>>keywords_2>>Natural Language Processing -> NLP: Language models": 0.12280136346817017, "IJCAI2023>>program>>Main Track>>1145>>keywords>>keywords_1>>Natural Language Processing -> NLP: Question answering": 0.12336510419845581, "IJCAI2023>>program>>Survey Track>>SV5557>>keywords>>keywords_4>>Survey -> Natural Language Processing": 0.1261582374572754, "IJCAI2023>>program>>Survey Track>>SV5647>>keywords>>keywords_4>>Survey -> Natural Language Processing": 0.12657958269119263, "IJCAI2023>>program>>Survey Track>>SV5639>>keywords>>keywords_4>>Survey -> Natural Language Processing": 0.12764203548431396, "IJCAI2023>>program>>Survey Track>>SV5654>>keywords>>keywords_1>>Survey -> Natural Language Processing": 0.12857329845428467, "IJCAI2023>>program>>Main Track>>4148>>keywords>>keywords_1>>Natural Language Processing -> NLP: Applications": 0.12940222024917603, "IJCAI2023>>program>>Survey Track>>SV5649>>keywords>>keywords_1>>Survey -> Natural Language Processing": 0.12949681282043457, "IJCAI2023>>program>>Survey Track>>SV5615>>keywords>>keywords_2>>Survey -> Natural Language Processing": 0.13000988960266113, "IJCAI2023>>program>>Survey Track>>SV5644>>keywords>>keywords_1>>Survey -> Natural Language Processing": 0.13003522157669067, "IJCAI2023>>program>>Main Track>>4765>>keywords>>keywords_1>>Natural Language Processing -> NLP: Question answering": 0.13022124767303467, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.13050353527069092, "IJCAI2023>>program>>Main Track>>1145>>title>>COOL, a Context Outlooker, and Its Application to Question Answering and Other Natural Language Processing Tasks": 0.1306159496307373, "IJCAI2023>>program>>Main Track>>2705>>keywords>>keywords_3>>Natural Language Processing -> NLP: Question answering": 0.13110852241516113, "IJCAI2023>>program>>Main Track>>3525>>keywords>>keywords_1>>Natural Language Processing -> NLP: Language models": 0.13152754306793213, "IJCAI2023>>program>>Main Track>>1250>>keywords>>keywords_2>>Natural Language Processing -> NLP: Speech": 0.1315457820892334, "IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_2>>Natural Language Processing -> NLP: Applications": 0.13161063194274902}, "What are the keywords associated with the paper presented in program 1145 at IJCAI 2023?": {"IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC3>>keywords>>keywords_3>>Sister Conferences Best Papers -> Humans and AI": 0.09786355495452881, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC25>>keywords>>keywords_1>>Sister Conferences Best Papers -> Machine Learning": 0.10260909795761108, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC12>>keywords>>keywords_4>>Sister Conferences Best Papers -> Search": 0.10365402698516846, "IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.10440599918365479, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>keywords>>keywords_2>>General -> General": 0.10583698749542236, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC12>>keywords>>keywords_2>>Sister Conferences Best Papers -> Knowledge Representation and Reasoning": 0.10603600740432739, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC10>>keywords>>keywords_1>>Sister Conferences Best Papers -> Knowledge Representation and Reasoning": 0.10611999034881592, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5756>>keywords>>keywords_1>>General -> General": 0.10702550411224365, "IJCAI2023>>program>>Main Track>>3955>>keywords>>keywords_3>>Search -> S: Search and machine learning": 0.10771739482879639, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5901>>keywords>>keywords_1>>General -> General": 0.10780709981918335, "IJCAI2023>>program>>Survey Track>>SV5587>>keywords>>keywords_3>>Survey -> Humans and AI": 0.10856401920318604, "IJCAI2023>>program>>Journal Track>>J5940>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> General": 0.10863006114959717, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.10910588502883911, "IJCAI2023>>program>>Survey Track>>SV5648>>keywords>>keywords_4>>Survey -> Humans and AI": 0.10910648107528687, "IJCAI2023>>program>>Main Track>>1813>>keywords>>keywords_3>>Computer Vision -> CV: Structural and model-based approaches, knowledge representation and reasoning": 0.10918688774108887, "IJCAI2023>>program>>Survey Track>>SV5473>>keywords>>keywords_3>>Survey -> Humans and AI": 0.10920155048370361}, "What is the title of the paper with code 460 in the IJCAI 2023 Main Track?": {"IJCAI2023>>program>>Main Track>>460>>authors>>authors_5>>Ji Zhang": 0.10204827785491943, "IJCAI2023>>program>>Main Track>>460>>authors>>authors_1>>Xiangze Jia": 0.10513859987258911, "IJCAI2023>>program>>Main Track>>460>>authors>>authors_2>>Hui Zhou": 0.10599052906036377, "IJCAI2023>>program>>Main Track>>4650>>authors>>authors_5>>William Yang Wang": 0.10975921154022217, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.1099366545677185, "IJCAI2023>>program>>Main Track>>4601>>authors>>authors_1>>Simon Wietheger": 0.11117470264434814, "IJCAI2023>>program>>Main Track>>4653>>authors>>authors_1>>Xi Yang": 0.11210942268371582, "IJCAI2023>>program>>Main Track>>460>>authors>>authors_3>>Xinge Zhu": 0.11250317096710205, "IJCAI2023>>program>>Main Track>>4372>>authors>>authors_7>>Jun Zhou": 0.11267632246017456, "IJCAI2023>>program>>Main Track>>5155>>authors>>authors_4>>Jing Jiang": 0.11288070678710938, "IJCAI2023>>program>>Main Track>>4526>>authors>>authors_1>>Joshua Kavner": 0.11314690113067627, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.11397284269332886, "IJCAI2023>>program>>Main Track>>1065>>authors>>authors_1>>Hua Jiang": 0.11408442258834839, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.1141057014465332, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.1142416000366211, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.11427175998687744, "IJCAI2023>>program>>Main Track>>4586>>authors>>authors_3>>Xinjian Li": 0.11442887783050537, "IJCAI2023>>program>>Main Track>>449>>authors>>authors_3>>Junhao Zheng": 0.11452025175094604, "IJCAI2023>>program>>Main Track>>3525>>authors>>authors_3>>Jiacheng Li": 0.11533403396606445, "IJCAI2023>>program>>Main Track>>3655>>authors>>authors_1>>Jiaming Liu": 0.11541175842285156, "IJCAI2023>>program>>Main Track>>3639>>authors>>authors_5>>Jia Wu": 0.11544567346572876}, "Who are the authors of the paper titled 'ContrastMotion: Self-supervised Scene Motion Learning for Large-Scale LiDAR Point Clouds'?": {"IJCAI2023>>program>>Main Track>>460>>title>>ContrastMotion: Self-supervised Scene Motion Learning for Large-Scale LiDAR Point Clouds": 0.0839691162109375, "IJCAI2023>>program>>Main Track>>460>>abstract>>In this paper, we propose a novel self-supervised motion estimator for LiDAR-based autonomous driving via BEV representation. Different from usually adopted self-supervised strategies for data-level structure consistency, we predict scene motion via feature-level consistency between pillars in consecutive frames, which can eliminate the effect caused by noise points and view-changing point clouds in dynamic scenes. Specifically, we propose Soft Discriminative Loss that provides the network with more pseudo-supervised signals to learn discriminative and robust features in a contrastive learning manner. We also propose Gated Multi-Frame Fusion block that learns valid compensation between point cloud frames automatically to enhance feature extraction. Finally, pillar association is proposed to predict pillar correspondence probabilities based on feature distance, and whereby further predicts scene motion. Extensive experiments show the effectiveness and superiority of our ContrastMotion on both scene flow and motion prediction tasks.": 0.14665871858596802, "IJCAI2023>>program>>Main Track>>396>>title>>A Large-Scale Film Style Dataset for Learning Multi-frequency Driven Film Enhancement": 0.17040956020355225, "IJCAI2023>>program>>Main Track>>656>>title>>Learning 3D Photography Videos via Self-supervised Diffusion on Single Images": 0.17054885625839233, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5773>>title>>Confidence-based Self-Corrective Learning: An Application in Height Estimation Using Satellite LiDAR and Imagery": 0.17080748081207275, "IJCAI2023>>program>>Main Track>>2160>>title>>Manifold-Aware Self-Training for Unsupervised Domain Adaptation on Regressing 6D Object Pose": 0.17137688398361206, "IJCAI2023>>program>>Main Track>>2840>>title>>Part Aware Contrastive Learning for Self-Supervised Action Recognition": 0.1742371916770935, "IJCAI2023>>program>>Main Track>>1762>>title>>Joint-MAE: 2D-3D Joint Masked Autoencoders for 3D Point Cloud Pre-training": 0.17759615182876587, "IJCAI2023>>program>>Main Track>>169>>title>>MM-PCQA: Multi-Modal Learning for No-reference Point Cloud Quality Assessment": 0.17815446853637695, "IJCAI2023>>program>>Main Track>>1593>>title>>Towards Robust Scene Text Image Super-resolution via Explicit Location Enhancement": 0.17890530824661255}, "What are the keywords of paper 460?": {"IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_1>>Planning": 0.17483419179916382, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.17778480052947998, "IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.18040049076080322, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_2>>Numeric Planning": 0.181749165058136, "IJCAI2023>>program>>Main Track>>4586>>keywords>>keywords_1>>Natural Language Processing -> NLP: Speech": 0.1843155026435852, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_3>>Mixed Planning": 0.18464064598083496, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_4>>Gradient Descent": 0.18523913621902466, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC12>>keywords>>keywords_4>>Sister Conferences Best Papers -> Search": 0.18568074703216553, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5756>>keywords>>keywords_1>>General -> General": 0.18618804216384888, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>keywords>>keywords_2>>General -> General": 0.1875818371772766, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5901>>keywords>>keywords_1>>General -> General": 0.18793272972106934, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC12>>keywords>>keywords_1>>Sister Conferences Best Papers -> Constraint Satisfaction and Optimization": 0.18805301189422607, "IJCAI2023>>program>>Main Track>>460>>keywords>>keywords_2>>Computer Vision -> CV: 3D computer vision": 0.1883608102798462, "IJCAI2023>>program>>Main Track>>4407>>keywords>>keywords_3>>Machine Learning -> ML: Kernel methods": 0.1885644793510437, "IJCAI2023>>program>>Journal Track>>J5927>>keywords>>keywords_2>>Machine Learning -> ML: Robustness": 0.18873077630996704, "IJCAI2023>>program>>Journal Track>>J5933>>keywords>>keywords_2>>Constraint Satisfaction and Optimization -> CSO: Constraint programming": 0.18876999616622925, "IJCAI2023>>program>>Main Track>>4306>>keywords>>keywords_1>>Constraint Satisfaction and Optimization -> CSO: Constraint optimization": 0.18878376483917236}, "Can you provide a brief about the paper 'ContrastMotion: Self-supervised Scene Motion Learning for Large-Scale LiDAR Point Clouds'?": {"IJCAI2023>>program>>Main Track>>460>>title>>ContrastMotion: Self-supervised Scene Motion Learning for Large-Scale LiDAR Point Clouds": 0.07699042558670044, "IJCAI2023>>program>>Main Track>>460>>abstract>>In this paper, we propose a novel self-supervised motion estimator for LiDAR-based autonomous driving via BEV representation. Different from usually adopted self-supervised strategies for data-level structure consistency, we predict scene motion via feature-level consistency between pillars in consecutive frames, which can eliminate the effect caused by noise points and view-changing point clouds in dynamic scenes. Specifically, we propose Soft Discriminative Loss that provides the network with more pseudo-supervised signals to learn discriminative and robust features in a contrastive learning manner. We also propose Gated Multi-Frame Fusion block that learns valid compensation between point cloud frames automatically to enhance feature extraction. Finally, pillar association is proposed to predict pillar correspondence probabilities based on feature distance, and whereby further predicts scene motion. Extensive experiments show the effectiveness and superiority of our ContrastMotion on both scene flow and motion prediction tasks.": 0.12997424602508545, "IJCAI2023>>program>>Main Track>>953>>abstract>>For many driving safety applications, it is of great importance to accurately register LiDAR point clouds generated on distant moving vehicles. However, such point clouds have extremely different point density and sensor perspective on the same object, making registration on such point clouds very hard. In this paper, we propose a novel feature extraction framework, called APR, for online distant point cloud registration. Specifically, APR leverages an autoencoder design, where the autoencoder reconstructs a denser aggregated point cloud with several frames instead of the original single input point cloud. Our design forces the encoder to extract features with rich local geometry information based on one single input point cloud. Such features are then used for online distant point cloud registration. We conduct extensive experiments against state-of-the-art (SOTA) feature extractors on KITTI and nuScenes datasets. Results show that APR outperforms all other extractors by a large margin, increasing average registration recall of SOTA extractors by 7.1% on LoKITTI and 4.6% on LoNuScenes. Code is available at https://github.com/liuQuan98/APR.": 0.1708056926727295}, "In the proposed method of the paper 'ContrastMotion: Self-supervised Scene Motion Learning for Large-Scale LiDAR Point Clouds', what are the strategies used to learn valid compensation between point cloud frames?": {"IJCAI2023>>program>>Main Track>>460>>title>>ContrastMotion: Self-supervised Scene Motion Learning for Large-Scale LiDAR Point Clouds": 0.09856843948364258, "IJCAI2023>>program>>Main Track>>460>>abstract>>In this paper, we propose a novel self-supervised motion estimator for LiDAR-based autonomous driving via BEV representation. Different from usually adopted self-supervised strategies for data-level structure consistency, we predict scene motion via feature-level consistency between pillars in consecutive frames, which can eliminate the effect caused by noise points and view-changing point clouds in dynamic scenes. Specifically, we propose Soft Discriminative Loss that provides the network with more pseudo-supervised signals to learn discriminative and robust features in a contrastive learning manner. We also propose Gated Multi-Frame Fusion block that learns valid compensation between point cloud frames automatically to enhance feature extraction. Finally, pillar association is proposed to predict pillar correspondence probabilities based on feature distance, and whereby further predicts scene motion. Extensive experiments show the effectiveness and superiority of our ContrastMotion on both scene flow and motion prediction tasks.": 0.1056707501411438, "IJCAI2023>>program>>Main Track>>3962>>abstract>>This paper investigates a novel unpaired video dehazing framework, which can be a good candidate in practical scenarios by relieving pressure from collecting paired data. In such a paradigm, two key issues including 1) loose supervision during training and 2) temporal consistency uninvolved in single image dehazing, need to be considered for satisfied performance. To handle the mentioned problems, we alternatively resort to constructing possible supervision across video frames. Specifically,  we attempt to synthesize realistic motions with depth information to make unsupervised recycle and spatial consideration applicable, and thus effectively regularizing the spatiotemporal consistency. Moreover, based on the observation that the visibility of the same object in hazy scene changes with the camera motion, we devise an algorithm to search reference frames with lighter or denser hazes for each frame in training videos. A cross-frame contrastive loss term between the reference frames and current frames is designed to provide extra guidance for further boosting the performance. Extensive experiments are conducted to validate our superiority over other competitors. Code will be made publicly available.": 0.15324550867080688}, "What is the title of the paper with id J5685 in Journal Track?": {"IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.13638979196548462, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_1>>Sriram Ganapathi Subramanian": 0.14462625980377197, "IJCAI2023>>program>>Journal Track>>J5688>>authors>>authors_2>>Martin Schmid": 0.1467875838279724, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_2>>Matthew E. Taylor": 0.14695870876312256, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.14930713176727295, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.14960342645645142, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_1>>Eugénio Ribeiro": 0.15018564462661743, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_1>>Zhiyuan Zeng": 0.1501917839050293, "IJCAI2023>>program>>Journal Track>>J5688>>authors>>authors_4>>Michael Bowling": 0.15022003650665283, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_2>>Deyi Xiong": 0.1519991159439087, "IJCAI2023>>program>>Main Track>>4636>>authors>>authors_9>>James T. Neal": 0.1522585153579712, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.15299773216247559, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.15314334630966187, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_3>>Ian P. Gent": 0.15352147817611694, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_3>>David Martins de Matos": 0.1535801887512207, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.15391939878463745, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_6>>Peter Nightingale": 0.15394282341003418, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_2>>Ricardo Ribeiro": 0.1548377275466919, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_1>>Özgür Akgün": 0.15491163730621338}, "Who is the second author of the paper with id J5685?": {"IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_2>>Matthew E. Taylor": 0.15120041370391846, "IJCAI2023>>program>>Journal Track>>J5688>>authors>>authors_2>>Martin Schmid": 0.154579758644104, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_2>>Ricardo Ribeiro": 0.15634357929229736, "IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.16008460521697998, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.16019123792648315, "IJCAI2023>>program>>Journal Track>>J5930>>authors>>authors_2>>Brian Williams": 0.16064131259918213, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.16170287132263184, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_2>>Deyi Xiong": 0.16234475374221802, "IJCAI2023>>program>>Journal Track>>J5552>>authors>>authors_2>>Nardine Osman": 0.16247522830963135, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_1>>Eugénio Ribeiro": 0.16342103481292725, "IJCAI2023>>program>>Journal Track>>J5927>>authors>>authors_2>>Janardhan Rao Doppa": 0.16352850198745728, "IJCAI2023>>program>>Journal Track>>J5938>>authors>>authors_2>>Emilie Devijver": 0.16379249095916748, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.16396856307983398, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.1647859811782837, "IJCAI2023>>program>>Main Track>>4476>>authors>>authors_2>>Krzysztof Jahn": 0.1651340126991272, "IJCAI2023>>program>>Main Track>>3667>>authors>>authors_2>>Jakob Jørgensen": 0.1651928424835205, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_6>>Peter Nightingale": 0.16582483053207397, "IJCAI2023>>program>>Main Track>>4732>>authors>>authors_2>>Peter Jung": 0.16591668128967285, "IJCAI2023>>program>>Journal Track>>J5942>>authors>>authors_3>>Peter Nightingale": 0.16670644283294678}, "What is the main aim of the paper's proposed method?": {"IJCAI2023>>calls>>Call For Papers: Survey Track>>Call For Papers: Survey Track_5>>How Should the Paper Be Written?>>The survey should have a well-defined scope and be understandable for most of the AI community. It should clarify why the topic is important and its intended or existing applications. The survey should be comprehensive concerning state of the art, with a personal stance on the topic: the description of the existing work should be structured. It should contain a discussion (aiming, for instance, at comparing alternative approaches or identifying open questions and challenges). It should not be a simple juxtaposition of summaries of papers or groups of papers. While the authors’ work can sometimes be an important part of a survey, there should be no significant bias towards it: the work of others should be mentioned and appreciated by its relevance and importance. The paper should be of very high quality in terms of presentation, be at the appropriate technical level, and be grounded in the existing literature.": 0.18183088302612305, "IJCAI2023>>calls>>Call For Competitions And Challenges>>Call For Competitions And Challenges_2>>Proposal Submission>>Proposal Submission_5>>One of the main goals of the competitions/challenges is to enable other researchers, and the society in general, to benefit from the competition/challenge. In particular, we expect the participants to share the source code of their participating systems.": 0.19407975673675537, "IJCAI2023>>calls>>Call For Papers>>Call For Papers_10>>Submission Requirements>>Ethics Statement:>>Authors may include a statement of the potential broader impact of their work, including its ethical aspects and future societal consequences. This part can be put in either the main body of the paper or on the reference pages. It is optional but is highly recommended for papers working with sensitive data or on sensitive tasks.": 0.19779819250106812, "IJCAI2023>>calls>>Call For Demos>>Call For Demos_10>>Selection Process>>Selection Process_1>>Papers will be peer-reviewed by program committee members. Selection criteria include originality, innovation, applicability and potential benefits of the resulting system. Note that there will be no rebuttal phase.": 0.20128995180130005, "IJCAI2023>>program>>Main Track>>71>>title>>Teaching What You Should Teach: A Data-Based Distillation Method": 0.20398086309432983}, "In which area does the paper with id J5685 contribute? Give one of the fields provided": {"IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_1>>Eugénio Ribeiro": 0.1945757269859314, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.19486618041992188, "IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.19764333963394165, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_2>>Ricardo Ribeiro": 0.19897234439849854, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_1>>Sriram Ganapathi Subramanian": 0.2004685401916504, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.20102840662002563, "IJCAI2023>>program>>Journal Track>>J5688>>authors>>authors_2>>Martin Schmid": 0.201959490776062, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.20339709520339966, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.20389515161514282, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_6>>Peter Nightingale": 0.20409619808197021, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_2>>Matthew E. Taylor": 0.2041148543357849, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.20423609018325806, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_3>>David Martins de Matos": 0.20473486185073853, "IJCAI2023>>program>>Journal Track>>J5937>>authors>>authors_3>>Fabiano Dalpiaz": 0.2057451605796814, "IJCAI2023>>program>>Journal Track>>J5650>>authors>>authors_4>>Francesco Braghin": 0.20580726861953735, "IJCAI2023>>program>>Main Track>>4665>>authors>>authors_2>>Stephen Cranefield": 0.2059382200241089, "IJCAI2023>>program>>Journal Track>>J5920>>authors>>authors_1>>Rana Tallal Javed": 0.20607209205627441, "IJCAI2023>>program>>Journal Track>>J5942>>authors>>authors_3>>Peter Nightingale": 0.20632106065750122, "IJCAI2023>>program>>Journal Track>>J5650>>authors>>authors_5>>Dario Piga": 0.20746004581451416}, "The authors of paper J5685 propose a new approach to recognize general-purpose communicative functions. What type of network does this approach use and why?": {"IJCAI2023>>program>>Journal Track>>J5685>>title>>Automatic Recognition of the General-Purpose Communicative Functions Defined by the ISO 24617-2 Standard for Dialog Act Annotation (Extended Abstract)": 0.13391244411468506, "IJCAI2023>>program>>Journal Track>>J5685>>abstract>>From the perspective of a dialog system, the identification of the intention behind the segments in a dialog is important, as it provides cues regarding the information present in the segments and how they should be interpreted. The ISO 24617-2 standard for dialog act annotation defines a hierarchically organized set of general-purpose communicative functions that correspond to different intentions that are relevant in the context of a dialog. In this paper, we explore the automatic recognition of these functions. To do so, we propose to adapt existing approaches to dialog act recognition, so that they can deal with the hierarchical classification problem. More specifically, we propose the use of an end-to-end hierarchical network with cascading outputs and maximum a posteriori path estimation to predict the communicative function at each level of the hierarchy, preserve the dependencies between the functions in the path, and decide at which level to stop. Additionally, we rely on transfer learning processes to address the data scarcity problem. Our experiments on the DialogBank show that this approach outperforms both flat and hierarchical approaches based on multiple classifiers and that each of its components plays an important role in the recognition of general-purpose communicative functions.": 0.14155209064483643, "IJCAI2023>>program>>Main Track>>1813>>title>>A Dual Semantic-Aware Recurrent Global-Adaptive Network for Vision-and-Language Navigation": 0.17304986715316772, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.17602086067199707}, "What is the title of the program with the code 4961 at the IJCAI2023 Main Track?": {"IJCAI2023>>program>>Main Track>>5176>>authors>>authors_6>>Xin Jiang": 0.10983490943908691, "IJCAI2023>>program>>Main Track>>4418>>authors>>authors_2>>John Grant": 0.10998368263244629, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.11004757881164551, "IJCAI2023>>program>>Main Track>>4961>>authors>>authors_3>>Ming Li": 0.11056184768676758, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.11127394437789917, "IJCAI2023>>program>>Main Track>>4936>>authors>>authors_1>>Pei Xu": 0.11140221357345581, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.1118125319480896, "IJCAI2023>>program>>Main Track>>4969>>authors>>authors_4>>Kai Zhao": 0.11204123497009277, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Professional title>>Program Chair": 0.11248517036437988, "IJCAI2023>>program>>Main Track>>4526>>authors>>authors_1>>Joshua Kavner": 0.11284208297729492, "IJCAI2023>>program>>Main Track>>4973>>authors>>authors_2>>Qi Liu": 0.11303567886352539, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.11345052719116211, "IJCAI2023>>program>>Main Track>>4476>>authors>>authors_2>>Krzysztof Jahn": 0.11364638805389404, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_8>>Jian Wu": 0.11385929584503174, "IJCAI2023>>program>>Main Track>>4636>>authors>>authors_9>>James T. Neal": 0.11388915777206421, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11405140161514282, "IJCAI2023>>program>>Main Track>>5155>>authors>>authors_4>>Jing Jiang": 0.11440819501876831, "IJCAI2023>>program>>Main Track>>3863>>authors>>authors_4>>Jing Liu": 0.11461925506591797, "IJCAI2023>>program>>Main Track>>4929>>authors>>authors_2>>Lianghao Xia": 0.1146543025970459, "IJCAI2023>>program>>Main Track>>4765>>authors>>authors_1>>Yonghao Liu": 0.1150016188621521}, "Who are the authors of the program 'Capturing the Long-Distance Dependency in the Control Flow Graph via Structural-Guided Attention for Bug Localization'?": {"IJCAI2023>>program>>Survey Track>>SV5569>>authors>>authors_3>>Longxiang Gao": 0.1589282751083374, "IJCAI2023>>program>>Survey Track>>SV5554>>authors>>authors_1>>Longbing Cao": 0.16218042373657227, "IJCAI2023>>program>>Survey Track>>SV5587>>authors>>authors_2>>Gabriel G. Castañé": 0.16321337223052979, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_4>>Li Guo": 0.1644728183746338, "IJCAI2023>>program>>Main Track>>3414>>authors>>authors_2>>Guodong Long": 0.16654711961746216, "IJCAI2023>>program>>Main Track>>3139>>authors>>authors_2>>Caspar Oesterheld": 0.16667217016220093, "IJCAI2023>>program>>Main Track>>2676>>authors>>authors_3>>Jean Christoph Jung": 0.16674888134002686, "IJCAI2023>>program>>Main Track>>752>>authors>>authors_7>>Longfei Zheng": 0.1670178771018982, "IJCAI2023>>program>>Survey Track>>SV5630>>authors>>authors_1>>Zhichun Guo": 0.16707754135131836, "IJCAI2023>>program>>Main Track>>639>>authors>>authors_3>>Long Chen": 0.1671648621559143, "IJCAI2023>>program>>Main Track>>1796>>authors>>authors_3>>Guibing Guo": 0.16718006134033203, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_8>>Jingbo Zhu": 0.16725564002990723, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_6>>Mingxuan Wang": 0.16734987497329712, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.16773241758346558, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_4>>Devarajan Sridharan": 0.16774630546569824, "IJCAI2023>>program>>Main Track>>5155>>authors>>authors_2>>Guodong Long": 0.16791903972625732, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.1680625081062317, "IJCAI2023>>program>>Main Track>>1679>>authors>>authors_1>>Matthias Lanzinger": 0.16811472177505493, "IJCAI2023>>program>>Survey Track>>SV5593>>authors>>authors_8>>Qing Li": 0.1683288812637329, "IJCAI2023>>program>>Main Track>>658>>authors>>authors_1>>Supeng Wang": 0.16865456104278564}, "What problem does the program with the code 4961 at the IJCAI2023 Main Track aim to address?": {"IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.12414056062698364, "IJCAI2023>>program>>Main Track>>4518>>authors>>authors_4>>Aravind Srinivasan": 0.12516015768051147, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.1254686713218689, "IJCAI2023>>program>>Main Track>>4476>>authors>>authors_2>>Krzysztof Jahn": 0.1255096197128296, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.12601137161254883, "IJCAI2023>>program>>Main Track>>4526>>authors>>authors_1>>Joshua Kavner": 0.1260983943939209, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.12632745504379272, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.12647271156311035, "IJCAI2023>>program>>Main Track>>5176>>authors>>authors_6>>Xin Jiang": 0.12649786472320557, "IJCAI2023>>program>>Main Track>>4418>>authors>>authors_2>>John Grant": 0.1265234351158142, "IJCAI2023>>program>>Main Track>>4760>>authors>>authors_1>>Piotr Faliszewski": 0.12658482789993286, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_8>>Jian Wu": 0.12659919261932373, "IJCAI2023>>program>>Main Track>>2241>>authors>>authors_3>>Hiroaki Shiokawa": 0.12681806087493896, "IJCAI2023>>program>>Main Track>>4383>>authors>>authors_5>>Aravind Srinivasan": 0.12688636779785156, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.12703847885131836, "IJCAI2023>>program>>Main Track>>4454>>authors>>authors_1>>Hannaneh Akrami": 0.1273210644721985, "IJCAI2023>>program>>Main Track>>4973>>authors>>authors_2>>Qi Liu": 0.12741655111312866, "IJCAI2023>>program>>Main Track>>4936>>authors>>authors_1>>Pei Xu": 0.12755167484283447, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.12761825323104858, "IJCAI2023>>program>>Main Track>>4062>>authors>>authors_1>>Jonathan Gadea Harder": 0.127871572971344}, "What is the novel bug localization model proposed in the program 'Capturing the Long-Distance Dependency in the Control Flow Graph via Structural-Guided Attention for Bug Localization'?": {"IJCAI2023>>program>>Main Track>>4961>>title>>Capturing the Long-Distance Dependency in the Control Flow Graph via Structural-Guided Attention for Bug Localization": 0.07903528213500977, "IJCAI2023>>program>>Main Track>>4961>>abstract>>To alleviate the burden of software maintenance, bug localization, which aims to automatically locate the buggy source files based on the bug report, has drawn significant attention in the software mining community. Recent studies indicate that the program structure in source code carries more semantics reflecting the program behavior, which is beneficial for bug localization. Benefiting from the rich structural information in the Control Flow Graph (CFG), CFG-based bug localization methods have achieved the state-of-the-art performance. Existing CFG-based methods extract the semantic feature from the CFG via the graph neural network. However, the step-wise feature propagation in the graph neural network suffers from the problem of information loss when the propagation distance is long, while the long-distance dependency is rather common in the CFG. In this paper, we argue that the long-distance dependency is crucial for feature extraction from the CFG, and propose a novel bug localization model named sgAttention. In sgAttention, a particularly designed structural-guided attention is employed to globally capture the information in the CFG, where features of irrelevant nodes are masked for each node to facilitate better feature extraction from the CFG. Experimental results on four widely-used open-source software projects indicate that sgAttention averagely improves the state-of-the-art bug localization methods by 32.9\\% and 29.2\\% and the state-of-the-art pre-trained models by 5.8\\%  and 4.9\\% in terms of MAP and MRR, respectively.": 0.08895981311798096, "IJCAI2023>>program>>Main Track>>2048>>title>>Video Diffusion Models with Local-Global Context Guidance": 0.16737109422683716}, "What are the research areas of the program with the code 4961, presented at the IJCAI2023 Main Track?": {"IJCAI2023>>program>>Main Track>>2869>>keywords>>keywords_2>>Humans and AI -> HAI: Brain sciences": 0.1136707067489624, "IJCAI2023>>program>>Main Track>>3955>>keywords>>keywords_3>>Search -> S: Search and machine learning": 0.11555880308151245, "IJCAI2023>>program>>Main Track>>2072>>keywords>>keywords_2>>Humans and AI -> HAI: Brain sciences": 0.115764319896698, "IJCAI2023>>program>>Main Track>>1032>>keywords>>keywords_2>>Humans and AI -> HAI: Brain sciences": 0.11632508039474487, "IJCAI2023>>program>>Main Track>>541>>keywords>>keywords_1>>Machine Learning -> ML: Other": 0.11690807342529297, "IJCAI2023>>program>>Main Track>>3174>>keywords>>keywords_2>>Humans and AI -> HAI: Brain sciences": 0.117489755153656, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.11777567863464355, "IJCAI2023>>program>>Main Track>>4961>>authors>>authors_3>>Ming Li": 0.11805152893066406, "IJCAI2023>>program>>Main Track>>1826>>keywords>>keywords_1>>Search -> S: Search and machine learning": 0.1186760663986206, "IJCAI2023>>program>>Survey Track>>SV5554>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.11917251348495483, "IJCAI2023>>program>>Survey Track>>SV5592>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.11929219961166382, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11932802200317383, "IJCAI2023>>program>>Survey Track>>SV5639>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.11939436197280884, "IJCAI2023>>program>>Survey Track>>SV5460>>keywords>>keywords_4>>Survey -> Multidisciplinary Topics and Applications": 0.1197136640548706, "IJCAI2023>>program>>Survey Track>>SV5653>>keywords>>keywords_1>>Survey -> Multidisciplinary Topics and Applications": 0.11977076530456543, "IJCAI2023>>program>>Survey Track>>SV5579>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.11981827020645142, "IJCAI2023>>program>>Main Track>>2459>>title>>Scalable Coupling of Deep Learning with Logical Reasoning": 0.11988317966461182}, "What is the title of the main track program 2099 in IJCAI 2023 conference?": {"IJCAI2023>>program>>Main Track>>2099>>authors>>authors_5>>Jiqiang Liu": 0.10286498069763184, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Professional title>>Program Chair": 0.10373729467391968, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.10450994968414307, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.10594958066940308, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.1080426573753357, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10894083976745605, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_1>>Jiahao Liu": 0.10942977666854858, "IJCAI2023>>program>>Main Track>>2038>>authors>>authors_2>>Xu Jiang": 0.10960078239440918, "IJCAI2023>>program>>Main Track>>902>>authors>>authors_3>>Jia Wu": 0.11035561561584473, "IJCAI2023>>program>>Main Track>>2099>>authors>>authors_4>>Wenjia Niu": 0.11221307516098022, "IJCAI2023>>program>>Main Track>>2106>>authors>>authors_3>>Yuan Jiang": 0.11285096406936646, "IJCAI2023>>program>>Main Track>>1099>>authors>>authors_2>>Tian-Jing Zhang": 0.11286348104476929, "IJCAI2023>>program>>Main Track>>2051>>authors>>authors_2>>Shuo Ji": 0.11300379037857056, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_8>>Jian Wu": 0.11303168535232544, "IJCAI2023>>program>>Main Track>>2120>>authors>>authors_5>>Jian Xu": 0.11354559659957886, "IJCAI2023>>program>>Main Track>>1068>>authors>>authors_1>>Hua Jiang": 0.11368101835250854, "IJCAI2023>>program>>Main Track>>2038>>authors>>authors_5>>Xi Wu": 0.11383569240570068, "IJCAI2023>>program>>Main Track>>2072>>authors>>authors_3>>Qianhui Liu": 0.1139676570892334, "IJCAI2023>>program>>Main Track>>2099>>authors>>authors_2>>Yunzhe Tian": 0.11398917436599731, "IJCAI2023>>program>>Main Track>>4195>>authors>>authors_3>>Xuan Liu": 0.11422765254974365}, "Who are the authors of the program 2099 in the IJCAI 2023 conference?": {"IJCAI2023>>program>>Main Track>>2099>>authors>>authors_5>>Jiqiang Liu": 0.10666513442993164, "IJCAI2023>>program>>Main Track>>2038>>authors>>authors_2>>Xu Jiang": 0.1091071367263794, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.11041277647018433, "IJCAI2023>>program>>Main Track>>4580>>authors>>authors_3>>Jorge A. Baier": 0.11204028129577637, "IJCAI2023>>program>>Main Track>>2051>>authors>>authors_2>>Shuo Ji": 0.11220419406890869, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.11238735914230347, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.11253213882446289, "IJCAI2023>>program>>Main Track>>2459>>authors>>authors_3>>Thomas Schiex": 0.11269307136535645, "IJCAI2023>>program>>Main Track>>2099>>authors>>authors_4>>Wenjia Niu": 0.11305409669876099, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.11332893371582031, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_1>>Jiahao Liu": 0.11389374732971191, "IJCAI2023>>program>>Main Track>>1957>>authors>>authors_2>>David S. Aleixo": 0.11459249258041382, "IJCAI2023>>program>>Main Track>>2038>>authors>>authors_5>>Xi Wu": 0.11473679542541504, "IJCAI2023>>program>>Main Track>>1099>>authors>>authors_2>>Tian-Jing Zhang": 0.11477231979370117, "IJCAI2023>>program>>Main Track>>3139>>authors>>authors_2>>Caspar Oesterheld": 0.11489969491958618, "IJCAI2023>>program>>Main Track>>2072>>authors>>authors_3>>Qianhui Liu": 0.11491513252258301, "IJCAI2023>>program>>Main Track>>263>>authors>>authors_1>>Keisuke Okumura": 0.11496436595916748, "IJCAI2023>>program>>Main Track>>204>>authors>>authors_2>>Takayuki Osogami": 0.1153104305267334, "IJCAI2023>>program>>Main Track>>2676>>authors>>authors_3>>Jean Christoph Jung": 0.11545157432556152, "IJCAI2023>>program>>Main Track>>1679>>authors>>authors_2>>Markus Nissl": 0.11564028263092041}, "What is the major challenge identified in the program 2099 at the IJCAI 2023 conference?": {"IJCAI2023>>program>>Journal Track>>J5931>>title>>Core Challenges in Embodied Vision-Language Planning (Extended Abstract)": 0.12503552436828613, "IJCAI2023>>calls>>Call For Competitions And Challenges>>Call For Competitions And Challenges_1>>We invite proposals for Competitions and Challenges of IJCAI 2023, the 32nd International Joint Conference on Artificial Intelligence, planned to be held in Macao, SAR, on 19–25 August 2023. The competitions and challenges can be on any topic of interest to the artificial intelligence (AI) community.": 0.12508976459503174, "IJCAI2023>>program>>Competitions and Challenges>>Competitions and Challenges_3>>Competition url>>http://jidiai.cn/ijcai_2023/": 0.12821364402770996, "IJCAI2023>>program>>Competitions and Challenges>>Competitions and Challenges_6>>Description>>The recent strides in robotics and artificial intelligence over the last decade have resulted in more and more robots sharing space and working together with humans in everyday life. This situation puts forth a lot of challenges and concerns that need to be addressed. Of these, understanding the interacting human’s mindset and their subjective satisfaction with the robot’s performance are very critical. One way to address these challenges is analysing the psychophysiological data of the interacting human. This competition encourages the participating teams to develop cutting-edge Signal Processing and/or Machine Learning approaches for the detection of erroneous behaviours using single-trial EEG data and test them on real hardware.": 0.13205105066299438, "IJCAI2023>>program>>Competitions and Challenges>>Competitions and Challenges_2>>Competition url>>https://iparesiliency-ijcai23.github.io/": 0.13208520412445068, "IJCAI2023>>program>>Competitions and Challenges>>Competitions and Challenges_7>>Timeline of the competition>>Timeline of the competition_5>>19-25 August          IJCAI 2023": 0.13363587856292725, "IJCAI2023>>program>>Competitions and Challenges>>Competitions and Challenges_1>>Timeline of the competition>>Timeline of the competition_6>>19th-25th August 2023:Winners will be invited to present during a dedicated session at IJCAI 2023": 0.1338081955909729, "IJCAI2023>>program>>Important Dates>>Conference>>August 19-25, 2023": 0.13499033451080322, "IJCAI2023>>program>>Main Track>>2459>>title>>Scalable Coupling of Deep Learning with Logical Reasoning": 0.13555467128753662}, "What is the main idea of the solution provided for robust RL in the program 2099 at the IJCAI 2023 conference?": {"IJCAI2023>>program>>Main Track>>2099>>title>>Robust Reinforcement Learning via Progressive Task Sequence": 0.11603492498397827, "IJCAI2023>>program>>Main Track>>2459>>title>>Scalable Coupling of Deep Learning with Logical Reasoning": 0.12214714288711548, "IJCAI2023>>program>>Main Track>>797>>title>>Leveraging Argumentation for Generating Robust Sample-based Explanations": 0.12271541357040405, "IJCAI2023>>program>>Main Track>>84>>keywords>>keywords_1>>Machine Learning -> ML: Robustness": 0.12571841478347778, "IJCAI2023>>program>>Main Track>>2969>>keywords>>keywords_3>>Machine Learning -> ML: Robustness": 0.1257549524307251, "IJCAI2023>>program>>Main Track>>1442>>keywords>>keywords_3>>Machine Learning -> ML: Robustness": 0.126512348651886, "IJCAI2023>>program>>Main Track>>2873>>keywords>>keywords_3>>Machine Learning -> ML: Robustness": 0.1265261173248291, "IJCAI2023>>program>>Main Track>>2929>>title>>Complex Contagion Influence Maximization: A Reinforcement Learning Approach": 0.12742578983306885, "IJCAI2023>>program>>Main Track>>109>>title>>Towards Hierarchical Policy Learning for Conversational Recommendation with Hypergraph-based Reinforcement Learning": 0.1277858018875122, "IJCAI2023>>program>>Main Track>>3540>>keywords>>keywords_3>>Machine Learning -> ML: Robustness": 0.12849527597427368, "IJCAI2023>>program>>Main Track>>1778>>title>>Learning to Self-Reconfigure for Freeform Modular Robots via Altruism Proximal Policy Optimization": 0.12870383262634277, "IJCAI2023>>program>>Main Track>>3934>>title>>Safe Reinforcement Learning via Probabilistic Logic Shields": 0.12947994470596313, "IJCAI2023>>program>>Main Track>>4255>>keywords>>keywords_1>>Machine Learning -> ML: Robustness": 0.12954747676849365, "IJCAI2023>>program>>Main Track>>736>>title>>Sequential Recommendation with Probabilistic Logical Reasoning": 0.13015210628509521, "IJCAI2023>>program>>Main Track>>1749>>title>>Learning Calibrated Uncertainties for Domain Shift: A Distributionally Robust Learning Approach": 0.1309424638748169, "IJCAI2023>>program>>Main Track>>1412>>title>>Towards Generalizable Reinforcement Learning for Trade Execution": 0.13135313987731934, "IJCAI2023>>program>>Main Track>>4842>>keywords>>keywords_4>>Machine Learning -> ML: Robustness": 0.13138139247894287}, "What are the keywords associated with program 2099 in the IJCAI 2023 conference?": {"IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.10647666454315186, "IJCAI2023>>program>>Main Track>>3955>>keywords>>keywords_3>>Search -> S: Search and machine learning": 0.10848826169967651, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>keywords>>keywords_2>>General -> General": 0.10926741361618042, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5901>>keywords>>keywords_1>>General -> General": 0.11059057712554932, "IJCAI2023>>program>>Journal Track>>J5940>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> General": 0.11117684841156006, "IJCAI2023>>program>>Main Track>>1826>>keywords>>keywords_1>>Search -> S: Search and machine learning": 0.1113743782043457, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5756>>keywords>>keywords_1>>General -> General": 0.11278986930847168, "IJCAI2023>>program>>Main Track>>930>>keywords>>keywords_3>>Robotics -> ROB: Cognitive robotics": 0.11355853080749512, "IJCAI2023>>program>>Main Track>>2619>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.1140640377998352, "IJCAI2023>>program>>Journal Track>>J5944>>keywords>>keywords_2>>Knowledge Representation and Reasoning -> General": 0.11414754390716553, "IJCAI2023>>program>>Main Track>>541>>keywords>>keywords_1>>Machine Learning -> ML: Other": 0.11454373598098755, "IJCAI2023>>program>>Main Track>>1630>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11504828929901123, "IJCAI2023>>program>>Main Track>>3127>>keywords>>keywords_2>>Machine Learning -> ML: Other": 0.11517739295959473, "IJCAI2023>>program>>Main Track>>3848>>keywords>>keywords_3>>Uncertainty in AI -> UAI: Other": 0.115231454372406, "IJCAI2023>>program>>Main Track>>298>>keywords>>keywords_2>>Computer Vision -> CV: 3D computer vision": 0.11524337530136108, "IJCAI2023>>program>>Main Track>>924>>keywords>>keywords_2>>Computer Vision -> CV: 3D computer vision": 0.11537444591522217, "IJCAI2023>>program>>Main Track>>847>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11539334058761597, "IJCAI2023>>program>>Main Track>>2072>>keywords>>keywords_2>>Humans and AI -> HAI: Brain sciences": 0.11552774906158447}, "What is the title of the paper with the ID 1836 in the main track at IJCAI2023?": {"IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.11522799730300903, "IJCAI2023>>program>>Main Track>>863>>authors>>authors_8>>Jie Chen": 0.11582577228546143, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.11592304706573486, "IJCAI2023>>program>>Main Track>>3636>>authors>>authors_6>>Hui Xiong": 0.11597859859466553, "IJCAI2023>>program>>Main Track>>1833>>authors>>authors_7>>Yan Zheng": 0.11658555269241333, "IJCAI2023>>program>>Main Track>>3639>>authors>>authors_3>>Zheng Wang": 0.11678510904312134, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_1>>Yu-Xuan Huang": 0.11692947149276733, "IJCAI2023>>program>>Main Track>>2816>>authors>>authors_1>>Jiangjiang Zhao": 0.11710852384567261, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.11761993169784546, "IJCAI2023>>program>>Main Track>>1068>>authors>>authors_1>>Hua Jiang": 0.11768913269042969, "IJCAI2023>>program>>Main Track>>3832>>authors>>authors_4>>Ian Miguel": 0.1177249550819397, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_3>>Seyed-Mohammad Seyed-Javadi": 0.11782151460647583, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.11815738677978516, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.11820155382156372, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.11827725172042847, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_8>>Zhi-Hua Zhou": 0.11845076084136963, "IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.11856698989868164, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11871278285980225, "IJCAI2023>>program>>Main Track>>1833>>authors>>authors_3>>Zhimeng Jiang": 0.11882287263870239, "IJCAI2023>>program>>Main Track>>1918>>authors>>authors_3>>Zhiwei Jiang": 0.11888408660888672}, "Who are the authors of the paper with the ID 1836 in the main track at IJCAI2023?": {"IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.11205744743347168, "IJCAI2023>>program>>Main Track>>3832>>authors>>authors_4>>Ian Miguel": 0.11365795135498047, "IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.11369061470031738, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_1>>Yu-Xuan Huang": 0.1145026683807373, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_1>>Barath Mohan Umapathi": 0.11451494693756104, "IJCAI2023>>program>>Main Track>>1868>>authors>>authors_1>>Alex Cloud": 0.11466622352600098, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_4>>Devarajan Sridharan": 0.11547267436981201, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_3>>Seyed-Mohammad Seyed-Javadi": 0.11579185724258423, "IJCAI2023>>program>>Main Track>>3848>>authors>>authors_6>>Diederik M. Roijers": 0.1160019040107727, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.11618983745574951, "IJCAI2023>>program>>Main Track>>1868>>authors>>authors_2>>Albert Wang": 0.11625641584396362, "IJCAI2023>>program>>Main Track>>1833>>authors>>authors_7>>Yan Zheng": 0.1163320541381836, "IJCAI2023>>program>>Main Track>>721>>authors>>authors_3>>Eduard Eiben": 0.11654043197631836, "IJCAI2023>>program>>Main Track>>586>>authors>>authors_5>>Wei Li": 0.1167951226234436, "IJCAI2023>>program>>Main Track>>3639>>authors>>authors_3>>Zheng Wang": 0.11680436134338379, "IJCAI2023>>program>>Main Track>>1816>>authors>>authors_2>>Bernardo Cuenca Grau": 0.11691391468048096, "IJCAI2023>>program>>Main Track>>1829>>authors>>authors_4>>Ivor W. Tsang": 0.11707192659378052, "IJCAI2023>>program>>Main Track>>4423>>authors>>authors_1>>André Schidler": 0.11712175607681274, "IJCAI2023>>program>>Main Track>>398>>authors>>authors_1>>Xuewei Li": 0.11743396520614624, "IJCAI2023>>program>>Main Track>>1476>>authors>>authors_1>>Ren-Jian Wang": 0.1174774169921875}, "What is the abstract of the paper with the ID 1836 in the main track at IJCAI2023?": {"IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.11194759607315063, "IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.11735695600509644, "IJCAI2023>>program>>Main Track>>3365>>authors>>authors_3>>Abhay Aradhya": 0.11869305372238159, "IJCAI2023>>program>>Main Track>>1833>>authors>>authors_7>>Yan Zheng": 0.11912822723388672, "IJCAI2023>>program>>Main Track>>3639>>authors>>authors_3>>Zheng Wang": 0.11921423673629761, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_8>>Zhi-Hua Zhou": 0.11966359615325928, "IJCAI2023>>program>>Main Track>>658>>authors>>authors_5>>Yabiao Wang": 0.12014925479888916, "IJCAI2023>>program>>Main Track>>2816>>authors>>authors_1>>Jiangjiang Zhao": 0.12038284540176392, "IJCAI2023>>program>>Main Track>>4148>>authors>>authors_1>>Abhinav Joshi": 0.12077194452285767, "IJCAI2023>>program>>Main Track>>863>>authors>>authors_8>>Jie Chen": 0.12108176946640015, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_1>>Yu-Xuan Huang": 0.1211390495300293, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.12143582105636597, "IJCAI2023>>program>>Main Track>>2671>>authors>>authors_3>>Jihua Zhu": 0.12152987718582153, "IJCAI2023>>program>>Main Track>>2676>>authors>>authors_3>>Jean Christoph Jung": 0.12158024311065674, "IJCAI2023>>program>>Main Track>>3848>>authors>>authors_6>>Diederik M. Roijers": 0.12164747714996338, "IJCAI2023>>program>>Main Track>>2869>>authors>>authors_3>>Haichao Wang": 0.12167197465896606, "IJCAI2023>>program>>Main Track>>1068>>authors>>authors_1>>Hua Jiang": 0.12177306413650513, "IJCAI2023>>program>>Main Track>>4826>>authors>>authors_4>>Alain Mermoud": 0.12180858850479126, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_3>>Seyed-Mohammad Seyed-Javadi": 0.12185525894165039, "IJCAI2023>>program>>Main Track>>283>>authors>>authors_3>>Zhen Huang": 0.122123122215271}, "What are the keywords of the paper with the ID 1836 in the main track at IJCAI2023?": {"IJCAI2023>>program>>Main Track>>1826>>keywords>>keywords_1>>Search -> S: Search and machine learning": 0.10633295774459839, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC3>>keywords>>keywords_3>>Sister Conferences Best Papers -> Humans and AI": 0.10650986433029175, "IJCAI2023>>program>>Main Track>>3955>>keywords>>keywords_3>>Search -> S: Search and machine learning": 0.1085582971572876, "IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.11061102151870728, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.11306500434875488, "IJCAI2023>>program>>Main Track>>1813>>keywords>>keywords_3>>Computer Vision -> CV: Structural and model-based approaches, knowledge representation and reasoning": 0.1134764552116394, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>keywords>>keywords_2>>General -> General": 0.11359691619873047, "IJCAI2023>>program>>Journal Track>>J5920>>keywords>>keywords_2>>Data Mining -> General": 0.11373680830001831, "IJCAI2023>>program>>Survey Track>>SV5639>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.11408060789108276, "IJCAI2023>>program>>Main Track>>1630>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11440169811248779, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC12>>keywords>>keywords_4>>Sister Conferences Best Papers -> Search": 0.11445599794387817, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC25>>keywords>>keywords_1>>Sister Conferences Best Papers -> Machine Learning": 0.1145668625831604, "IJCAI2023>>program>>Journal Track>>J5940>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> General": 0.11467850208282471, "IJCAI2023>>program>>Survey Track>>SV5587>>keywords>>keywords_3>>Survey -> Humans and AI": 0.11478155851364136, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC10>>keywords>>keywords_1>>Sister Conferences Best Papers -> Knowledge Representation and Reasoning": 0.1151505708694458, "IJCAI2023>>program>>Main Track>>4339>>keywords>>keywords_1>>Machine Learning -> ML: Experimental methodology": 0.1152411699295044}, "What is the main topic addressed by the paper with the ID 1836 in the main track at IJCAI2023?": {"IJCAI2023>>calls>>Call For Papers: Survey Track>>Call For Papers: Survey Track_4>>What Is a Suitable Topic?>>The IJCAI 2023 Survey Track provides an opportunity for established researchers in the AI community to give a broad talk on a well-established body of research, which provides a big-picture view of the topic rather than discussing a particular aspect. The topic should be of interest to current AI practitioners. Of particular interest are papers that describe how lessons learned from the topic can contribute to new ideas and visions that can stimulate the research community to pursue new directions, e.g., new problems.": 0.11993032693862915, "IJCAI2023>>program>>Main Track>>2459>>title>>Scalable Coupling of Deep Learning with Logical Reasoning": 0.12358427047729492, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.12433701753616333, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Name>>Edith Elkind": 0.1287628412246704, "IJCAI2023>>program>>Main Track>>1856>>title>>Towards a Better Understanding of Learning with Multiagent Teams": 0.1292475461959839, "IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.12967807054519653, "IJCAI2023>>program>>Main Track>>1268>>title>>Towards Semantics- and Domain-Aware Adversarial Attacks": 0.1305943727493286, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_3>>Seyed-Mohammad Seyed-Javadi": 0.1306474804878235, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.13068020343780518, "IJCAI2023>>program>>Main Track>>1834>>title>>A Unifying Formal Approach to Importance Values in Boolean Functions": 0.13071459531784058, "IJCAI2023>>program>>Main Track>>863>>authors>>authors_8>>Jie Chen": 0.13087767362594604, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.13105028867721558, "IJCAI2023>>program>>Main Track>>1813>>keywords>>keywords_3>>Computer Vision -> CV: Structural and model-based approaches, knowledge representation and reasoning": 0.13129454851150513, "IJCAI2023>>program>>Main Track>>2836>>title>>The Hardness of Reasoning about Probabilities and Causality": 0.1313081979751587}, "What is the title of the paper presented in the Special Track on AI for Good?": {"IJCAI2023>>calls>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)_5>>Also, just as the research papers submitted to the main track of IJCAI 2023, papers in this track should be anonymous. Unlike for papers in the main track, there will be no author rebuttal, and no summary reject phase. Accepted research papers in the AI for Good track will be included in the IJCAI proceedings. An award will be given to honour outstanding research papers in this track.": 0.09808945655822754, "IJCAI2023>>calls>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)_6>>Submission of Research Papers>>Submission of Research Papers_2>>Also, just as the research papers submitted to the main track of IJCAI 2023, papers in this track should beanonymous. Unlike for papers in the main track, there will beno author rebuttal, andno summary rejectphase. Accepted research papers in the AI for Good track will be included in the IJCAI proceedings. An award will be given to honour outstanding research papers in this track.": 0.1000482439994812, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5763>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.10025978088378906, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5813>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.10040092468261719, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5859>>authors>>authors_1>>Adel Khorramrouz": 0.10060012340545654, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5823>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.10070478916168213, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.10087031126022339, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5694>>authors>>authors_3>>Azza Abouzied": 0.10092109441757202}, "Who are the authors of the paper titled 'GreenFlow: A Computation Allocation Framework for Building Environmentally Sound Recommendation System'?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5746>>authors>>authors_1>>Junfan Lin": 0.18243056535720825, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG1368>>authors>>authors_3>>Pengfei Wei": 0.18335121870040894, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.18394100666046143, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG1573>>authors>>authors_7>>YangFei Zheng": 0.18408745527267456, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG1573>>authors>>authors_5>>Lin-Tao Ma": 0.1841980218887329, "IJCAI2023>>program>>Main Track>>1654>>authors>>authors_6>>Yen-Wei Chen": 0.18437737226486206, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5772>>authors>>authors_5>>Roy Ka-Wei Lee": 0.18438559770584106, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG1573>>authors>>authors_3>>Xiaoming Shi": 0.18451452255249023, "IJCAI2023>>program>>Survey Track>>SV5569>>authors>>authors_5>>Yunfeng Li": 0.18477219343185425, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5772>>authors>>authors_4>>Kenny Tsu Wei Choo": 0.1849789023399353, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_4>>Chengqi Zhao": 0.1851901412010193, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5787>>authors>>authors_2>>Richard Jiang": 0.18529081344604492, "IJCAI2023>>program>>Survey Track>>SV5593>>authors>>authors_1>>Chengyi Liu": 0.18544155359268188, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5761>>authors>>authors_6>>Xiaowei Jia": 0.18557918071746826, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.1856706738471985, "IJCAI2023>>program>>Main Track>>619>>authors>>authors_1>>Chengming Feng": 0.18579810857772827, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5772>>authors>>authors_1>>Han Wang": 0.1861305832862854}, "What is the main proposal in the abstract of the paper titled 'GreenFlow: A Computation Allocation Framework for Building Environmentally Sound Recommendation System'?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5800>>title>>GreenFlow: A Computation Allocation Framework for Building Environmentally Sound Recommendation System": 0.08595067262649536, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5800>>abstract>>Given the enormous number of users and items, industrial cascade recommendation systems (RS) are continuously expanded in size and complexity to deliver relevant items, such as news, services, and commodities, to the appropriate users. In a real-world scenario with hundreds of thousands requests per second, significant computation is required to infer personalized results for each request, resulting in a massive energy consumption and carbon emission that raises concern. \n\nThis paper proposes GreenFlow, a practical computation allocation framework for RS, that considers both accuracy and carbon emission during inference. For each stage (e.g., recall, pre-ranking, ranking, etc.) of a cascade RS, when a user triggers a request, we define two actions that determine the computation: (1) the trained instances of models with different computational complexity; and (2) the number of items to be inferred in the stage. We refer to the combinations of actions in all stages as action chains. A reward score is estimated for each action chain, followed by dynamic primal-dual optimization considering both the reward and computation budget. Extensive experiments verify the effectiveness of the framework, reducing computation consumption by 41% in an industrial mobile application while maintaining commercial revenue. Moreover, the proposed framework saves approximately 5000kWh of electricity and reduces 3 tons of carbon emissions per day.": 0.12852561473846436, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG1573>>title>>Full Scaling Automation for Sustainable Development of Green Data Centers": 0.1619986891746521}, "What are the general areas of interest or keywords concerning the paper titled 'GreenFlow: A Computation Allocation Framework for Building Environmentally Sound Recommendation System'?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5800>>title>>GreenFlow: A Computation Allocation Framework for Building Environmentally Sound Recommendation System": 0.09415030479431152, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5800>>abstract>>Given the enormous number of users and items, industrial cascade recommendation systems (RS) are continuously expanded in size and complexity to deliver relevant items, such as news, services, and commodities, to the appropriate users. In a real-world scenario with hundreds of thousands requests per second, significant computation is required to infer personalized results for each request, resulting in a massive energy consumption and carbon emission that raises concern. \n\nThis paper proposes GreenFlow, a practical computation allocation framework for RS, that considers both accuracy and carbon emission during inference. For each stage (e.g., recall, pre-ranking, ranking, etc.) of a cascade RS, when a user triggers a request, we define two actions that determine the computation: (1) the trained instances of models with different computational complexity; and (2) the number of items to be inferred in the stage. We refer to the combinations of actions in all stages as action chains. A reward score is estimated for each action chain, followed by dynamic primal-dual optimization considering both the reward and computation budget. Extensive experiments verify the effectiveness of the framework, reducing computation consumption by 41% in an industrial mobile application while maintaining commercial revenue. Moreover, the proposed framework saves approximately 5000kWh of electricity and reduces 3 tons of carbon emissions per day.": 0.13978439569473267, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG1573>>title>>Full Scaling Automation for Sustainable Development of Green Data Centers": 0.16201120615005493, "IJCAI2023>>program>>Main Track>>2692>>keywords>>keywords_2>>Multidisciplinary Topics and Applications -> MDA: Energy, environment and sustainability": 0.17291951179504395, "IJCAI2023>>program>>Main Track>>684>>keywords>>keywords_1>>Data Mining -> DM: Recommender systems": 0.17429661750793457, "IJCAI2023>>program>>Main Track>>736>>keywords>>keywords_1>>Data Mining -> DM: Recommender systems": 0.17446517944335938, "IJCAI2023>>program>>Main Track>>109>>keywords>>keywords_1>>Data Mining -> DM: Recommender systems": 0.1744968295097351}, "What are the environmental benefits of the proposed GreenFlow framework as per the abstract?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5800>>title>>GreenFlow: A Computation Allocation Framework for Building Environmentally Sound Recommendation System": 0.1441338062286377, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5800>>abstract>>Given the enormous number of users and items, industrial cascade recommendation systems (RS) are continuously expanded in size and complexity to deliver relevant items, such as news, services, and commodities, to the appropriate users. In a real-world scenario with hundreds of thousands requests per second, significant computation is required to infer personalized results for each request, resulting in a massive energy consumption and carbon emission that raises concern. \n\nThis paper proposes GreenFlow, a practical computation allocation framework for RS, that considers both accuracy and carbon emission during inference. For each stage (e.g., recall, pre-ranking, ranking, etc.) of a cascade RS, when a user triggers a request, we define two actions that determine the computation: (1) the trained instances of models with different computational complexity; and (2) the number of items to be inferred in the stage. We refer to the combinations of actions in all stages as action chains. A reward score is estimated for each action chain, followed by dynamic primal-dual optimization considering both the reward and computation budget. Extensive experiments verify the effectiveness of the framework, reducing computation consumption by 41% in an industrial mobile application while maintaining commercial revenue. Moreover, the proposed framework saves approximately 5000kWh of electricity and reduces 3 tons of carbon emissions per day.": 0.18730521202087402}, "What is the title of the demonstration track DM5722?": {"IJCAI2023>>program>>Demonstrations Track>>DM5735>>authors>>authors_1>>Joachim Baumann": 0.16569334268569946, "IJCAI2023>>program>>Demonstrations Track>>DM5742>>authors>>authors_6>>Keerthiram Murugesan": 0.16789978742599487, "IJCAI2023>>program>>Demonstrations Track>>DM5703>>authors>>authors_2>>Pedro Miguel Sánchez Sánchez": 0.1702306866645813, "IJCAI2023>>program>>Demonstrations Track>>DM5705>>authors>>authors_1>>Ibrahim Abdelaziz": 0.1705862283706665, "IJCAI2023>>program>>Demonstrations Track>>DM5742>>authors>>authors_2>>Bharath Muppasani": 0.17150306701660156, "IJCAI2023>>program>>Demonstrations Track>>DM5718>>authors>>authors_5>>Srinath Srinivasa": 0.1717340350151062, "IJCAI2023>>program>>Demonstrations Track>>DM5728>>authors>>authors_1>>Anuradha Bhamidipaty": 0.17241686582565308, "IJCAI2023>>program>>Demonstrations Track>>DM5705>>authors>>authors_5>>Kavitha Srinivas": 0.17309904098510742, "IJCAI2023>>program>>Demonstrations Track>>DM5742>>authors>>authors_10>>Yathin Kethepalli": 0.17354553937911987, "IJCAI2023>>program>>Demonstrations Track>>DM5696>>authors>>authors_4>>Thomas McCluskey": 0.17367488145828247, "IJCAI2023>>program>>Demonstrations Track>>DM5742>>authors>>authors_1>>Vishal Pallagani": 0.17405009269714355, "IJCAI2023>>program>>Demonstrations Track>>DM5703>>authors>>authors_1>>Enrique Tomás Martínez Beltrán": 0.17412686347961426, "IJCAI2023>>program>>Demonstrations Track>>DM5742>>authors>>authors_9>>Rony Joseph": 0.17491257190704346, "IJCAI2023>>program>>Demonstrations Track>>DM5680>>title>>IMPsys: An Intelligent Mold Processing System for Smart Factory": 0.17499500513076782, "IJCAI2023>>program>>Demonstrations Track>>DM5719>>authors>>authors_3>>Adlane Sayede": 0.17554986476898193, "IJCAI2023>>program>>Demonstrations Track>>DM5732>>authors>>authors_4>>Yong Shan": 0.17675942182540894, "IJCAI2023>>program>>Demonstrations Track>>DM5735>>authors>>authors_5>>Nicole Inverardi": 0.17690938711166382}, "Who are the authors of the demonstration 'mahaNLP: A Marathi Natural Language Processing Library'?": {"IJCAI2023>>program>>Demonstrations Track>>DM5722>>authors>>authors_3>>Sharayu Hiwarkhedkar": 0.1561252474784851, "IJCAI2023>>program>>Main Track>>3422>>authors>>authors_3>>Madhav Marathe": 0.1562483310699463, "IJCAI2023>>program>>Main Track>>4383>>authors>>authors_4>>Madhav Marathe": 0.1611291766166687, "IJCAI2023>>program>>Demonstrations Track>>DM5742>>authors>>authors_2>>Bharath Muppasani": 0.1616024374961853, "IJCAI2023>>program>>Demonstrations Track>>DM5731>>authors>>authors_4>>Prasenjit Mitra": 0.1619347333908081, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>authors>>authors_2>>Omkar Dhekane": 0.16332381963729858, "IJCAI2023>>program>>Demonstrations Track>>DM5718>>authors>>authors_2>>Arpitha Malavalli": 0.1674085259437561, "IJCAI2023>>program>>Main Track>>2929>>authors>>authors_6>>Milind Tambe": 0.1680082082748413, "IJCAI2023>>program>>Demonstrations Track>>DM5728>>authors>>authors_1>>Anuradha Bhamidipaty": 0.16805315017700195, "IJCAI2023>>program>>Demonstrations Track>>DM5742>>authors>>authors_1>>Vishal Pallagani": 0.16864049434661865, "IJCAI2023>>program>>Demonstrations Track>>DM5741>>authors>>authors_1>>Prabhant Singh": 0.16893398761749268, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>authors>>authors_4>>Saloni Mittal": 0.16914957761764526, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>authors>>authors_5>>Raviraj Joshi": 0.16934043169021606, "IJCAI2023>>program>>Demonstrations Track>>DM5696>>authors>>authors_1>>Saumya Bhatnagar": 0.17010104656219482, "IJCAI2023>>program>>Demonstrations Track>>DM5728>>authors>>authors_3>>Bhavna Agrawal": 0.1702038049697876, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_1>>Barath Mohan Umapathi": 0.1704694628715515, "IJCAI2023>>program>>Demonstrations Track>>DM5705>>authors>>authors_5>>Kavitha Srinivas": 0.17060202360153198}, "What is the goal of the mahaNLP library?": {"IJCAI2023>>program>>Demonstrations Track>>DM5722>>abstract>>We present mahaNLP, an open-source natural language processing (NLP) library specifically built for the Marathi language. It aims to enhance the support for the low-resource Indian language Marathi in the field of NLP. It is an easy-to-use, extensible and modular toolkit for Marathi text analysis built on state-of-the-art transformer models. In comparison to other existing Indic NLP libraries that support basic Marathi processing, this toolkit houses an extensive set of NLP tasks ranging from basic preprocessing tasks to advanced NLP tasks. Additionally, it provides functionality to load datasets for supervised tasks like Marathi sentiment analysis, NER, and Hate speech detection as data frames. This paper focuses on the overview of the mahaNLP framework, its features, and its usage. This work is a part of the L3Cube MahaNLP initiative, more information about it can be found at https://github.com/l3cube-pune/MarathiNLP and the demonstration video and file of mahaNLP are available at https://youtu.be/KxExcwCrTO0 and https://cutt.ly/f1FYQak respectively.": 0.09275943040847778, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>title>>mahaNLP: A Marathi Natural Language Processing Library": 0.11462521553039551, "IJCAI2023>>program>>Main Track>>2562>>keywords>>keywords_3>>Natural Language Processing -> NLP: Tools": 0.17445701360702515, "IJCAI2023>>program>>Main Track>>2816>>keywords>>keywords_1>>Natural Language Processing -> NLP: Language models": 0.17646175622940063, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>keywords>>keywords_1>>Natural Language Processing -> NLP: Tools": 0.17670494318008423, "IJCAI2023>>program>>Main Track>>1145>>keywords>>keywords_2>>Natural Language Processing -> NLP: Language models": 0.1777738332748413, "IJCAI2023>>program>>Main Track>>3222>>keywords>>keywords_1>>Natural Language Processing -> NLP: Language models": 0.17803144454956055, "IJCAI2023>>program>>Main Track>>2705>>keywords>>keywords_3>>Natural Language Processing -> NLP: Question answering": 0.1802791953086853, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>keywords>>keywords_3>>Natural Language Processing -> NLP: Language models": 0.1803112030029297}, "What are the features and functionality of the mahaNLP library?": {"IJCAI2023>>program>>Demonstrations Track>>DM5722>>abstract>>We present mahaNLP, an open-source natural language processing (NLP) library specifically built for the Marathi language. It aims to enhance the support for the low-resource Indian language Marathi in the field of NLP. It is an easy-to-use, extensible and modular toolkit for Marathi text analysis built on state-of-the-art transformer models. In comparison to other existing Indic NLP libraries that support basic Marathi processing, this toolkit houses an extensive set of NLP tasks ranging from basic preprocessing tasks to advanced NLP tasks. Additionally, it provides functionality to load datasets for supervised tasks like Marathi sentiment analysis, NER, and Hate speech detection as data frames. This paper focuses on the overview of the mahaNLP framework, its features, and its usage. This work is a part of the L3Cube MahaNLP initiative, more information about it can be found at https://github.com/l3cube-pune/MarathiNLP and the demonstration video and file of mahaNLP are available at https://youtu.be/KxExcwCrTO0 and https://cutt.ly/f1FYQak respectively.": 0.09535586833953857, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>title>>mahaNLP: A Marathi Natural Language Processing Library": 0.119087815284729, "IJCAI2023>>program>>Main Track>>2562>>keywords>>keywords_3>>Natural Language Processing -> NLP: Tools": 0.17342126369476318, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>keywords>>keywords_1>>Natural Language Processing -> NLP: Tools": 0.17361027002334595, "IJCAI2023>>program>>Main Track>>2816>>keywords>>keywords_1>>Natural Language Processing -> NLP: Language models": 0.17399239540100098, "IJCAI2023>>program>>Main Track>>1145>>keywords>>keywords_2>>Natural Language Processing -> NLP: Language models": 0.17499184608459473, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>keywords>>keywords_3>>Natural Language Processing -> NLP: Language models": 0.17774778604507446, "IJCAI2023>>program>>Main Track>>3222>>keywords>>keywords_1>>Natural Language Processing -> NLP: Language models": 0.17779844999313354, "IJCAI2023>>program>>Demonstrations Track>>DM5691>>keywords>>keywords_8>>Natural Language Processing -> NLP: Applications": 0.17790687084197998}, "What are the keywords associated with the DM5722 demonstration track?": {"IJCAI2023>>program>>Demonstrations Track>>DM5731>>keywords>>keywords_2>>Data Mining -> DM: Applications": 0.15530318021774292, "IJCAI2023>>program>>Demonstrations Track>>DM5741>>keywords>>keywords_2>>Machine Learning -> ML: Automated machine learning": 0.15557026863098145, "IJCAI2023>>program>>Demonstrations Track>>DM5740>>keywords>>keywords_1>>Machine Learning -> ML: Feature extraction, selection and dimensionality reduction": 0.15567970275878906, "IJCAI2023>>program>>Demonstrations Track>>DM5705>>keywords>>keywords_1>>Machine Learning -> ML: Automated machine learning": 0.15595293045043945, "IJCAI2023>>program>>Demonstrations Track>>DM5686>>keywords>>keywords_6>>Machine Learning -> ML: Multi-modal learning": 0.1588510274887085, "IJCAI2023>>program>>Demonstrations Track>>DM5703>>keywords>>keywords_4>>Machine Learning -> ML: Evaluation": 0.15892523527145386, "IJCAI2023>>program>>Demonstrations Track>>DM5719>>keywords>>keywords_4>>Machine Learning -> ML: Feature extraction, selection and dimensionality reduction": 0.15943574905395508, "IJCAI2023>>program>>Demonstrations Track>>DM5695>>keywords>>keywords_6>>Machine Learning -> ML: Feature extraction, selection and dimensionality reduction": 0.1594361662864685, "IJCAI2023>>program>>Demonstrations Track>>DM5731>>keywords>>keywords_3>>Data Mining -> DM: Mining spatial and/or temporal data": 0.1609998345375061, "IJCAI2023>>program>>Demonstrations Track>>DM5695>>keywords>>keywords_4>>Data Mining -> DM: Exploratory data mining": 0.16141360998153687, "IJCAI2023>>program>>Demonstrations Track>>DM5740>>keywords>>keywords_2>>Multidisciplinary Topics and Applications -> MDA: Energy, environment and sustainability": 0.16220033168792725, "IJCAI2023>>program>>Demonstrations Track>>DM5712>>keywords>>keywords_2>>Multidisciplinary Topics and Applications -> MDA: Other": 0.16226834058761597, "IJCAI2023>>program>>Demonstrations Track>>DM5680>>keywords>>keywords_2>>Computer Vision -> CV: 3D computer vision": 0.16293984651565552, "IJCAI2023>>program>>Demonstrations Track>>DM5740>>keywords>>keywords_6>>Machine Learning -> ML: Classification": 0.1632329821586609, "IJCAI2023>>program>>Demonstrations Track>>DM5732>>keywords>>keywords_2>>Multidisciplinary Topics and Applications -> MDA: Other": 0.16342705488204956}, "What is the title of the paper with the ID 4313 in the Main Track program?": {"IJCAI2023>>program>>Main Track>>4350>>authors>>authors_3>>Gerhard Widmer": 0.14153379201889038, "IJCAI2023>>program>>Main Track>>4401>>authors>>authors_4>>Johannes Oetsch": 0.14273285865783691, "IJCAI2023>>program>>Main Track>>4418>>authors>>authors_2>>John Grant": 0.14405280351638794, "IJCAI2023>>program>>Main Track>>4311>>authors>>authors_1>>Jiahua Xiao": 0.1451270580291748, "IJCAI2023>>program>>Main Track>>4152>>authors>>authors_3>>Jidong Lv": 0.14513057470321655, "IJCAI2023>>program>>Main Track>>4423>>authors>>authors_1>>André Schidler": 0.14523237943649292, "IJCAI2023>>program>>Main Track>>4372>>authors>>authors_7>>Jun Zhou": 0.14535313844680786, "IJCAI2023>>program>>Main Track>>4438>>authors>>authors_1>>Debarun Bhattacharjya": 0.14539051055908203, "IJCAI2023>>program>>Main Track>>4480>>authors>>authors_3>>Dariusz R. Kowalski": 0.14691734313964844, "IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.14696484804153442, "IJCAI2023>>program>>Main Track>>4401>>authors>>authors_1>>Thomas Eiter": 0.1470065712928772, "IJCAI2023>>program>>Main Track>>4492>>authors>>authors_1>>Andrew Estornell": 0.14727038145065308, "IJCAI2023>>program>>Main Track>>4438>>authors>>authors_4>>Keerthiram Murugesan": 0.14728277921676636, "IJCAI2023>>program>>Main Track>>3414>>authors>>authors_3>>Tianyi Zhou": 0.14735901355743408, "IJCAI2023>>program>>Main Track>>3243>>authors>>authors_3>>Zhen Wang": 0.1475352644920349, "IJCAI2023>>program>>Main Track>>4313>>authors>>authors_1>>Emiliano Lorini": 0.14782625436782837, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.1478613018989563, "IJCAI2023>>program>>Main Track>>4714>>authors>>authors_1>>Daniel Hernandez": 0.14805036783218384, "IJCAI2023>>program>>Main Track>>4206>>authors>>authors_3>>Meirav Zehavi": 0.14814341068267822, "IJCAI2023>>program>>Main Track>>3140>>authors>>authors_3>>Matthew E. Taylor": 0.14819401502609253}, "Who is the author of the paper 'A Rule-Based Modal View of Causal Reasoning'?": {"IJCAI2023>>program>>Main Track>>4313>>title>>A Rule-Based Modal View of Causal Reasoning": 0.09734910726547241, "IJCAI2023>>program>>Main Track>>4313>>abstract>>We present a novel rule-based semantics for causal reasoning as well as a number of modal languages interpreted over it. They enable us to represent some fundamental concepts in the theory of causality including causal necessity and possibility, interventionist conditionals and Lewisian conditionals. We provide complexity results for the satisfiability checking and model checking problem for these modal languages. Moreover, we study the relationship between our rule-based semantics and the structural equation modeling (SEM) approach to causal reasoning, as well as between our rule-based semantics for causal conditionals and the standard semantics for belief base change.": 0.13153928518295288, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC10>>title>>MV-Datalog+/-: Effective Rule-based Reasoning with Uncertain Observations": 0.1457352638244629, "IJCAI2023>>program>>Main Track>>2836>>title>>The Hardness of Reasoning about Probabilities and Causality": 0.16110330820083618, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC1>>title>>Causal Conceptions of Fairness and their Consequences.": 0.1668996810913086, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5906>>title>>On Building a Semi-Automated Framework for Generating Causal Bayesian Networks from Raw Text": 0.1680971384048462, "IJCAI2023>>program>>Main Track>>1883>>title>>On the Paradox of Learning to Reason from Data": 0.16845190525054932, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5906>>keywords>>keywords_3>>Knowledge Representation and Reasoning -> KRR: Causality": 0.17099571228027344, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5895>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> KRR: Causality": 0.17182040214538574, "IJCAI2023>>program>>Main Track>>2147>>keywords>>keywords_2>>Knowledge Representation and Reasoning -> KRR: Causality": 0.17216366529464722, "IJCAI2023>>program>>Main Track>>2836>>keywords>>keywords_2>>Knowledge Representation and Reasoning -> KRR: Causality": 0.17250895500183105, "IJCAI2023>>program>>Main Track>>2705>>title>>An Empirical Study on the Language Modal in Visual Question Answering": 0.1730673909187317}, "What is the abstract of the paper with the ID 4313 in the Main Track program?": {"IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.12860941886901855, "IJCAI2023>>program>>Main Track>>4350>>authors>>authors_3>>Gerhard Widmer": 0.13613736629486084, "IJCAI2023>>program>>Main Track>>4401>>authors>>authors_4>>Johannes Oetsch": 0.13637977838516235, "IJCAI2023>>program>>Main Track>>3151>>authors>>authors_1>>Abdullah Al Maruf": 0.1389983892440796, "IJCAI2023>>program>>Main Track>>3127>>authors>>authors_1>>K. Darshana Abeyrathna": 0.13900768756866455, "IJCAI2023>>program>>Main Track>>658>>authors>>authors_5>>Yabiao Wang": 0.13969385623931885, "IJCAI2023>>program>>Main Track>>3243>>authors>>authors_3>>Zhen Wang": 0.13976335525512695, "IJCAI2023>>program>>Main Track>>4372>>authors>>authors_7>>Jun Zhou": 0.1401316523551941, "IJCAI2023>>program>>Main Track>>4580>>authors>>authors_3>>Jorge A. Baier": 0.1405848264694214, "IJCAI2023>>program>>Main Track>>4311>>authors>>authors_1>>Jiahua Xiao": 0.14060163497924805, "IJCAI2023>>program>>Main Track>>3414>>authors>>authors_3>>Tianyi Zhou": 0.14081627130508423, "IJCAI2023>>program>>Main Track>>3365>>authors>>authors_3>>Abhay Aradhya": 0.14108526706695557, "IJCAI2023>>program>>Main Track>>4438>>authors>>authors_1>>Debarun Bhattacharjya": 0.1411827802658081, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_3>>Seyed-Mohammad Seyed-Javadi": 0.14136332273483276, "IJCAI2023>>program>>Main Track>>4826>>authors>>authors_4>>Alain Mermoud": 0.1414705514907837, "IJCAI2023>>program>>Main Track>>4413>>authors>>authors_2>>Zhen Wang": 0.14181333780288696, "IJCAI2023>>program>>Main Track>>4313>>authors>>authors_1>>Emiliano Lorini": 0.14189088344573975, "IJCAI2023>>program>>Main Track>>4423>>authors>>authors_1>>André Schidler": 0.14198565483093262, "IJCAI2023>>program>>Main Track>>4236>>authors>>authors_7>>Zhetao Li": 0.14206832647323608}, "What are the keywords associated with the paper 'A Rule-Based Modal View of Causal Reasoning'?": {"IJCAI2023>>program>>Main Track>>4313>>title>>A Rule-Based Modal View of Causal Reasoning": 0.09277671575546265, "IJCAI2023>>program>>Main Track>>4313>>abstract>>We present a novel rule-based semantics for causal reasoning as well as a number of modal languages interpreted over it. They enable us to represent some fundamental concepts in the theory of causality including causal necessity and possibility, interventionist conditionals and Lewisian conditionals. We provide complexity results for the satisfiability checking and model checking problem for these modal languages. Moreover, we study the relationship between our rule-based semantics and the structural equation modeling (SEM) approach to causal reasoning, as well as between our rule-based semantics for causal conditionals and the standard semantics for belief base change.": 0.11100345849990845, "IJCAI2023>>program>>Main Track>>2147>>keywords>>keywords_2>>Knowledge Representation and Reasoning -> KRR: Causality": 0.13766658306121826, "IJCAI2023>>program>>Main Track>>2836>>keywords>>keywords_2>>Knowledge Representation and Reasoning -> KRR: Causality": 0.13780450820922852, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5906>>keywords>>keywords_3>>Knowledge Representation and Reasoning -> KRR: Causality": 0.13838797807693481, "IJCAI2023>>program>>Main Track>>4313>>keywords>>keywords_2>>Knowledge Representation and Reasoning -> KRR: Causality": 0.13847166299819946, "IJCAI2023>>program>>Main Track>>3153>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> KRR: Causality": 0.13997042179107666, "IJCAI2023>>program>>Main Track>>4799>>keywords>>keywords_3>>Knowledge Representation and Reasoning -> KRR: Causality": 0.14006668329238892, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5895>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> KRR: Causality": 0.14055359363555908, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC10>>title>>MV-Datalog+/-: Effective Rule-based Reasoning with Uncertain Observations": 0.14326989650726318, "IJCAI2023>>program>>Main Track>>479>>keywords>>keywords_2>>Machine Learning -> ML: Causality": 0.144084632396698, "IJCAI2023>>program>>Main Track>>2103>>keywords>>keywords_2>>Machine Learning -> ML: Causality": 0.14603549242019653}, "In which area does the paper 'A Rule-Based Modal View of Causal Reasoning' fall under in terms of Knowledge Representation and Reasoning?": {"IJCAI2023>>program>>Main Track>>4313>>title>>A Rule-Based Modal View of Causal Reasoning": 0.10791653394699097, "IJCAI2023>>program>>Main Track>>4313>>abstract>>We present a novel rule-based semantics for causal reasoning as well as a number of modal languages interpreted over it. They enable us to represent some fundamental concepts in the theory of causality including causal necessity and possibility, interventionist conditionals and Lewisian conditionals. We provide complexity results for the satisfiability checking and model checking problem for these modal languages. Moreover, we study the relationship between our rule-based semantics and the structural equation modeling (SEM) approach to causal reasoning, as well as between our rule-based semantics for causal conditionals and the standard semantics for belief base change.": 0.12139171361923218, "IJCAI2023>>program>>Journal Track>>J5940>>keywords>>keywords_5>>Knowledge Representation and Reasoning -> KRR: Reasoning about knowledge and belief": 0.1371402144432068, "IJCAI2023>>program>>Journal Track>>J5586>>keywords>>keywords_2>>Knowledge Representation and Reasoning -> KRR: Reasoning about knowledge and belief": 0.1387408971786499, "IJCAI2023>>program>>Main Track>>3761>>keywords>>keywords_3>>Knowledge Representation and Reasoning -> KRR: Reasoning about knowledge and belief": 0.14165472984313965, "IJCAI2023>>program>>Demonstrations Track>>DM5729>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> KRR: Reasoning about knowledge and belief": 0.14177507162094116, "IJCAI2023>>program>>Main Track>>222>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> KRR: Reasoning about knowledge and belief": 0.1418532133102417, "IJCAI2023>>program>>Main Track>>4313>>keywords>>keywords_3>>Knowledge Representation and Reasoning -> KRR: Reasoning about knowledge and belief": 0.14245754480361938}, "What is the title of the presentation under the Main Track program number 298?": {"IJCAI2023>>program>>Main Track>>2969>>authors>>authors_1>>Barath Mohan Umapathi": 0.16227960586547852, "IJCAI2023>>program>>Main Track>>1456>>title>>Bi-level Dynamic Learning  for Jointly Multi-modality Image Fusion and Beyond": 0.16429758071899414, "IJCAI2023>>program>>Main Track>>3140>>authors>>authors_3>>Matthew E. Taylor": 0.16434431076049805, "IJCAI2023>>program>>Main Track>>3978>>authors>>authors_8>>Nimrod Talmon": 0.1645514965057373, "IJCAI2023>>program>>Main Track>>3040>>title>>Dual Video Summarization: From Frames to Captions": 0.16551363468170166, "IJCAI2023>>program>>Main Track>>1875>>title>>Advancing Post-Hoc Case-Based Explanation with Feature Highlighting": 0.16599106788635254, "IJCAI2023>>program>>Main Track>>4383>>authors>>authors_5>>Aravind Srinivasan": 0.16620957851409912, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_4>>Devarajan Sridharan": 0.1663273572921753, "IJCAI2023>>program>>Main Track>>2178>>authors>>authors_3>>Ruben Solozabal Ochoa de Retana": 0.16643846035003662, "IJCAI2023>>program>>Main Track>>4518>>authors>>authors_4>>Aravind Srinivasan": 0.1670934557914734, "IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.167122483253479, "IJCAI2023>>program>>Main Track>>3139>>authors>>authors_4>>Paul W. Goldberg": 0.16726887226104736, "IJCAI2023>>program>>Main Track>>3151>>authors>>authors_5>>Radha Poovendran": 0.16771984100341797, "IJCAI2023>>program>>Main Track>>705>>title>>Some Might Say All You Need Is Sum": 0.16814887523651123, "IJCAI2023>>program>>Main Track>>1231>>title>>Rainbow Cycle Number and EFX Allocations: (Almost) Closing the Gap": 0.1683453917503357, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.16837036609649658, "IJCAI2023>>program>>Main Track>>2836>>title>>The Hardness of Reasoning about Probabilities and Causality": 0.1683727502822876, "IJCAI2023>>program>>Main Track>>398>>authors>>authors_2>>Tao Wu": 0.1684056520462036}, "Who are the authors of the presentation under the Main Track program number 298?": {"IJCAI2023>>program>>Main Track>>2969>>authors>>authors_1>>Barath Mohan Umapathi": 0.1428138017654419, "IJCAI2023>>program>>Main Track>>3978>>authors>>authors_8>>Nimrod Talmon": 0.14617353677749634, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.1467902660369873, "IJCAI2023>>program>>Main Track>>1856>>authors>>authors_1>>David Radke": 0.14782798290252686, "IJCAI2023>>program>>Main Track>>3140>>authors>>authors_3>>Matthew E. Taylor": 0.14838528633117676, "IJCAI2023>>program>>Main Track>>1812>>authors>>authors_3>>Joseph Y. Halpern": 0.14869117736816406, "IJCAI2023>>program>>Main Track>>2178>>authors>>authors_3>>Ruben Solozabal Ochoa de Retana": 0.1490277647972107, "IJCAI2023>>program>>Main Track>>3139>>authors>>authors_4>>Paul W. Goldberg": 0.1493636965751648, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_4>>Devarajan Sridharan": 0.1499444842338562, "IJCAI2023>>program>>Main Track>>3943>>authors>>authors_2>>Mark Law": 0.15062814950942993, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_2>>Richard Klein": 0.15064626932144165, "IJCAI2023>>program>>Main Track>>4636>>authors>>authors_4>>Beth A. Cimini": 0.15164148807525635, "IJCAI2023>>program>>Main Track>>398>>authors>>authors_2>>Tao Wu": 0.15235310792922974, "IJCAI2023>>program>>Main Track>>1842>>authors>>authors_2>>Caspar Oesterheld": 0.1524205207824707, "IJCAI2023>>program>>Main Track>>3139>>authors>>authors_2>>Caspar Oesterheld": 0.1527794599533081, "IJCAI2023>>program>>Main Track>>1856>>authors>>authors_2>>Kate Larson": 0.15286672115325928, "IJCAI2023>>program>>Main Track>>1957>>authors>>authors_1>>Rubens O. Moraes": 0.15289485454559326, "IJCAI2023>>program>>Main Track>>4383>>authors>>authors_5>>Aravind Srinivasan": 0.15313148498535156, "IJCAI2023>>program>>Main Track>>3138>>authors>>authors_2>>Ken Forbus": 0.1532902717590332, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.15332233905792236}, "What is the abstract of the presentation under the Main Track program number 298, and what field does it pertain to?": {"IJCAI2023>>program>>Main Track>>4431>>title>>Preferences and Constraints in Abstract Argumentation": 0.1530768871307373, "IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.15744298696517944, "IJCAI2023>>program>>Journal Track>>J5940>>title>>Incremental Event Calculus for Run-Time Reasoning (Extended Abstract)": 0.16489636898040771, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_1>>Barath Mohan Umapathi": 0.16545557975769043, "IJCAI2023>>program>>Main Track>>2836>>title>>The Hardness of Reasoning about Probabilities and Causality": 0.1662529706954956, "IJCAI2023>>program>>Main Track>>3139>>authors>>authors_4>>Paul W. Goldberg": 0.1664908528327942, "IJCAI2023>>program>>Main Track>>3140>>authors>>authors_3>>Matthew E. Taylor": 0.16667890548706055, "IJCAI2023>>program>>Main Track>>3151>>authors>>authors_1>>Abdullah Al Maruf": 0.16697967052459717, "IJCAI2023>>program>>Main Track>>4580>>authors>>authors_3>>Jorge A. Baier": 0.1672552227973938, "IJCAI2023>>program>>Main Track>>1639>>title>>Bipolar Abstract Dialectical Frameworks Are Covered by Kleene’s Three-valued Logic": 0.16813337802886963, "IJCAI2023>>program>>Main Track>>4309>>title>>Quantifying Consistency and Information Loss for Causal Abstraction Learning": 0.16828036308288574, "IJCAI2023>>program>>Main Track>>4504>>title>>Explaining Answer-Set Programs with Abstract Constraint Atoms": 0.1689165234565735, "IJCAI2023>>program>>Main Track>>3127>>authors>>authors_1>>K. Darshana Abeyrathna": 0.16930437088012695, "IJCAI2023>>program>>Main Track>>4505>>authors>>authors_2>>Abhronil Sengupta": 0.16952919960021973, "IJCAI2023>>program>>Journal Track>>J5924>>title>>A Logic-based Explanation Generation Framework for Classical and Hybrid Planning Problems (Extended Abstract)": 0.16996395587921143, "IJCAI2023>>program>>Main Track>>658>>authors>>authors_5>>Yabiao Wang": 0.17037075757980347, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_3>>Michael Katz": 0.17046332359313965, "IJCAI2023>>program>>Main Track>>1265>>authors>>authors_1>>Abhirama Subramanyam Penamakuri": 0.1705682873725891}, "What are the keywords associated with the presentation under the Main Track program number 298?": {"IJCAI2023>>program>>Main Track>>2788>>keywords>>keywords_2>>Computer Vision -> CV: Motion and tracking": 0.14618319272994995, "IJCAI2023>>program>>Main Track>>460>>keywords>>keywords_1>>Computer Vision -> CV: Motion and tracking": 0.1486973762512207, "IJCAI2023>>program>>Main Track>>2479>>keywords>>keywords_1>>Computer Vision -> CV: Motion and tracking": 0.14870023727416992, "IJCAI2023>>program>>Main Track>>2094>>keywords>>keywords_2>>Computer Vision -> CV: Motion and tracking": 0.1494743824005127, "IJCAI2023>>program>>Main Track>>1028>>keywords>>keywords_1>>Machine Learning -> ML: Optimization": 0.1495097279548645, "IJCAI2023>>program>>Main Track>>2758>>keywords>>keywords_1>>Machine Learning -> ML: Other": 0.15023881196975708, "IJCAI2023>>program>>Main Track>>1626>>keywords>>keywords_1>>Computer Vision -> CV: Motion and tracking": 0.15051472187042236, "IJCAI2023>>program>>Main Track>>3127>>keywords>>keywords_2>>Machine Learning -> ML: Other": 0.15083813667297363, "IJCAI2023>>program>>Main Track>>3357>>keywords>>keywords_1>>Computer Vision -> CV: Motion and tracking": 0.15104830265045166, "IJCAI2023>>program>>Main Track>>345>>keywords>>keywords_2>>Computer Vision -> CV: Motion and tracking": 0.15145516395568848, "IJCAI2023>>program>>Main Track>>541>>keywords>>keywords_1>>Machine Learning -> ML: Other": 0.15185850858688354, "IJCAI2023>>program>>Main Track>>3171>>keywords>>keywords_3>>Search -> S: Applications": 0.15219122171401978, "IJCAI2023>>program>>Main Track>>1953>>keywords>>keywords_1>>Computer Vision -> CV: Motion and tracking": 0.1527896523475647, "IJCAI2023>>program>>Main Track>>4152>>keywords>>keywords_2>>Machine Learning -> ML: Optimization": 0.15291547775268555, "IJCAI2023>>program>>Main Track>>1604>>keywords>>keywords_1>>Machine Learning -> ML: Feature extraction, selection and dimensionality reduction": 0.1539325714111328, "IJCAI2023>>program>>Main Track>>298>>keywords>>keywords_2>>Computer Vision -> CV: 3D computer vision": 0.15412020683288574, "IJCAI2023>>program>>Main Track>>1009>>keywords>>keywords_1>>Machine Learning -> ML: Optimization": 0.1544165015220642, "IJCAI2023>>program>>Main Track>>2998>>keywords>>keywords_1>>Machine Learning -> ML: Automated machine learning": 0.15466994047164917}, "What is the approach proposed by the authors of the presentation under the Main Track program number 298 to enhance 3D surface based on 2D normal images?": {"IJCAI2023>>program>>Main Track>>298>>title>>3D Surface Super-resolution from Enhanced 2D Normal Images: A Multimodal-driven Variational AutoEncoder Approach": 0.11528027057647705, "IJCAI2023>>program>>Main Track>>298>>abstract>>3D surface super-resolution is an important technical tool in virtual reality, and it is also a research hotspot in computer vision. Due to the unstructured and irregular nature of 3D object data, it is usually difficult to obtain high-quality surface details and geometry textures via a low-cost hardware setup. In this paper, we establish a multimodal-driven variational autoencoder (mmVAE) framework to perform 3D surface enhancement based on 2D normal images. To fully leverage the multimodal learning, we investigate a multimodal Gaussian mixture model (mmGMM) to align and fuse the latent feature representations from different modalities, and further propose a cross-scale encoder-decoder structure to reconstruct high-resolution normal images. Experimental results on several benchmark datasets demonstrate that our method delivers promising surface geometry structures and details in comparison with competitive advances.": 0.14028245210647583, "IJCAI2023>>program>>Main Track>>847>>abstract>>Recovering the shape and appearance of real-world objects from natural 2D images is a long-standing and challenging inverse rendering problem. In this paper, we introduce a novel hybrid differentiable rendering method to efficiently reconstruct the 3D geometry and reflectance of a scene from multi-view images captured by conventional hand-held cameras. Our method follows an analysis-by-synthesis approach and consists of two phases. In the initialization phase, we use traditional SfM and MVS methods to reconstruct a virtual scene roughly matching the real scene. Then in the optimization phase, we adopt a hybrid approach to refine the geometry and reflectance, where the geometry is first optimized using an approximate differentiable rendering method, and the reflectance is optimized afterward using a physically-based differentiable rendering method. Our hybrid approach combines the efficiency of approximate methods with the high-quality results of physically-based methods. Extensive experiments on synthetic and real data demonstrate that our method can produce reconstructions with similar or higher quality than state-of-the-art methods while being more efficient.": 0.14506864547729492, "IJCAI2023>>program>>Main Track>>1529>>title>>Image Composition with Depth Registration": 0.1524471640586853, "IJCAI2023>>program>>Main Track>>1593>>title>>Towards Robust Scene Text Image Super-resolution via Explicit Location Enhancement": 0.15474426746368408}, "What is the title of the paper with the ID 4306 in the main track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>4372>>authors>>authors_7>>Jun Zhou": 0.10850870609283447, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.11026030778884888, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.11093270778656006, "IJCAI2023>>program>>Main Track>>4650>>authors>>authors_5>>William Yang Wang": 0.11209237575531006, "IJCAI2023>>program>>Main Track>>3243>>authors>>authors_3>>Zhen Wang": 0.11215132474899292, "IJCAI2023>>program>>Main Track>>4195>>authors>>authors_3>>Xuan Liu": 0.1134340763092041, "IJCAI2023>>program>>Main Track>>3636>>authors>>authors_6>>Hui Xiong": 0.11368316411972046, "IJCAI2023>>program>>Main Track>>4311>>authors>>authors_1>>Jiahua Xiao": 0.11375939846038818, "IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.11396098136901855, "IJCAI2023>>program>>Main Track>>3475>>authors>>authors_4>>Jing Huang": 0.11400556564331055, "IJCAI2023>>program>>Main Track>>460>>authors>>authors_5>>Ji Zhang": 0.11429345607757568, "IJCAI2023>>program>>Main Track>>656>>authors>>authors_9>>Lijuan Wang": 0.11437350511550903, "IJCAI2023>>program>>Main Track>>5126>>authors>>authors_5>>Tian Wang": 0.11440277099609375, "IJCAI2023>>program>>Main Track>>4372>>authors>>authors_3>>Kai Zhang": 0.11450600624084473, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11455422639846802, "IJCAI2023>>program>>Main Track>>4350>>authors>>authors_3>>Gerhard Widmer": 0.11461377143859863, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_2>>Junqi Jin": 0.11467099189758301, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.11477649211883545, "IJCAI2023>>program>>Main Track>>648>>authors>>authors_7>>Jun Wang": 0.11488932371139526, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.11496931314468384, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_4>>Jing Xiao": 0.11497735977172852}, "Who are the authors of the paper titled 'Unifying Core-Guided and Implicit Hitting Set Based Optimization'?": {"IJCAI2023>>program>>Main Track>>1426>>authors>>authors_3>>Yu-Shuen Wang": 0.17549771070480347, "IJCAI2023>>program>>Main Track>>1796>>authors>>authors_3>>Guibing Guo": 0.17607492208480835, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_4>>Li Guo": 0.176097571849823, "IJCAI2023>>program>>Main Track>>4195>>authors>>authors_4>>Zhankun Xiong": 0.17619985342025757, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_1>>Yu-Xuan Huang": 0.1762133240699768, "IJCAI2023>>program>>Main Track>>721>>authors>>authors_2>>Gregory Gutin": 0.17643696069717407, "IJCAI2023>>program>>Survey Track>>SV5630>>authors>>authors_1>>Zhichun Guo": 0.1770613193511963, "IJCAI2023>>program>>Main Track>>3314>>authors>>authors_2>>Xingyi Guo": 0.17721635103225708, "IJCAI2023>>program>>Main Track>>981>>authors>>authors_4>>Hongji Zhu": 0.17737126350402832, "IJCAI2023>>program>>Main Track>>1685>>authors>>authors_8>>Minghui Yang": 0.1775922179222107, "IJCAI2023>>program>>Main Track>>3636>>authors>>authors_6>>Hui Xiong": 0.1776173710823059, "IJCAI2023>>program>>Main Track>>596>>authors>>authors_4>>Ming Xu": 0.1777045726776123, "IJCAI2023>>program>>Main Track>>586>>authors>>authors_4>>Guozheng Li": 0.17773056030273438, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.17783671617507935, "IJCAI2023>>program>>Main Track>>1593>>authors>>authors_1>>Hang Guo": 0.17797011137008667, "IJCAI2023>>program>>Main Track>>981>>authors>>authors_3>>Yuqing Wang": 0.1781940460205078, "IJCAI2023>>program>>Main Track>>3221>>authors>>authors_6>>Hui Xiong": 0.17831546068191528, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_6>>Mingxuan Wang": 0.17839688062667847, "IJCAI2023>>program>>Main Track>>1624>>authors>>authors_3>>Guojie Song": 0.17849749326705933, "IJCAI2023>>program>>Main Track>>1778>>authors>>authors_2>>Bin Guo": 0.1785925030708313}, "What is the abstract of the paper with the ID 4306 in the main track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.10935664176940918, "IJCAI2023>>program>>Main Track>>4372>>authors>>authors_7>>Jun Zhou": 0.11207818984985352, "IJCAI2023>>program>>Main Track>>658>>authors>>authors_5>>Yabiao Wang": 0.11364573240280151, "IJCAI2023>>program>>Main Track>>3243>>authors>>authors_3>>Zhen Wang": 0.11433541774749756, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.11444222927093506, "IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.11503499746322632, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.11546427011489868, "IJCAI2023>>program>>Main Track>>4148>>authors>>authors_1>>Abhinav Joshi": 0.11588633060455322, "IJCAI2023>>program>>Main Track>>4650>>authors>>authors_5>>William Yang Wang": 0.11595308780670166, "IJCAI2023>>program>>Main Track>>1242>>authors>>authors_6>>Jian Zhang": 0.11610400676727295, "IJCAI2023>>program>>Main Track>>460>>authors>>authors_5>>Ji Zhang": 0.116324782371521, "IJCAI2023>>program>>Main Track>>656>>authors>>authors_9>>Lijuan Wang": 0.11633056402206421, "IJCAI2023>>program>>Main Track>>3475>>authors>>authors_4>>Jing Huang": 0.11662685871124268, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_8>>Zhi-Hua Zhou": 0.11666250228881836, "IJCAI2023>>program>>Main Track>>2106>>authors>>authors_4>>Zhi-Hua Zhou": 0.11667764186859131, "IJCAI2023>>program>>Main Track>>648>>authors>>authors_7>>Jun Wang": 0.11678540706634521, "IJCAI2023>>program>>Main Track>>3639>>authors>>authors_3>>Zheng Wang": 0.11690109968185425, "IJCAI2023>>program>>Main Track>>774>>authors>>authors_3>>Yabiao Wang": 0.11691230535507202, "IJCAI2023>>program>>Main Track>>4372>>authors>>authors_3>>Kai Zhang": 0.11716705560684204, "IJCAI2023>>program>>Main Track>>4311>>authors>>authors_1>>Jiahua Xiao": 0.11744564771652222, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11766105890274048}, "What are the keywords associated with the paper ID 4306 in IJCAI2023?": {"IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.1116979718208313, "IJCAI2023>>program>>Journal Track>>J5920>>keywords>>keywords_2>>Data Mining -> General": 0.11312884092330933, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>keywords>>keywords_2>>General -> General": 0.11478543281555176, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.11531078815460205, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC3>>keywords>>keywords_3>>Sister Conferences Best Papers -> Humans and AI": 0.11535501480102539, "IJCAI2023>>program>>Main Track>>3955>>keywords>>keywords_3>>Search -> S: Search and machine learning": 0.116646409034729, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC25>>keywords>>keywords_1>>Sister Conferences Best Papers -> Machine Learning": 0.11773133277893066, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5756>>keywords>>keywords_1>>General -> General": 0.11780071258544922, "IJCAI2023>>program>>Journal Track>>J5940>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> General": 0.11798763275146484, "IJCAI2023>>program>>Journal Track>>J5922>>keywords>>keywords_6>>Robotics -> ROB: Cognitive robotics": 0.11807698011398315, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5901>>keywords>>keywords_1>>General -> General": 0.11819452047348022, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC12>>keywords>>keywords_4>>Sister Conferences Best Papers -> Search": 0.11832404136657715, "IJCAI2023>>program>>Main Track>>1826>>keywords>>keywords_1>>Search -> S: Search and machine learning": 0.11892855167388916, "IJCAI2023>>program>>Survey Track>>SV5587>>keywords>>keywords_2>>Survey -> Machine Learning": 0.11896806955337524, "IJCAI2023>>program>>Survey Track>>SV5639>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.11921405792236328, "IJCAI2023>>program>>Survey Track>>SV5587>>keywords>>keywords_3>>Survey -> Humans and AI": 0.11927527189254761, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.11937075853347778}, "Is the paper titled 'Unifying Core-Guided and Implicit Hitting Set Based Optimization' related to Constraint Satisfaction and Optimization?": {"IJCAI2023>>program>>Main Track>>4306>>title>>Unifying Core-Guided and Implicit Hitting Set Based Optimization": 0.09575062990188599, "IJCAI2023>>program>>Main Track>>4306>>abstract>>Two of the most central algorithmic paradigms implemented in practical solvers for maximum satisfiability (MaxSAT) and other related declarative paradigms for NP-hard combinatorial optimization are the core-guided (CG) and implicit hitting set (IHS) approaches. We develop a general unifying algorithmic framework, based on the recent notion of abstract cores, that captures both CG and IHS computations. The framework offers a unified way of establishing the correctness of variants of the approaches, and can be instantiated in novel ways giving rise to new algorithmic variants of the core-guided and IHS approaches. We illustrate the latter aspect by developing a prototype implementation of an algorithm variant for MaxSAT based on the framework.": 0.1378192901611328, "IJCAI2023>>program>>Main Track>>1068>>keywords>>keywords_2>>Constraint Satisfaction and Optimization -> CSO: Constraint optimization": 0.1396448016166687, "IJCAI2023>>program>>Main Track>>1378>>keywords>>keywords_1>>Constraint Satisfaction and Optimization -> CSO: Constraint optimization": 0.14108365774154663, "IJCAI2023>>program>>Main Track>>108>>keywords>>keywords_2>>Constraint Satisfaction and Optimization -> CSO: Constraint optimization": 0.14261597394943237, "IJCAI2023>>program>>Main Track>>1180>>keywords>>keywords_1>>Constraint Satisfaction and Optimization -> CSO: Constraint optimization": 0.14261817932128906, "IJCAI2023>>program>>Main Track>>2005>>keywords>>keywords_2>>Constraint Satisfaction and Optimization -> CSO: Constraint optimization": 0.1428312063217163, "IJCAI2023>>program>>Survey Track>>SV5648>>keywords>>keywords_2>>Survey -> Constraint Satisfaction and Optimization": 0.14284193515777588, "IJCAI2023>>program>>Main Track>>3422>>keywords>>keywords_4>>Constraint Satisfaction and Optimization -> CSO: Constraint optimization": 0.1428844928741455, "IJCAI2023>>program>>Main Track>>1379>>keywords>>keywords_1>>Constraint Satisfaction and Optimization -> CSO: Constraint optimization": 0.14305567741394043, "IJCAI2023>>program>>Survey Track>>SV5614>>keywords>>keywords_2>>Survey -> Constraint Satisfaction and Optimization": 0.1436895728111267, "IJCAI2023>>program>>Main Track>>1598>>keywords>>keywords_1>>Constraint Satisfaction and Optimization -> CSO: Constraint satisfaction": 0.14500272274017334}, "What is the title of the paper with id 1850 in the main track program of the IJCAI2023 conference?": {"IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.0948137640953064, "IJCAI2023>>program>>Main Track>>2358>>authors>>authors_2>>Hongtao Xie": 0.09800052642822266, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.09832686185836792, "IJCAI2023>>program>>Main Track>>4350>>authors>>authors_3>>Gerhard Widmer": 0.09888499975204468, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.09888941049575806, "IJCAI2023>>program>>Main Track>>5148>>authors>>authors_3>>Xiangzhou Huang": 0.0993189811706543, "IJCAI2023>>program>>Main Track>>1918>>authors>>authors_3>>Zhiwei Jiang": 0.10001116991043091, "IJCAI2023>>program>>Main Track>>3525>>authors>>authors_3>>Jiacheng Li": 0.100208580493927, "IJCAI2023>>program>>Main Track>>2611>>authors>>authors_7>>Xiaohua Xie": 0.10076075792312622, "IJCAI2023>>program>>Main Track>>3254>>authors>>authors_2>>Jihai Dong": 0.10081398487091064, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.10081881284713745, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.10082590579986572, "IJCAI2023>>program>>Main Track>>930>>authors>>authors_3>>Huajin Tang": 0.10086822509765625, "IJCAI2023>>program>>Main Track>>1065>>authors>>authors_1>>Hua Jiang": 0.10089743137359619, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_1>>Yiheng Zhu": 0.10093557834625244, "IJCAI2023>>program>>Main Track>>863>>authors>>authors_8>>Jie Chen": 0.1010284423828125, "IJCAI2023>>program>>Main Track>>1654>>authors>>authors_2>>Hongyi Wang": 0.10108166933059692, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10112202167510986, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_3>>Seyed-Mohammad Seyed-Javadi": 0.10116583108901978, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_8>>Zhi-Hua Zhou": 0.10128742456436157}, "Who are the authors of the paper 'MultiPar-T: Multiparty-Transformer for Capturing Contingent Behaviors in Group Conversations'?": {"IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.17631542682647705, "IJCAI2023>>program>>Main Track>>1812>>authors>>authors_3>>Joseph Y. Halpern": 0.17950916290283203, "IJCAI2023>>program>>Main Track>>906>>authors>>authors_1>>Mehrdad Khatir": 0.18232953548431396, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.18322539329528809, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC8>>authors>>authors_5>>Gerard de Melo": 0.18394428491592407, "IJCAI2023>>program>>Main Track>>1817>>authors>>authors_2>>Sarit Kraus": 0.18402034044265747, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC18>>authors>>authors_1>>Patricia Bouyer": 0.18450427055358887, "IJCAI2023>>program>>Main Track>>3072>>authors>>authors_1>>Margot Herin": 0.18456637859344482, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_3>>David Martins de Matos": 0.18483507633209229, "IJCAI2023>>program>>Main Track>>1223>>authors>>authors_1>>Prantik Chatterjee": 0.18513083457946777, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_2>>Nariaki Kitamura": 0.18517333269119263, "IJCAI2023>>program>>Main Track>>4206>>authors>>authors_3>>Meirav Zehavi": 0.1854851245880127, "IJCAI2023>>program>>Main Track>>1621>>authors>>authors_1>>Maria Christakis": 0.18549323081970215, "IJCAI2023>>program>>Main Track>>3139>>authors>>authors_2>>Caspar Oesterheld": 0.185910165309906, "IJCAI2023>>program>>Survey Track>>SV5648>>authors>>authors_5>>Pradeep K. Murukannaiah": 0.18595486879348755, "IJCAI2023>>program>>Survey Track>>SV5587>>authors>>authors_1>>Roberta Calegari": 0.18644040822982788, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_3>>Michael Katz": 0.18678629398345947, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC3>>authors>>authors_5>>Michael Mathioudakis": 0.18707787990570068}, "What is the abstract of the paper with id 1850 in the main track program of IJCAI2023 conference?": {"IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.09487283229827881, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10206454992294312, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_8>>Zhi-Hua Zhou": 0.10271435976028442, "IJCAI2023>>program>>Main Track>>2671>>authors>>authors_3>>Jihua Zhu": 0.10290324687957764, "IJCAI2023>>program>>Main Track>>5148>>authors>>authors_3>>Xiangzhou Huang": 0.10328108072280884, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_1>>Yiheng Zhu": 0.10333901643753052, "IJCAI2023>>program>>Main Track>>809>>authors>>authors_2>>Zhiwei Zhang": 0.10336560010910034, "IJCAI2023>>program>>Main Track>>658>>authors>>authors_5>>Yabiao Wang": 0.10340875387191772, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.10365545749664307, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.10385900735855103, "IJCAI2023>>program>>Main Track>>2358>>authors>>authors_2>>Hongtao Xie": 0.10401290655136108, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.10432541370391846, "IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.10444056987762451, "IJCAI2023>>program>>Main Track>>2869>>authors>>authors_3>>Haichao Wang": 0.10468286275863647, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_3>>Seyed-Mohammad Seyed-Javadi": 0.10492563247680664, "IJCAI2023>>program>>Main Track>>1065>>authors>>authors_1>>Hua Jiang": 0.10540896654129028, "IJCAI2023>>program>>Main Track>>3151>>authors>>authors_1>>Abdullah Al Maruf": 0.10545861721038818, "IJCAI2023>>program>>Main Track>>3525>>authors>>authors_3>>Jiacheng Li": 0.10545897483825684, "IJCAI2023>>program>>Main Track>>1654>>authors>>authors_2>>Hongyi Wang": 0.10548144578933716, "IJCAI2023>>program>>Main Track>>2562>>authors>>authors_3>>Zhengkui Wang": 0.10551685094833374}, "In which categories does the paper 'MultiPar-T: Multiparty-Transformer for Capturing Contingent Behaviors in Group Conversations' fall under?": {"IJCAI2023>>program>>Main Track>>1850>>title>>MultiPar-T: Multiparty-Transformer for Capturing Contingent Behaviors in Group Conversations": 0.0973014235496521, "IJCAI2023>>program>>Main Track>>1850>>abstract>>As we move closer to real-world social AI systems, AI agents must be able to deal with multiparty (group) conversations. Recognizing and interpreting multiparty behaviors is challenging, as the system must recognize individual behavioral cues, deal with the complexity of multiple streams of data from multiple people, and recognize the subtle contingent social exchanges that take place amongst group members. To tackle this challenge, we propose the Multiparty-Transformer (Multipar- T), a transformer model for multiparty behavior modeling. The core component of our proposed approach is Crossperson Attention, which is specifically designed to detect contingent behavior between pairs of people. We verify the effectiveness of Multipar-T on a publicly available video-based group engagement detection benchmark, where it outperforms state-of-the-art approaches in average F-1 scores by 5.2% and individual class F-1 scores by up to 10.0%. Through qualitative analysis, we show that our Crossperson Attention module is able to discover contingent behaviors.": 0.10959988832473755, "IJCAI2023>>program>>Main Track>>174>>title>>Scalable Communication for Multi-Agent Reinforcement Learning via Transformer-Based Email Mechanism": 0.174152672290802, "IJCAI2023>>program>>Survey Track>>SV5654>>abstract>>Recently, speech-to-text translation has attracted more and more attention and many studies have emerged rapidly. In this paper, we present a comprehensive survey on direct speech translation aiming to summarize the current state-of-the-art techniques. First, we categorize the existing research work into three directions based on the main challenges — modeling burden, data scarcity, and application issues. To tackle the problem of modeling burden, two main structures have been proposed, encoder-decoder framework (Transformer and the variants) and multitask frameworks. For the challenge of data scarcity, recent work resorts to many sophisticated techniques, such as data augmentation, pre-training, knowledge distillation, and multilingual modeling. We analyze and summarize the application issues, which include real-time, segmentation, named entity, gender bias, and code-switching. Finally, we discuss some promising directions for future work.": 0.17679119110107422}, "What is the main feature of the Multipar-T proposed in the 'MultiPar-T: Multiparty-Transformer for Capturing Contingent Behaviors in Group Conversations' paper?": {"IJCAI2023>>program>>Main Track>>1850>>title>>MultiPar-T: Multiparty-Transformer for Capturing Contingent Behaviors in Group Conversations": 0.08221304416656494, "IJCAI2023>>program>>Main Track>>1850>>abstract>>As we move closer to real-world social AI systems, AI agents must be able to deal with multiparty (group) conversations. Recognizing and interpreting multiparty behaviors is challenging, as the system must recognize individual behavioral cues, deal with the complexity of multiple streams of data from multiple people, and recognize the subtle contingent social exchanges that take place amongst group members. To tackle this challenge, we propose the Multiparty-Transformer (Multipar- T), a transformer model for multiparty behavior modeling. The core component of our proposed approach is Crossperson Attention, which is specifically designed to detect contingent behavior between pairs of people. We verify the effectiveness of Multipar-T on a publicly available video-based group engagement detection benchmark, where it outperforms state-of-the-art approaches in average F-1 scores by 5.2% and individual class F-1 scores by up to 10.0%. Through qualitative analysis, we show that our Crossperson Attention module is able to discover contingent behaviors.": 0.0847083330154419, "IJCAI2023>>program>>Main Track>>1100>>abstract>>This paper studies multiparty learning, aiming to learn a model using the private data of different participants. Model reuse is a promising solution for multiparty learning, assuming that a local model has been trained for each party. Considering the potential sample selection bias among different parties, some heterogeneous model reuse approaches have been developed. However, although pre-trained local classifiers are utilized in these approaches, the characteristics of the local data are not well exploited. This motivates us to estimate the density of local data and design an auxiliary model together with the local classifiers for reuse. To address the scenarios where some local models are not well pre-trained, we further design a multiparty cross-entropy loss for calibration. Upon existing works, we address a challenging problem of heterogeneous model reuse from a decision theory perspective and take advantage of recent advances in density estimation. Experimental results on both synthetic and benchmark data demonstrate the superiority of the proposed method.": 0.16499364376068115}, "What is the title of the paper with id 223 in the Main Track program for IJCAI2023?": {"IJCAI2023>>program>>Main Track>>223>>authors>>authors_6>>Zhiwei Xiong": 0.09480834007263184, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.0984504222869873, "IJCAI2023>>program>>Main Track>>2228>>authors>>authors_3>>Xuan Wang": 0.10020619630813599, "IJCAI2023>>program>>Main Track>>2358>>authors>>authors_2>>Hongtao Xie": 0.10132801532745361, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.10261201858520508, "IJCAI2023>>program>>Main Track>>223>>authors>>authors_5>>Tianzhu Zhang": 0.10282105207443237, "IJCAI2023>>program>>Main Track>>3222>>authors>>authors_5>>Ji Li": 0.1029927134513855, "IJCAI2023>>program>>Main Track>>3243>>authors>>authors_3>>Zhen Wang": 0.1030227541923523, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10316658020019531, "IJCAI2023>>program>>Main Track>>2225>>authors>>authors_2>>Wei Huang": 0.10353010892868042, "IJCAI2023>>program>>Main Track>>3221>>authors>>authors_6>>Hui Xiong": 0.10429161787033081, "IJCAI2023>>program>>Main Track>>2144>>authors>>authors_1>>Hao-Tian Li": 0.10435372591018677, "IJCAI2023>>program>>Main Track>>2250>>authors>>authors_6>>Zhixiang Huang": 0.10438013076782227, "IJCAI2023>>program>>Main Track>>3281>>authors>>authors_3>>Jie Qiao": 0.10448777675628662, "IJCAI2023>>program>>Main Track>>1242>>authors>>authors_6>>Jian Zhang": 0.10450071096420288, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10475528240203857, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_4>>Yu Xiang": 0.10475903749465942, "IJCAI2023>>program>>Main Track>>3525>>authors>>authors_3>>Jiacheng Li": 0.10508668422698975, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.10516345500946045, "IJCAI2023>>program>>Main Track>>223>>authors>>authors_1>>Rui Sun": 0.1051781177520752, "IJCAI2023>>program>>Main Track>>2296>>authors>>authors_3>>Yuqi Liang": 0.10528051853179932}, "Who are the authors of the paper about Connectome Reconstruction in the IJCAI2023 conference?": {"IJCAI2023>>program>>Main Track>>1679>>authors>>authors_2>>Markus Nissl": 0.14320653676986694, "IJCAI2023>>program>>Main Track>>2676>>authors>>authors_3>>Jean Christoph Jung": 0.1480088233947754, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.14825040102005005, "IJCAI2023>>program>>Main Track>>4732>>authors>>authors_2>>Peter Jung": 0.1497601866722107, "IJCAI2023>>program>>Main Track>>4062>>authors>>authors_2>>Simon Krogmann": 0.14979177713394165, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC26>>authors>>authors_1>>Sander J.J. Leemans": 0.14984160661697388, "IJCAI2023>>program>>Main Track>>1223>>authors>>authors_2>>Jose Campos": 0.15007776021957397, "IJCAI2023>>program>>Main Track>>5281>>authors>>authors_1>>Conghao Xiong": 0.15010178089141846, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC14>>authors>>authors_1>>Victor Gutierrez-Basulto": 0.15057867765426636, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5917>>authors>>authors_1>>Joachim Baumann": 0.15089887380599976, "IJCAI2023>>program>>Main Track>>2459>>authors>>authors_3>>Thomas Schiex": 0.15136396884918213, "IJCAI2023>>program>>Main Track>>1626>>authors>>authors_5>>Marius Cordts": 0.15153276920318604, "IJCAI2023>>program>>Main Track>>607>>authors>>authors_6>>Jiming Chen": 0.151553213596344, "IJCAI2023>>program>>Main Track>>2989>>authors>>authors_1>>Chenghao Dong": 0.15189868211746216, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_3>>David Martins de Matos": 0.152022123336792, "IJCAI2023>>program>>Main Track>>4601>>authors>>authors_1>>Simon Wietheger": 0.15209561586380005, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC10>>authors>>authors_2>>Matthias Lanzinger": 0.15223491191864014, "IJCAI2023>>program>>Main Track>>619>>authors>>authors_3>>Xin Wang": 0.15244752168655396, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.15264832973480225}, "What are the challenges faced in neural connectivity reconstruction as discussed in the paper?": {"IJCAI2023>>program>>Main Track>>223>>abstract>>Neural connectivity reconstruction aims to understand the function of biological reconstruction and promote basic scientific research. The intricate morphology and densely intertwined branches make it an extremely challenging task. Most previous best-performing methods adopt affinity learning or metric learning. Nevertheless, they either neglect to model explicit voxel semantics caused by implicit optimization or are hysteresis to spatial information. Furthermore, the inherent locality of 3D CNNs limits modeling long-range dependencies, leading to sub-optimal results. In this work, we propose a coherent and unified Appearance Prompt Vision Transformer (APViT) to integrate affinity and metric learning to exploit the complementarity by learning long-range spatial dependencies. The proposed APViT enjoys several merits. First, the extension continuity-aware attention module aims at constructing hierarchical attention customized for neuron extensibility and slice continuity to learn instance voxel semantic context from a global perspective and utilize continuity priors to enhance voxel spatial awareness. Second, the appearance prompt modulator is responsible for leveraging voxel-adaptive appearance knowledge conditioned on affinity rich in spatial information to instruct instance voxel semantics, exploiting the potential of affinity learning to complement metric learning. Extensive experimental results on multiple challenging benchmarks demonstrate that our APViT achieves consistent improvements with huge flexibility under the same post-processing strategy.": 0.16135060787200928, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5856>>abstract>>Deep neural networks (DNNs) have gained huge attention over the last several years due to their promising results in various tasks. However, due to their large model size and over-parameterization, they are recognized as being computationally demanding. Therefore, deep learning models are not well-suited to applications with limited computational resources and battery life. Current solutions to reduce computation costs mainly focus on inference efficiency while being resource-intensive during training. This Ph.D. research aims to address these challenges by developing cost-effective neural networks that can achieve decent performance on various complex tasks using minimum computational resources during training and inference of the network.": 0.1800367832183838, "IJCAI2023>>program>>Main Track>>223>>title>>Appearance Prompt Vision Transformer for Connectome Reconstruction": 0.18585336208343506}, "What is the proposed solution to the challenges faced in neural connectivity reconstruction in the research paper?": {"IJCAI2023>>program>>Main Track>>223>>abstract>>Neural connectivity reconstruction aims to understand the function of biological reconstruction and promote basic scientific research. The intricate morphology and densely intertwined branches make it an extremely challenging task. Most previous best-performing methods adopt affinity learning or metric learning. Nevertheless, they either neglect to model explicit voxel semantics caused by implicit optimization or are hysteresis to spatial information. Furthermore, the inherent locality of 3D CNNs limits modeling long-range dependencies, leading to sub-optimal results. In this work, we propose a coherent and unified Appearance Prompt Vision Transformer (APViT) to integrate affinity and metric learning to exploit the complementarity by learning long-range spatial dependencies. The proposed APViT enjoys several merits. First, the extension continuity-aware attention module aims at constructing hierarchical attention customized for neuron extensibility and slice continuity to learn instance voxel semantic context from a global perspective and utilize continuity priors to enhance voxel spatial awareness. Second, the appearance prompt modulator is responsible for leveraging voxel-adaptive appearance knowledge conditioned on affinity rich in spatial information to instruct instance voxel semantics, exploiting the potential of affinity learning to complement metric learning. Extensive experimental results on multiple challenging benchmarks demonstrate that our APViT achieves consistent improvements with huge flexibility under the same post-processing strategy.": 0.14666426181793213, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5856>>abstract>>Deep neural networks (DNNs) have gained huge attention over the last several years due to their promising results in various tasks. However, due to their large model size and over-parameterization, they are recognized as being computationally demanding. Therefore, deep learning models are not well-suited to applications with limited computational resources and battery life. Current solutions to reduce computation costs mainly focus on inference efficiency while being resource-intensive during training. This Ph.D. research aims to address these challenges by developing cost-effective neural networks that can achieve decent performance on various complex tasks using minimum computational resources during training and inference of the network.": 0.1681235432624817}, "What are the key advantages of the Appearance Prompt Vision Transformer (APViT) as discussed in the paper?": {"IJCAI2023>>program>>Main Track>>223>>abstract>>Neural connectivity reconstruction aims to understand the function of biological reconstruction and promote basic scientific research. The intricate morphology and densely intertwined branches make it an extremely challenging task. Most previous best-performing methods adopt affinity learning or metric learning. Nevertheless, they either neglect to model explicit voxel semantics caused by implicit optimization or are hysteresis to spatial information. Furthermore, the inherent locality of 3D CNNs limits modeling long-range dependencies, leading to sub-optimal results. In this work, we propose a coherent and unified Appearance Prompt Vision Transformer (APViT) to integrate affinity and metric learning to exploit the complementarity by learning long-range spatial dependencies. The proposed APViT enjoys several merits. First, the extension continuity-aware attention module aims at constructing hierarchical attention customized for neuron extensibility and slice continuity to learn instance voxel semantic context from a global perspective and utilize continuity priors to enhance voxel spatial awareness. Second, the appearance prompt modulator is responsible for leveraging voxel-adaptive appearance knowledge conditioned on affinity rich in spatial information to instruct instance voxel semantics, exploiting the potential of affinity learning to complement metric learning. Extensive experimental results on multiple challenging benchmarks demonstrate that our APViT achieves consistent improvements with huge flexibility under the same post-processing strategy.": 0.15238970518112183, "IJCAI2023>>program>>Main Track>>435>>abstract>>Despite the popularity of Vision Transformers (ViTs) and eXplainable AI (XAI), only a few explanation methods have been designed specially for ViTs thus far. They mostly use attention weights of the [CLS] token on patch embeddings and often produce unsatisfactory saliency maps. This paper proposes a novel method for explaining ViTs called ViT-CX. It is based on patch embeddings, rather than attentions paid to them, and their causal impacts on the model output. Other characteristics of ViTs such as causal overdetermination are considered in the design of ViT-CX. The empirical results show that ViT-CX produces more meaningful saliency maps and does a better job revealing all important evidence for the predictions than previous methods. The explanation generated by ViT-CX also shows significantly better faithfulness to the model. The codes and appendix are available at https://github.com/vaynexie/CausalX-ViT.": 0.15830397605895996, "IJCAI2023>>program>>Main Track>>223>>title>>Appearance Prompt Vision Transformer for Connectome Reconstruction": 0.15942561626434326}, "What is the title of the Journal J5942 in IJCAI2023?": {"IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.10561937093734741, "IJCAI2023>>program>>Journal Track>>J5922>>title>>Creative Problem Solving in Artificially Intelligent Agents: A Survey and Framework (Extended Abstract)": 0.10808193683624268, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.1094522476196289, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_2>>Deyi Xiong": 0.1099589467048645, "IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.11215817928314209, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.11228352785110474, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.11310982704162598, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_1>>Zhiyuan Zeng": 0.11567884683609009, "IJCAI2023>>program>>Journal Track>>J5940>>authors>>authors_2>>Alexander Artikis": 0.11591362953186035, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_2>>Alexey Ignatiev": 0.11599445343017578, "IJCAI2023>>program>>Journal Track>>J5939>>title>>A Survey of Methods for Automated Algorithm Configuration (Extended Abstract)": 0.1160581111907959, "IJCAI2023>>program>>Journal Track>>J5946>>authors>>authors_1>>Farhad Mohsin": 0.11654198169708252, "IJCAI2023>>program>>Journal Track>>J5922>>authors>>authors_2>>Lakshmi Nair": 0.11689198017120361, "IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.1170310378074646, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.11711466312408447, "IJCAI2023>>program>>Journal Track>>J5946>>authors>>authors_5>>Lirong Xia": 0.11742258071899414, "IJCAI2023>>program>>Journal Track>>J5688>>title>>Rethinking Formal Models of Partially Observable Multiagent Decision Making (Extended Abstract)": 0.11744338274002075, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_1>>Sriram Ganapathi Subramanian": 0.11824357509613037}, "Who are the authors of the journal J5942 in the IJCAI2023 program?": {"IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.0938226580619812, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_2>>Deyi Xiong": 0.09386014938354492, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.09595084190368652, "IJCAI2023>>program>>Journal Track>>J5922>>authors>>authors_2>>Lakshmi Nair": 0.09597831964492798, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.09671777486801147, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.0969095230102539, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.09784036874771118, "IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.0984581708908081, "IJCAI2023>>program>>Journal Track>>J5926>>authors>>authors_2>>Vadim Indelman": 0.09873402118682861, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_2>>Alexey Ignatiev": 0.09910005331039429, "IJCAI2023>>program>>Journal Track>>J5946>>authors>>authors_2>>Ao Liu": 0.10027599334716797, "IJCAI2023>>program>>Main Track>>1242>>authors>>authors_6>>Jian Zhang": 0.10028624534606934, "IJCAI2023>>program>>Journal Track>>J5946>>authors>>authors_1>>Farhad Mohsin": 0.1003914475440979, "IJCAI2023>>program>>Journal Track>>J5940>>authors>>authors_2>>Alexander Artikis": 0.10160410404205322, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.10163837671279907, "IJCAI2023>>program>>Main Track>>586>>authors>>authors_2>>Jiafeng Xie": 0.10205775499343872, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_1>>Zhiyuan Zeng": 0.1024135947227478, "IJCAI2023>>program>>Main Track>>2676>>authors>>authors_3>>Jean Christoph Jung": 0.10243868827819824, "IJCAI2023>>program>>Main Track>>892>>authors>>authors_6>>Xiangyang Ji": 0.10249269008636475, "IJCAI2023>>program>>Main Track>>2883>>authors>>authors_2>>Jiaxin Yang": 0.10263299942016602}, "What is the main subject of the journal J5942 in the IJCAI2023 program?": {"IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10920113325119019, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10975807905197144, "IJCAI2023>>program>>Main Track>>1242>>authors>>authors_6>>Jian Zhang": 0.11016571521759033, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.1112019419670105, "IJCAI2023>>program>>Main Track>>1068>>authors>>authors_1>>Hua Jiang": 0.11193442344665527, "IJCAI2023>>program>>Main Track>>3352>>authors>>authors_7>>Jiazhong Chen": 0.11209297180175781, "IJCAI2023>>program>>Main Track>>3475>>authors>>authors_4>>Jing Huang": 0.11237448453903198, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.11242473125457764, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.11249005794525146, "IJCAI2023>>program>>Main Track>>3639>>authors>>authors_5>>Jia Wu": 0.11255061626434326, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11273795366287231, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_8>>Jian Wu": 0.11275619268417358, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.11304646730422974, "IJCAI2023>>program>>Main Track>>1065>>authors>>authors_1>>Hua Jiang": 0.11306953430175781, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_6>>Ji Liu": 0.11311429738998413, "IJCAI2023>>program>>Main Track>>2883>>authors>>authors_2>>Jiaxin Yang": 0.11320602893829346, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.11323869228363037, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.11332517862319946, "IJCAI2023>>program>>Main Track>>3222>>authors>>authors_5>>Ji Li": 0.11333173513412476, "IJCAI2023>>program>>Main Track>>892>>authors>>authors_6>>Xiangyang Ji": 0.11338663101196289, "IJCAI2023>>program>>Main Track>>2816>>authors>>authors_1>>Jiangjiang Zhao": 0.11356401443481445}, "What are the keywords associated with Journal J5942 in IJCAI2023?": {"IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.08976048231124878, "IJCAI2023>>program>>Journal Track>>J5920>>keywords>>keywords_2>>Data Mining -> General": 0.09602862596511841, "IJCAI2023>>program>>Journal Track>>J5940>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> General": 0.09750604629516602, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.09757626056671143, "IJCAI2023>>program>>Journal Track>>J5935>>keywords>>keywords_5>>Search -> S: Applications": 0.1007232666015625, "IJCAI2023>>program>>Journal Track>>J5944>>keywords>>keywords_2>>Knowledge Representation and Reasoning -> General": 0.10166603326797485, "IJCAI2023>>program>>Journal Track>>J5937>>keywords>>keywords_7>>Machine Learning -> ML: Classification": 0.1034584641456604, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>keywords>>keywords_2>>General -> General": 0.10609889030456543, "IJCAI2023>>program>>Journal Track>>J5920>>keywords>>keywords_1>>AI Ethics, Trust, Fairness -> General": 0.10610091686248779, "IJCAI2023>>program>>Journal Track>>J5919>>keywords>>keywords_1>>Machine Learning -> ML: Applications": 0.10631418228149414, "IJCAI2023>>program>>Journal Track>>J5922>>keywords>>keywords_6>>Robotics -> ROB: Cognitive robotics": 0.10632145404815674, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_1>>Planning": 0.10655826330184937, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5901>>keywords>>keywords_1>>General -> General": 0.10872822999954224, "IJCAI2023>>program>>Journal Track>>J5935>>keywords>>keywords_6>>Search -> S: Combinatorial search and optimisation": 0.10899174213409424, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5756>>keywords>>keywords_1>>General -> General": 0.10899621248245239, "IJCAI2023>>program>>Journal Track>>J5923>>keywords>>keywords_2>>AI Ethics, Trust, Fairness -> General": 0.10906857252120972, "IJCAI2023>>program>>Journal Track>>J5935>>keywords>>keywords_7>>Search -> S: Heuristic search": 0.10933613777160645, "IJCAI2023>>program>>Journal Track>>J5922>>keywords>>keywords_2>>Humans and AI -> HAI: Cognitive systems": 0.10951113700866699}, "What problem are the authors addressing in Journal J5942 in IJCAI2023?": {"IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_1>>Sriram Ganapathi Subramanian": 0.12432271242141724, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_2>>Deyi Xiong": 0.12447631359100342, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.12521255016326904, "IJCAI2023>>program>>Journal Track>>J5922>>authors>>authors_2>>Lakshmi Nair": 0.1252925992012024, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.1263483166694641, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.12661510705947876, "IJCAI2023>>program>>Journal Track>>J5946>>authors>>authors_1>>Farhad Mohsin": 0.12926578521728516, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.12929928302764893, "IJCAI2023>>program>>Journal Track>>J5940>>authors>>authors_2>>Alexander Artikis": 0.12979108095169067, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_2>>Alexey Ignatiev": 0.12995827198028564, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_1>>Zhiyuan Zeng": 0.13008683919906616, "IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.13095778226852417, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.1312882900238037, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.13141870498657227, "IJCAI2023>>program>>Journal Track>>J5946>>authors>>authors_5>>Lirong Xia": 0.13231182098388672, "IJCAI2023>>program>>Journal Track>>J5926>>authors>>authors_2>>Vadim Indelman": 0.1324746012687683, "IJCAI2023>>program>>Journal Track>>J5946>>authors>>authors_2>>Ao Liu": 0.1328829526901245, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.13293927907943726, "IJCAI2023>>program>>Main Track>>1242>>authors>>authors_6>>Jian Zhang": 0.13355594873428345}, "What is the title of the paper with the ID 1009 in the main track of the IJCAI2023 program?": {"IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.10428643226623535, "IJCAI2023>>program>>Main Track>>1068>>authors>>authors_1>>Hua Jiang": 0.10437673330307007, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10483443737030029, "IJCAI2023>>program>>Main Track>>1137>>authors>>authors_8>>Jian Wu": 0.10588598251342773, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.1060858964920044, "IJCAI2023>>program>>Main Track>>656>>authors>>authors_9>>Lijuan Wang": 0.1063644289970398, "IJCAI2023>>program>>Main Track>>1099>>authors>>authors_2>>Tian-Jing Zhang": 0.10653311014175415, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_8>>Jian Wu": 0.10656124353408813, "IJCAI2023>>program>>Main Track>>2611>>authors>>authors_7>>Xiaohua Xie": 0.10674381256103516, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.10679048299789429, "IJCAI2023>>program>>Main Track>>1065>>authors>>authors_1>>Hua Jiang": 0.1071053147315979, "IJCAI2023>>program>>Main Track>>1242>>authors>>authors_6>>Jian Zhang": 0.10738176107406616, "IJCAI2023>>program>>Main Track>>3636>>authors>>authors_6>>Hui Xiong": 0.10802638530731201, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10819846391677856, "IJCAI2023>>program>>Main Track>>3639>>authors>>authors_5>>Jia Wu": 0.10827696323394775, "IJCAI2023>>program>>Main Track>>981>>authors>>authors_4>>Hongji Zhu": 0.10827720165252686, "IJCAI2023>>program>>Main Track>>3434>>authors>>authors_3>>Yijia Ruan": 0.10848844051361084, "IJCAI2023>>program>>Main Track>>892>>authors>>authors_6>>Xiangyang Ji": 0.10864514112472534, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_8>>Zhi-Hua Zhou": 0.1089712381362915, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.10901302099227905, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.10901772975921631}, "Who are the authors of the paper titled 'Dynamic Flows on Curved Space Generated by Labeled Data'?": {"IJCAI2023>>program>>Survey Track>>SV5639>>authors>>authors_2>>Lu Cheng": 0.17664670944213867, "IJCAI2023>>program>>Survey Track>>SV5593>>authors>>authors_1>>Chengyi Liu": 0.1770525574684143, "IJCAI2023>>program>>Survey Track>>SV5614>>authors>>authors_2>>Elias B. Khalil": 0.17976176738739014, "IJCAI2023>>program>>Main Track>>3395>>authors>>authors_6>>Mark Dras": 0.18011128902435303, "IJCAI2023>>program>>Main Track>>1194>>authors>>authors_4>>Yingda Lyu": 0.18107694387435913, "IJCAI2023>>program>>Survey Track>>SV5487>>authors>>authors_3>>Yuandou Wang": 0.18108773231506348, "IJCAI2023>>program>>Survey Track>>SV5619>>authors>>authors_4>>John C. S. Lui": 0.18115001916885376, "IJCAI2023>>program>>Main Track>>880>>authors>>authors_3>>Cheng-Lin Liu": 0.1814449429512024, "IJCAI2023>>program>>Survey Track>>SV5644>>authors>>authors_2>>Ming Liu": 0.18165898323059082, "IJCAI2023>>program>>Main Track>>1426>>authors>>authors_2>>Yuan-Kui Li": 0.18241596221923828, "IJCAI2023>>program>>Main Track>>2612>>authors>>authors_2>>Feng Lu": 0.18246275186538696, "IJCAI2023>>program>>Survey Track>>SV5484>>authors>>authors_3>>Jia Wu": 0.1826818585395813, "IJCAI2023>>program>>Survey Track>>SV5569>>authors>>authors_6>>Jianxin Li": 0.1829478144645691, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_6>>Mingxuan Wang": 0.18309944868087769, "IJCAI2023>>program>>Survey Track>>SV5563>>authors>>authors_4>>Xindong Wu": 0.1832714080810547, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_1>>Chen Xu": 0.18346452713012695, "IJCAI2023>>program>>Survey Track>>SV5666>>authors>>authors_1>>Chaoning Zhang": 0.1835193634033203, "IJCAI2023>>program>>Main Track>>1817>>authors>>authors_3>>Lu Feng": 0.18374007940292358, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_4>>Chengqi Zhao": 0.1840498447418213, "IJCAI2023>>program>>Survey Track>>SV5593>>authors>>authors_6>>Hui Liu": 0.1841822862625122}, "What is the abstract of the paper with the ID 1009?": {"IJCAI2023>>program>>Journal Track>>J5922>>title>>Creative Problem Solving in Artificially Intelligent Agents: A Survey and Framework (Extended Abstract)": 0.16943657398223877, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC9>>abstract>>unkonwn": 0.16968458890914917, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.17122983932495117, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC19>>abstract>>unkonwn": 0.17316704988479614, "IJCAI2023>>program>>Journal Track>>J5939>>title>>A Survey of Methods for Automated Algorithm Configuration (Extended Abstract)": 0.1733761429786682, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC8>>abstract>>unkonwn": 0.17370200157165527, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC11>>abstract>>unkonwn": 0.17387378215789795, "IJCAI2023>>program>>Journal Track>>J5552>>title>>A Computational Model of Ostrom’s Institutional Analysis and Development Framework (Extended Abstract)": 0.17452377080917358, "IJCAI2023>>program>>Journal Track>>J5688>>title>>Rethinking Formal Models of Partially Observable Multiagent Decision Making (Extended Abstract)": 0.17483127117156982, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC14>>abstract>>unkonwn": 0.17484122514724731, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC5>>abstract>>unkonwn": 0.17520934343338013, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC16>>abstract>>unkonwn": 0.17539739608764648, "IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.17567986249923706, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC1>>abstract>>unkonwn": 0.1757746934890747, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC24>>abstract>>unkonwn": 0.17599648237228394, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC4>>abstract>>unkonwn": 0.17604798078536987, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC13>>abstract>>unkonwn": 0.17637193202972412, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC23>>abstract>>unkonwn": 0.176530122756958}, "What are the keywords associated with the paper titled 'Dynamic Flows on Curved Space Generated by Labeled Data'?": {"IJCAI2023>>program>>Main Track>>1009>>title>>Dynamic Flows on Curved Space Generated by Labeled Data": 0.09157449007034302, "IJCAI2023>>program>>Main Track>>1009>>abstract>>The scarcity of labeled data is a long-standing challenge for many machine learning tasks. We propose our gradient flow method to leverage the existing dataset (i.e., source) to generate new samples that are close to the dataset of interest (i.e., target). We lift both datasets to the space of probability distributions on the feature-Gaussian manifold, and then develop a gradient flow method that minimizes the maximum mean discrepancy loss. To perform the gradient flow of distributions on the curved feature-Gaussian space, we unravel the Riemannian structure of the space and compute explicitly the  Riemannian gradient of the loss function induced by the optimal transport metric. For practical applications, we also propose a discretized flow, and provide conditional results guaranteeing the global convergence of the flow to the optimum. We illustrate the results of our proposed gradient flow method on several real-world datasets and show our method can improve the accuracy of classification models in transfer learning settings.": 0.15719491243362427, "IJCAI2023>>program>>Journal Track>>J5927>>keywords>>keywords_1>>Machine Learning -> ML: Time series and data streams": 0.16787737607955933, "IJCAI2023>>program>>Survey Track>>SV5587>>keywords>>keywords_2>>Survey -> Machine Learning": 0.1683763861656189, "IJCAI2023>>program>>Main Track>>1274>>keywords>>keywords_3>>Machine Learning -> ML: Time series and data streams": 0.16849958896636963, "IJCAI2023>>program>>Main Track>>3254>>keywords>>keywords_3>>Machine Learning -> ML: Time series and data streams": 0.16946077346801758, "IJCAI2023>>program>>Main Track>>3434>>keywords>>keywords_2>>Machine Learning -> ML: Time series and data streams": 0.16963738203048706, "IJCAI2023>>program>>Survey Track>>SV5619>>keywords>>keywords_1>>Survey -> Machine Learning": 0.16976863145828247, "IJCAI2023>>program>>Survey Track>>SV5614>>keywords>>keywords_1>>Survey -> Machine Learning": 0.1697978973388672, "IJCAI2023>>program>>Survey Track>>SV5488>>keywords>>keywords_2>>Survey -> Machine Learning": 0.17001819610595703, "IJCAI2023>>program>>Survey Track>>SV5579>>keywords>>keywords_1>>Survey -> Machine Learning": 0.17012536525726318}, "Does the paper with ID 1009 have a solution to the scarcity of labeled data?": {"IJCAI2023>>program>>Main Track>>1009>>abstract>>The scarcity of labeled data is a long-standing challenge for many machine learning tasks. We propose our gradient flow method to leverage the existing dataset (i.e., source) to generate new samples that are close to the dataset of interest (i.e., target). We lift both datasets to the space of probability distributions on the feature-Gaussian manifold, and then develop a gradient flow method that minimizes the maximum mean discrepancy loss. To perform the gradient flow of distributions on the curved feature-Gaussian space, we unravel the Riemannian structure of the space and compute explicitly the  Riemannian gradient of the loss function induced by the optimal transport metric. For practical applications, we also propose a discretized flow, and provide conditional results guaranteeing the global convergence of the flow to the optimum. We illustrate the results of our proposed gradient flow method on several real-world datasets and show our method can improve the accuracy of classification models in transfer learning settings.": 0.1745535135269165, "IJCAI2023>>program>>Main Track>>4636>>abstract>>Various strategies for label-scarce object detection have been explored by the computer vision research community. These strategies mainly rely on assumptions that are specific to natural images and not directly applicable to the biological and biomedical vision domains. In this work, we frame a crucial problem in spatial transcriptomics – decoding barcodes from In-Situ-Sequencing (ISS) images – as a semi-supervised object detection (SSOD) problem. Most SSOD strategies rely on a small set of labeled data as a confident source of ground truth in a semi-supervised learning setting.  In many biological vision applications, however, the ground truth is unknown and indirect information might be available in the form of noisy estimations or orthogonal evidence. Our proposed framework incorporates additional available sources of information into a semi-supervised learning framework in the form of privileged information. The privileged information is incorporated into the teacher’s pseudo-labeling in a teacher-student self-training iteration. Although the available privileged information could be data domain specific, we have introduced a general strategy of pseudo-labeling enhanced by privileged information (PLePI) and exemplified the concept using ISS images, as well the COCO benchmark using extra evidence provided by CLIP.": 0.17544078826904297}, "What is the title of the paper AI4SG5788 in the special track on AI for Good at IJCAI 2023?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5888>>authors>>authors_4>>Ganesh Ramakrishnan": 0.07641887664794922, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5458>>authors>>authors_8>>Jianguang Zheng": 0.07681703567504883, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.07819265127182007, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5763>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.07833415269851685, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>keywords>>keywords_3>>AI for Good -> Multidisciplinary Topics and Applications": 0.07875359058380127, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5813>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.07888597249984741, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5823>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.07894891500473022, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5818>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.07897907495498657, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5682>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.07903152704238892, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5682>>authors>>authors_7>>Raghavan Srinivasan": 0.07907527685165405, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5782>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.07910019159317017, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5761>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.07914775609970093, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5783>>keywords>>keywords_3>>AI for Good -> Multidisciplinary Topics and Applications": 0.07915246486663818, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5787>>keywords>>keywords_2>>AI for Good -> Humans and AI": 0.07918035984039307}, "Who are the authors of the paper AI4SG5788 presented at IJCAI 2023?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5787>>authors>>authors_2>>Richard Jiang": 0.1069449782371521, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5772>>authors>>authors_1>>Han Wang": 0.11257976293563843, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>authors>>authors_1>>Claudio S. Pinhanez": 0.11278247833251953, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5682>>authors>>authors_6>>Michael Jacobs": 0.11309182643890381, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5840>>authors>>authors_6>>Jiageng Wu": 0.1143602728843689, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5458>>authors>>authors_8>>Jianguang Zheng": 0.11443555355072021, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5755>>authors>>authors_3>>Changjun Jiang": 0.11471295356750488, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5823>>authors>>authors_1>>Yang Zhang": 0.11502295732498169, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG1573>>authors>>authors_6>>James Zhang": 0.11517763137817383, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5836>>authors>>authors_1>>Kaiming Xiao": 0.11559009552001953, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5777>>authors>>authors_1>>Yang Zhang": 0.11607557535171509, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5682>>authors>>authors_7>>Raghavan Srinivasan": 0.11607849597930908, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5458>>authors>>authors_10>>Changjun Jiang": 0.11637240648269653, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>authors>>authors_3>>Marisa Vasconcelos": 0.11640334129333496, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5815>>authors>>authors_1>>Louis Zigrand": 0.11642801761627197, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.11643171310424805}, "What is the abstract content of the paper coded as AI4SG5788 under the Special Track on AI for Good at IJCAI 2023?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5458>>authors>>authors_8>>Jianguang Zheng": 0.08839535713195801, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5694>>authors>>authors_3>>Azza Abouzied": 0.08866757154464722, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.08948415517807007, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5763>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.08994626998901367, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5787>>keywords>>keywords_2>>AI for Good -> Humans and AI": 0.09001809358596802, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>keywords>>keywords_3>>AI for Good -> Multidisciplinary Topics and Applications": 0.09011775255203247, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5796>>keywords>>keywords_3>>AI for Good -> Humans and AI": 0.09021103382110596, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5782>>keywords>>keywords_3>>AI for Good -> Machine Learning": 0.09029805660247803, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5836>>keywords>>keywords_3>>AI for Good -> Humans and AI": 0.09031075239181519, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5778>>keywords>>keywords_2>>AI for Good -> Humans and AI": 0.09040313959121704, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5803>>keywords>>keywords_3>>AI for Good -> Humans and AI": 0.09050190448760986, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5867>>keywords>>keywords_2>>AI for Good -> Humans and AI": 0.09051579236984253, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5879>>keywords>>keywords_1>>AI for Good -> Humans and AI": 0.09053432941436768, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5867>>keywords>>keywords_3>>AI for Good -> Multidisciplinary Topics and Applications": 0.0905805230140686}, "What are the keywords associated with the paper AI4SG5788 at IJCAI 2023?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5761>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.09603363275527954, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG3146>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.0963640809059143, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5867>>keywords>>keywords_3>>AI for Good -> Multidisciplinary Topics and Applications": 0.09639906883239746, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5817>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.09666794538497925, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5813>>keywords>>keywords_2>>AI for Good -> Multidisciplinary Topics and Applications": 0.09671801328659058, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>keywords>>keywords_3>>AI for Good -> Multidisciplinary Topics and Applications": 0.09700709581375122, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5782>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.09710657596588135, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5851>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.09716451168060303, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5783>>keywords>>keywords_3>>AI for Good -> Multidisciplinary Topics and Applications": 0.09723478555679321, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5859>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.09729832410812378, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5818>>keywords>>keywords_1>>AI for Good -> Multidisciplinary Topics and Applications": 0.097412109375, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5823>>keywords>>keywords_2>>AI for Good -> Multidisciplinary Topics and Applications": 0.09755373001098633, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5773>>keywords>>keywords_3>>AI for Good -> Multidisciplinary Topics and Applications": 0.09767097234725952}, "Which indigenous language is discussed in the case study in the paper AI4SG5788 at IJCAI 2023?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>title>>Balancing Social Impact, Opportunities, and Ethical Constraints of Using AI in the Documentation and Vitalization of Indigenous Languages": 0.10568434000015259, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>abstract>>In this paper we discuss how AI can contribute to support the documentation and vitalization of Indigenous languages and how that involves a delicate balancing of ensuring social impact, exploring technical opportunities, and dealing with ethical constraints. We start by surveying previous work on using AI and NLP to support critical activities of strengthening Indigenous and endangered languages and discussing key limitations of current technologies. After presenting basic ethical constraints of working with Indigenous languages and communities, we propose that creating and deploying language technology ethically with and for Indigenous communities forces AI researchers and engineers to address some of the main shortcomings and criticisms of current technologies. Those ideas are also explored in the discussion of a real case of development of large language models for Brazilian Indigenous languages.": 0.11008065938949585, "IJCAI2023>>program>>Main Track>>2705>>title>>An Empirical Study on the Language Modal in Visual Question Answering": 0.14831030368804932, "IJCAI2023>>program>>Main Track>>2225>>title>>Privacy-Preserving End-to-End Spoken Language Understanding": 0.15001589059829712, "IJCAI2023>>program>>Main Track>>1918>>title>>Contrastive Learning for Sign Language Recognition and Translation": 0.15090501308441162, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5865>>title>>Promoting Gender Equality through Gender-biased Language Analysis in Social Media": 0.15353870391845703, "IJCAI2023>>program>>Main Track>>1838>>title>>On Translations between ML Models for XAI Purposes": 0.15478253364562988, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5913>>title>>Exploring Multilingual Intent Dynamics and Applications": 0.15564590692520142, "IJCAI2023>>program>>Survey Track>>SV5654>>title>>Recent Advances in Direct Speech-to-text Translation": 0.15674471855163574, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5803>>title>>Sign Language-to-Text Dictionary with Lightweight Transformer Models": 0.16042214632034302, "IJCAI2023>>program>>Demonstrations Track>>DM5722>>title>>mahaNLP: A Marathi Natural Language Processing Library": 0.16046714782714844, "IJCAI2023>>program>>Survey Track>>SV5647>>keywords>>keywords_4>>Survey -> Natural Language Processing": 0.1605013608932495}, "What is the title of the paper with ID 547 in the Main Track program at IJCAI 2023?": {"IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10380363464355469, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.10592120885848999, "IJCAI2023>>program>>Main Track>>547>>authors>>authors_2>>Victoria Huang": 0.10674393177032471, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10742926597595215, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.10783571004867554, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.1078946590423584, "IJCAI2023>>program>>Main Track>>5274>>authors>>authors_2>>Niels Grüttemeier": 0.10860919952392578, "IJCAI2023>>program>>Main Track>>4195>>authors>>authors_3>>Xuan Liu": 0.10878831148147583, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.10880845785140991, "IJCAI2023>>program>>Main Track>>1327>>authors>>authors_3>>Jun Liu": 0.10888206958770752, "IJCAI2023>>program>>Main Track>>3525>>authors>>authors_3>>Jiacheng Li": 0.10890364646911621, "IJCAI2023>>program>>Main Track>>3655>>authors>>authors_1>>Jiaming Liu": 0.10935777425765991, "IJCAI2023>>program>>Main Track>>4518>>authors>>authors_4>>Aravind Srinivasan": 0.10943561792373657, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_6>>Ji Liu": 0.10976266860961914, "IJCAI2023>>program>>Main Track>>451>>authors>>authors_3>>Yu-Hui Wen": 0.11013960838317871, "IJCAI2023>>program>>Main Track>>451>>authors>>authors_6>>Yong-Jin Liu": 0.11028176546096802, "IJCAI2023>>program>>Main Track>>752>>authors>>authors_1>>Weiming Liu": 0.11031633615493774, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11065977811813354, "IJCAI2023>>program>>Main Track>>5155>>authors>>authors_4>>Jing Jiang": 0.11112016439437866, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_3>>Jianzong Wang": 0.11121898889541626, "IJCAI2023>>program>>Main Track>>3654>>authors>>authors_4>>Jiaying Liu": 0.11130940914154053}, "Who are the authors of the paper with ID 547 in the Main Track program at IJCAI 2023?": {"IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.10111337900161743, "IJCAI2023>>program>>Main Track>>547>>authors>>authors_2>>Victoria Huang": 0.10202926397323608, "IJCAI2023>>program>>Main Track>>5274>>authors>>authors_2>>Niels Grüttemeier": 0.10230571031570435, "IJCAI2023>>program>>Main Track>>4423>>authors>>authors_1>>André Schidler": 0.10313242673873901, "IJCAI2023>>program>>Main Track>>5274>>authors>>authors_4>>Nils Morawietz": 0.10466617345809937, "IJCAI2023>>program>>Main Track>>1679>>authors>>authors_2>>Markus Nissl": 0.1050758957862854, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_4>>Devarajan Sridharan": 0.1055765151977539, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10615092515945435, "IJCAI2023>>program>>Main Track>>4383>>authors>>authors_5>>Aravind Srinivasan": 0.10665583610534668, "IJCAI2023>>program>>Main Track>>1957>>authors>>authors_2>>David S. Aleixo": 0.10679113864898682, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_6>>Ji Liu": 0.10680025815963745, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10683822631835938, "IJCAI2023>>program>>Main Track>>3697>>authors>>authors_2>>Lars Schmidt-Thieme": 0.10701578855514526, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_1>>Jiahao Liu": 0.107185959815979, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.1073387861251831, "IJCAI2023>>program>>Main Track>>4518>>authors>>authors_4>>Aravind Srinivasan": 0.10739010572433472, "IJCAI2023>>program>>Main Track>>1274>>authors>>authors_1>>Yiduo Li": 0.10749167203903198, "IJCAI2023>>program>>Main Track>>3832>>authors>>authors_4>>Ian Miguel": 0.10756784677505493, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.10777169466018677, "IJCAI2023>>program>>Main Track>>5367>>authors>>authors_2>>Huan Li": 0.10793131589889526}, "What is the abstract of the paper with ID 547 in the Main Track program at IJCAI 2023?": {"IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.10559952259063721, "IJCAI2023>>program>>Main Track>>5274>>authors>>authors_2>>Niels Grüttemeier": 0.10635000467300415, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10653609037399292, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.10762608051300049, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10864746570587158, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.10891503095626831, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.10942023992538452, "IJCAI2023>>program>>Main Track>>547>>authors>>authors_2>>Victoria Huang": 0.10944503545761108, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_6>>Ji Liu": 0.11028236150741577, "IJCAI2023>>program>>Main Track>>3151>>authors>>authors_1>>Abdullah Al Maruf": 0.1105528473854065, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_3>>Jianzong Wang": 0.11081022024154663, "IJCAI2023>>program>>Main Track>>2671>>authors>>authors_3>>Jihua Zhu": 0.1108211874961853, "IJCAI2023>>program>>Main Track>>3475>>authors>>authors_4>>Jing Huang": 0.11122530698776245, "IJCAI2023>>program>>Main Track>>3525>>authors>>authors_3>>Jiacheng Li": 0.11125409603118896, "IJCAI2023>>program>>Main Track>>1242>>authors>>authors_6>>Jian Zhang": 0.11136412620544434, "IJCAI2023>>program>>Main Track>>5367>>authors>>authors_2>>Huan Li": 0.1114802360534668, "IJCAI2023>>program>>Main Track>>656>>authors>>authors_9>>Lijuan Wang": 0.1114966869354248, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11167687177658081, "IJCAI2023>>program>>Main Track>>1327>>authors>>authors_3>>Jun Liu": 0.11168134212493896, "IJCAI2023>>program>>Main Track>>4195>>authors>>authors_3>>Xuan Liu": 0.11182832717895508, "IJCAI2023>>program>>Main Track>>658>>authors>>authors_5>>Yabiao Wang": 0.112246572971344}, "What are the keywords related to the paper with ID 547 in the Main Track program at IJCAI 2023?": {"IJCAI2023>>program>>Main Track>>3955>>keywords>>keywords_3>>Search -> S: Search and machine learning": 0.10150718688964844, "IJCAI2023>>program>>Main Track>>541>>keywords>>keywords_1>>Machine Learning -> ML: Other": 0.10239309072494507, "IJCAI2023>>program>>Main Track>>1826>>keywords>>keywords_1>>Search -> S: Search and machine learning": 0.10554081201553345, "IJCAI2023>>program>>Main Track>>3127>>keywords>>keywords_2>>Machine Learning -> ML: Other": 0.10847091674804688, "IJCAI2023>>program>>Main Track>>2758>>keywords>>keywords_1>>Machine Learning -> ML: Other": 0.10872542858123779, "IJCAI2023>>program>>Main Track>>1009>>keywords>>keywords_1>>Machine Learning -> ML: Optimization": 0.1101386547088623, "IJCAI2023>>program>>Main Track>>847>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11017203330993652, "IJCAI2023>>program>>Main Track>>3510>>keywords>>keywords_1>>Machine Learning -> ML: Meta-learning": 0.11044198274612427, "IJCAI2023>>program>>Main Track>>451>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11058658361434937, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC3>>keywords>>keywords_3>>Sister Conferences Best Papers -> Humans and AI": 0.11118704080581665, "IJCAI2023>>program>>Main Track>>536>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11126643419265747, "IJCAI2023>>program>>Main Track>>607>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11154806613922119, "IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.11174750328063965, "IJCAI2023>>program>>Main Track>>827>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.1119810938835144, "IJCAI2023>>program>>Main Track>>3037>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11201095581054688, "IJCAI2023>>program>>Main Track>>953>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11214315891265869, "IJCAI2023>>program>>Main Track>>4152>>keywords>>keywords_2>>Machine Learning -> ML: Optimization": 0.11219263076782227}, "What is the main conclusion of the paper with ID 547 in the Main Track program at IJCAI 2023?": {"IJCAI2023>>program>>Main Track>>2459>>title>>Scalable Coupling of Deep Learning with Logical Reasoning": 0.12180089950561523, "IJCAI2023>>program>>Main Track>>1274>>authors>>authors_1>>Yiduo Li": 0.12357276678085327, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.12428015470504761, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.12601220607757568, "IJCAI2023>>program>>Main Track>>1327>>authors>>authors_3>>Jun Liu": 0.12609291076660156, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_6>>Ji Liu": 0.12673640251159668, "IJCAI2023>>program>>Main Track>>752>>authors>>authors_1>>Weiming Liu": 0.12681275606155396, "IJCAI2023>>program>>Main Track>>547>>authors>>authors_2>>Victoria Huang": 0.1270146369934082, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.12702322006225586, "IJCAI2023>>program>>Main Track>>930>>authors>>authors_3>>Huajin Tang": 0.1270594596862793, "IJCAI2023>>program>>Main Track>>451>>authors>>authors_3>>Yu-Hui Wen": 0.12717580795288086, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC12>>title>>Data-Driven Invariant Learning for Probabilistic Programs (Extended Abstract)": 0.1279609203338623, "IJCAI2023>>program>>Main Track>>2045>>authors>>authors_1>>Jiahao Liu": 0.12811845541000366, "IJCAI2023>>program>>Main Track>>5274>>authors>>authors_2>>Niels Grüttemeier": 0.12812578678131104, "IJCAI2023>>program>>Main Track>>1883>>title>>On the Paradox of Learning to Reason from Data": 0.12830418348312378, "IJCAI2023>>program>>Main Track>>451>>authors>>authors_1>>Aihua Mao": 0.1283828616142273, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_3>>Seyed-Mohammad Seyed-Javadi": 0.12845778465270996, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.12849318981170654, "IJCAI2023>>program>>Main Track>>1137>>authors>>authors_8>>Jian Wu": 0.12850463390350342, "IJCAI2023>>program>>Main Track>>3434>>authors>>authors_3>>Yijia Ruan": 0.12863385677337646}, "What is the title of the study conducted in track 4482 at the IJCAI 2023 conference?": {"IJCAI2023>>program>>Main Track>>4580>>authors>>authors_3>>Jorge A. Baier": 0.11888223886489868, "IJCAI2023>>program>>Survey Track>>SV5484>>authors>>authors_3>>Jia Wu": 0.11895030736923218, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.11897307634353638, "IJCAI2023>>program>>Main Track>>4480>>authors>>authors_1>>Giorgos Chionas": 0.11912471055984497, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.12014651298522949, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.12017941474914551, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.12034809589385986, "IJCAI2023>>program>>Main Track>>4428>>authors>>authors_4>>Ming Liu": 0.12039119005203247, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.12058126926422119, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.12067729234695435, "IJCAI2023>>program>>Main Track>>4195>>authors>>authors_3>>Xuan Liu": 0.12069690227508545, "IJCAI2023>>program>>Main Track>>4732>>authors>>authors_2>>Peter Jung": 0.12120318412780762, "IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.12127876281738281, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.12136876583099365, "IJCAI2023>>program>>Main Track>>3814>>authors>>authors_3>>Xiao Wang": 0.12143367528915405, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.12147724628448486, "IJCAI2023>>program>>Main Track>>3475>>authors>>authors_4>>Jing Huang": 0.1215658187866211, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.12168383598327637, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_2>>Yong Liu": 0.12174320220947266, "IJCAI2023>>program>>Main Track>>2676>>authors>>authors_3>>Jean Christoph Jung": 0.12178236246109009, "IJCAI2023>>program>>Main Track>>4936>>authors>>authors_3>>Kaiqi Huang": 0.12186336517333984}, "Who is the author of the study titled 'Fair Division of a Graph into Compact Bundles' at the IJCAI 2023 conference?": {"IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.14566880464553833, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.14812928438186646, "IJCAI2023>>program>>Main Track>>827>>authors>>authors_3>>Zhi-Gang Fan": 0.14877980947494507, "IJCAI2023>>program>>Main Track>>2905>>authors>>authors_2>>Steve Bellart": 0.14928460121154785, "IJCAI2023>>program>>Survey Track>>SV5460>>authors>>authors_1>>Bohan Zhuang": 0.14995414018630981, "IJCAI2023>>program>>Survey Track>>SV5654>>authors>>authors_8>>Jingbo Zhu": 0.15032345056533813, "IJCAI2023>>program>>Main Track>>4580>>authors>>authors_3>>Jorge A. Baier": 0.15032559633255005, "IJCAI2023>>program>>Main Track>>848>>authors>>authors_2>>Weiwei Li": 0.15036499500274658, "IJCAI2023>>program>>Main Track>>1679>>authors>>authors_2>>Markus Nissl": 0.15058565139770508, "IJCAI2023>>program>>Main Track>>827>>authors>>authors_5>>Yuanzhu Gan": 0.1510920524597168, "IJCAI2023>>program>>Main Track>>981>>authors>>authors_4>>Hongji Zhu": 0.15139251947402954, "IJCAI2023>>program>>Journal Track>>J5937>>authors>>authors_5>>Brian Logan": 0.15143996477127075, "IJCAI2023>>program>>Main Track>>1412>>authors>>authors_5>>Jian Li": 0.15148669481277466, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_3>>Michael Katz": 0.15154635906219482, "IJCAI2023>>program>>Survey Track>>SV5587>>authors>>authors_1>>Roberta Calegari": 0.1515527367591858, "IJCAI2023>>program>>Main Track>>1327>>authors>>authors_3>>Jun Liu": 0.1515762209892273, "IJCAI2023>>program>>Main Track>>580>>authors>>authors_6>>Hui Fang": 0.1516256332397461, "IJCAI2023>>program>>Main Track>>1829>>authors>>authors_3>>Yu Zhang": 0.1516815423965454, "IJCAI2023>>program>>Main Track>>2869>>authors>>authors_3>>Haichao Wang": 0.15178650617599487, "IJCAI2023>>program>>Main Track>>1242>>authors>>authors_6>>Jian Zhang": 0.15180599689483643, "IJCAI2023>>program>>Journal Track>>J5933>>authors>>authors_3>>Marc Garcia": 0.15200650691986084}, "What is the abstract of the study conducted by Jayakrishnan Madathil at the IJCAI 2023 conference?": {"IJCAI2023>>program>>Main Track>>4482>>authors>>authors_1>>Jayakrishnan Madathil": 0.09760230779647827, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.12082946300506592, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC23>>abstract>>unkonwn": 0.12142336368560791, "IJCAI2023>>program>>Main Track>>3365>>authors>>authors_3>>Abhay Aradhya": 0.12284153699874878, "IJCAI2023>>program>>Journal Track>>J5922>>title>>Creative Problem Solving in Artificially Intelligent Agents: A Survey and Framework (Extended Abstract)": 0.12356281280517578, "IJCAI2023>>program>>Demonstrations Track>>DM5728>>authors>>authors_1>>Anuradha Bhamidipaty": 0.12427186965942383, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC13>>abstract>>unkonwn": 0.12460649013519287, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC11>>abstract>>unkonwn": 0.12475907802581787, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC21>>abstract>>unkonwn": 0.12494111061096191, "IJCAI2023>>program>>Demonstrations Track>>DM5705>>authors>>authors_5>>Kavitha Srinivas": 0.12496638298034668, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.12538808584213257, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_1>>Barath Mohan Umapathi": 0.12545925378799438, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC19>>abstract>>unkonwn": 0.12567180395126343, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC24>>abstract>>unkonwn": 0.12581515312194824, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC9>>abstract>>unkonwn": 0.1258952021598816, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC14>>abstract>>unkonwn": 0.12596583366394043, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC8>>abstract>>unkonwn": 0.12624192237854004, "IJCAI2023>>program>>Main Track>>3127>>authors>>authors_1>>K. Darshana Abeyrathna": 0.12624478340148926}, "What are the keywords related to the study titled 'Fair Division of a Graph into Compact Bundles' at the IJCAI 2023 conference?": {"IJCAI2023>>program>>Main Track>>4482>>title>>Fair Division of a Graph into Compact Bundles": 0.06544685363769531, "IJCAI2023>>program>>Main Track>>4482>>abstract>>We study the computational complexity of fair division of indivisible items in an enriched model: there is an underlying graph on the set of items. And we have to allocate the items (i.e., the vertices of the graph) to a set of agents in such a way that (a) the allocation is fair (for appropriate notions of fairness) and (b) each agent receives a bundle of items (i.e., a subset of vertices) that induces a subgraph with a specific “nice structure.” This model has previously been studied in the literature with the nice structure being a connected subgraph. In this paper, we propose an alternative for connectivity in fair division. We introduce compact graphs, and look for fair allocations in which each agent receives a compact bundle of items. Through compactness, we attempt to capture the idea that every agent must receive a bundle of “closely related” items. We prove a host of hardness and tractability results with respect to fairness concepts such as proportionality, envy-freeness and maximin share guarantee.": 0.11093902587890625, "IJCAI2023>>program>>Main Track>>3155>>title>>Exploring Structural Similarity in Fitness Landscapes via Graph Data Mining: A Case Study on Number Partitioning Problems": 0.13372832536697388, "IJCAI2023>>program>>Workshops and Symposia>>Workshops>>W46>>Title>>First IJCAI Workshop on Computational Fair Division": 0.13469982147216797}, "What is the primary field of study for the research conducted by Jayakrishnan Madathil at the IJCAI 2023 conference?": {"IJCAI2023>>program>>Main Track>>4482>>authors>>authors_1>>Jayakrishnan Madathil": 0.10895192623138428, "IJCAI2023>>calls>>Call For Papers: Survey Track>>Call For Papers: Survey Track_4>>What Is a Suitable Topic?>>The IJCAI 2023 Survey Track provides an opportunity for established researchers in the AI community to give a broad talk on a well-established body of research, which provides a big-picture view of the topic rather than discussing a particular aspect. The topic should be of interest to current AI practitioners. Of particular interest are papers that describe how lessons learned from the topic can contribute to new ideas and visions that can stimulate the research community to pursue new directions, e.g., new problems.": 0.1301291584968567, "IJCAI2023>>program>>Main Track>>3930>>authors>>authors_1>>Santhini K. A.": 0.13129079341888428, "IJCAI2023>>program>>Main Track>>3398>>authors>>authors_4>>Kavitha Srinivas": 0.13231658935546875, "IJCAI2023>>Home>>Description>>Welcome to IJCAI 2023, the 32nd International Joint Conference on Artificial Intelligence, the premier international gathering of researchers in AI!": 0.13297051191329956, "IJCAI2023>>program>>Main Track>>4734>>authors>>authors_2>>Sandhya Saisubramanian": 0.13340264558792114, "IJCAI2023>>program>>Early Career Track>>Early Career Track_6>>Research field>>AI and Multi-agent Systems for Real World Decision Making": 0.13370031118392944, "IJCAI2023>>program>>Survey Track>>SV5648>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.1337043046951294}, "What is the title of the paper J5946 in the Journal Track?": {"IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.137281596660614, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.1418590545654297, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.14487093687057495, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.14490389823913574, "IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.14541363716125488, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_2>>Deyi Xiong": 0.14626789093017578, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_1>>Sriram Ganapathi Subramanian": 0.14704644680023193, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_2>>Matthew E. Taylor": 0.14762061834335327, "IJCAI2023>>program>>Journal Track>>J5688>>authors>>authors_2>>Martin Schmid": 0.1498379111289978, "IJCAI2023>>program>>Journal Track>>J5688>>authors>>authors_4>>Michael Bowling": 0.14989757537841797, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.15002882480621338, "IJCAI2023>>program>>Journal Track>>J5946>>authors>>authors_1>>Farhad Mohsin": 0.1502707600593567, "IJCAI2023>>program>>Main Track>>4636>>authors>>authors_9>>James T. Neal": 0.1506142020225525, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_1>>Özgür Akgün": 0.15089428424835205, "IJCAI2023>>program>>Journal Track>>J5939>>authors>>authors_2>>Jasmin Brandt": 0.1516786813735962, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_6>>Peter Nightingale": 0.15174949169158936, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_1>>Zhiyuan Zeng": 0.15183424949645996, "IJCAI2023>>program>>Journal Track>>J5940>>authors>>authors_2>>Alexander Artikis": 0.15230494737625122, "IJCAI2023>>program>>Journal Track>>J5922>>authors>>authors_2>>Lakshmi Nair": 0.15255725383758545}, "Who are the authors of the paper J5946 in the Journal Track?": {"IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.13033068180084229, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.13365113735198975, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.13587838411331177, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_2>>Matthew E. Taylor": 0.13891881704330444, "IJCAI2023>>program>>Journal Track>>J5688>>authors>>authors_2>>Martin Schmid": 0.14079374074935913, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.14113742113113403, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.14144682884216309, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_2>>Nariaki Kitamura": 0.14226484298706055, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_2>>Deyi Xiong": 0.1422916054725647, "IJCAI2023>>program>>Journal Track>>J5940>>authors>>authors_2>>Alexander Artikis": 0.14254575967788696, "IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.1426803469657898, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_3>>David Martins de Matos": 0.1430041790008545, "IJCAI2023>>program>>Main Track>>4636>>authors>>authors_9>>James T. Neal": 0.1432129144668579, "IJCAI2023>>program>>Journal Track>>J5930>>authors>>authors_2>>Brian Williams": 0.14342385530471802, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_1>>Sriram Ganapathi Subramanian": 0.1440732479095459, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.1441994309425354, "IJCAI2023>>program>>Journal Track>>J5939>>authors>>authors_2>>Jasmin Brandt": 0.14422309398651123, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.14451175928115845, "IJCAI2023>>program>>Journal Track>>J5922>>authors>>authors_2>>Lakshmi Nair": 0.14522117376327515}, "What is the central theme of the paper J5946?": {"IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.18954890966415405, "IJCAI2023>>program>>Journal Track>>J5944>>title>>A False Sense of Security (Extended Abstract)": 0.19164270162582397, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.19284892082214355, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.19438683986663818, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>keywords>>keywords_2>>General -> General": 0.19543075561523438, "IJCAI2023>>program>>Journal Track>>J5552>>title>>A Computational Model of Ostrom’s Institutional Analysis and Development Framework (Extended Abstract)": 0.19670230150222778, "IJCAI2023>>program>>Journal Track>>J5927>>title>>Adversarial Framework with Certified Robustness for Time-Series Domain via Statistical Features (Extended Abstract)": 0.1973942518234253, "IJCAI2023>>program>>Journal Track>>J5946>>title>>Learning to Design Fair and Private Voting Rules (Extended Abstract)": 0.19751030206680298, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5756>>keywords>>keywords_1>>General -> General": 0.19807535409927368, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.19822120666503906, "IJCAI2023>>program>>Journal Track>>J5949>>title>>Optimizing the Computation of Overriding in DLN (Extended Abstract)": 0.1983312964439392, "IJCAI2023>>program>>Journal Track>>J5931>>title>>Core Challenges in Embodied Vision-Language Planning (Extended Abstract)": 0.1986854076385498, "IJCAI2023>>program>>Journal Track>>J5688>>title>>Rethinking Formal Models of Partially Observable Multiagent Decision Making (Extended Abstract)": 0.19892632961273193, "IJCAI2023>>program>>Journal Track>>J5922>>title>>Creative Problem Solving in Artificially Intelligent Agents: A Survey and Framework (Extended Abstract)": 0.2002655267715454, "IJCAI2023>>program>>Journal Track>>J5939>>title>>A Survey of Methods for Automated Algorithm Configuration (Extended Abstract)": 0.2006281018257141, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.20103031396865845, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>title>>Fairness and Stability in Complex Domains": 0.2012861967086792}, "What is the new concept introduced in this paper J5946?": {"IJCAI2023>>program>>Journal Track>>J5948>>title>>Conjure: Automatic Generation of Constraint Models from Problem Specifications (Extended Abstract)": 0.178391695022583, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.18106365203857422, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.185299813747406, "IJCAI2023>>program>>Journal Track>>J5925>>title>>Interpretable Local Concept-based Explanation with Human Feedback to Predict All-cause Mortality (Extended Abstract)": 0.18660598993301392, "IJCAI2023>>program>>Journal Track>>J5939>>title>>A Survey of Methods for Automated Algorithm Configuration (Extended Abstract)": 0.18784099817276, "IJCAI2023>>program>>Journal Track>>J5943>>title>>On Tackling Explanation Redundancy in Decision Trees (Extended Abstract)": 0.18830406665802002, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.188306987285614, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.1883842945098877, "IJCAI2023>>program>>Journal Track>>J5944>>title>>A False Sense of Security (Extended Abstract)": 0.18954914808273315, "IJCAI2023>>program>>Journal Track>>J5946>>title>>Learning to Design Fair and Private Voting Rules (Extended Abstract)": 0.19034308195114136, "IJCAI2023>>program>>Journal Track>>J5688>>title>>Rethinking Formal Models of Partially Observable Multiagent Decision Making (Extended Abstract)": 0.19038617610931396, "IJCAI2023>>program>>Journal Track>>J5927>>title>>Adversarial Framework with Certified Robustness for Time-Series Domain via Statistical Features (Extended Abstract)": 0.19039863348007202, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.19081956148147583, "IJCAI2023>>program>>Journal Track>>J5949>>title>>Optimizing the Computation of Overriding in DLN (Extended Abstract)": 0.1911279559135437, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_1>>Sriram Ganapathi Subramanian": 0.19202721118927002, "IJCAI2023>>program>>Journal Track>>J5937>>title>>Data-Driven Revision of Conditional Norms in Multi-Agent Systems (Extended Abstract)": 0.19208365678787231}, "What are the keywords related to paper J5946?": {"IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.15749609470367432, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_1>>Planning": 0.1579667329788208, "IJCAI2023>>program>>Journal Track>>J5935>>keywords>>keywords_5>>Search -> S: Applications": 0.1619599461555481, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_2>>Numeric Planning": 0.1625070571899414, "IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.1644061803817749, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>keywords>>keywords_2>>General -> General": 0.16723334789276123, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5756>>keywords>>keywords_1>>General -> General": 0.16927999258041382, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_1>>Natural Language Processing -> NLP: Tagging, chunking, and parsing": 0.1717483401298523, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_3>>Mixed Planning": 0.17185837030410767, "IJCAI2023>>program>>Journal Track>>J5937>>keywords>>keywords_7>>Machine Learning -> ML: Classification": 0.17274540662765503, "IJCAI2023>>program>>Journal Track>>J5940>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> General": 0.17381197214126587, "IJCAI2023>>program>>Journal Track>>J5920>>keywords>>keywords_2>>Data Mining -> General": 0.1745586395263672, "IJCAI2023>>program>>Journal Track>>J5935>>keywords>>keywords_6>>Search -> S: Combinatorial search and optimisation": 0.17496585845947266, "IJCAI2023>>program>>Journal Track>>J5685>>keywords>>keywords_1>>Natural Language Processing -> NLP: Text classification": 0.17555546760559082, "IJCAI2023>>program>>Journal Track>>J5944>>keywords>>keywords_2>>Knowledge Representation and Reasoning -> General": 0.1756715178489685, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_4>>Gradient Descent": 0.17591071128845215, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5901>>keywords>>keywords_1>>General -> General": 0.1764012575149536}, "What is the paper J5946 proposing?": {"IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.17280620336532593, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.17522460222244263, "IJCAI2023>>program>>Journal Track>>J5946>>authors>>authors_1>>Farhad Mohsin": 0.18073219060897827, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.18127506971359253, "IJCAI2023>>program>>Journal Track>>J5948>>title>>Conjure: Automatic Generation of Constraint Models from Problem Specifications (Extended Abstract)": 0.18219780921936035, "IJCAI2023>>program>>Journal Track>>J5688>>title>>Rethinking Formal Models of Partially Observable Multiagent Decision Making (Extended Abstract)": 0.1829594373703003, "IJCAI2023>>program>>Journal Track>>J5758>>authors>>authors_1>>Sriram Ganapathi Subramanian": 0.18350499868392944, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_6>>Peter Nightingale": 0.18427932262420654, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_1>>Planning": 0.1845744252204895, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.18514126539230347, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_2>>Deyi Xiong": 0.18521058559417725, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.1853286623954773, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.1855459213256836, "IJCAI2023>>program>>Journal Track>>J5949>>title>>Optimizing the Computation of Overriding in DLN (Extended Abstract)": 0.1855478286743164, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.1861429214477539, "IJCAI2023>>program>>Journal Track>>J5586>>authors>>authors_1>>Junli Jiang": 0.18638205528259277, "IJCAI2023>>program>>Journal Track>>J5946>>title>>Learning to Design Fair and Private Voting Rules (Extended Abstract)": 0.18674015998840332, "IJCAI2023>>program>>Journal Track>>J5688>>authors>>authors_4>>Michael Bowling": 0.18725550174713135}, "According to the paper J5946, is it possible to always obtain maximal economic efficiency with high fairness?": {"IJCAI2023>>program>>Survey Track>>SV5550>>abstract>>Fair allocation of indivisible goods is a central topic in many AI applications. Unfortunately, the corresponding problems are known to be NP-hard for many fairness concepts, so unless P = NP, exact polynomial-time algorithms cannot exist for them. In practical applications, however, it would be highly desirable to find exact solutions as quickly as possible. This motivates the study of algorithms that—even though they only run in exponential time—are as fast as possible and exactly solve such problems. We present known complexity results for them and give a survey of important techniques for designing such algorithms, mainly focusing on four common fairness notions: max-min fairness, maximin share, maximizing Nash social welfare, and envy-freeness. We also highlight the most challenging open problems for future work.": 0.13279670476913452, "IJCAI2023>>program>>Main Track>>680>>title>>First-Choice Maximality Meets Ex-ante and Ex-post Fairness": 0.14312922954559326, "IJCAI2023>>program>>Journal Track>>J5946>>abstract>>Voting is used widely to aggregate preferences to make a collective decision. In this paper, we focus on evaluating and designing voting rules that support both the privacy of the voting agents and a notion of fairness over such agents. First, we introduce a novel notion of group fairness and adopt the existing notion of local differential privacy. We then evaluate the level of group fairness in several existing voting rules, as well as the trade-offs between fairness and privacy, showing that it is not possible to always obtain maximal economic efficiency with high fairness. \nThen, we present both a machine learning and a constrained optimization approach to design new voting rules that are fair while maintaining a high level of economic efficiency. Finally, we empirically examine the effect of adding noise to create local differentially private voting rules and discuss the three-way trade-off between economic efficiency, fairness, and privacy.": 0.14564788341522217}, "Does the paper J5946 discuss the effect of adding noise to create local differentially private voting rules?": {"IJCAI2023>>program>>Journal Track>>J5946>>abstract>>Voting is used widely to aggregate preferences to make a collective decision. In this paper, we focus on evaluating and designing voting rules that support both the privacy of the voting agents and a notion of fairness over such agents. First, we introduce a novel notion of group fairness and adopt the existing notion of local differential privacy. We then evaluate the level of group fairness in several existing voting rules, as well as the trade-offs between fairness and privacy, showing that it is not possible to always obtain maximal economic efficiency with high fairness. \nThen, we present both a machine learning and a constrained optimization approach to design new voting rules that are fair while maintaining a high level of economic efficiency. Finally, we empirically examine the effect of adding noise to create local differentially private voting rules and discuss the three-way trade-off between economic efficiency, fairness, and privacy.": 0.1203346848487854, "IJCAI2023>>program>>Journal Track>>J5946>>title>>Learning to Design Fair and Private Voting Rules (Extended Abstract)": 0.14834243059158325, "IJCAI2023>>program>>Main Track>>4172>>title>>An Experimental Comparison of Multiwinner Voting Rules on Approval Elections": 0.16563677787780762, "IJCAI2023>>program>>Main Track>>4172>>abstract>>In this paper, we experimentally compare major approval based multiwinner voting rules. To this end, we define a measure of similarity between two equal sized committees subject to a given election. Using synthetic elections coming from several distributions, we analyze how similar are the committees provided by prominent voting rules. Our results can be visualized as ”maps of voting rules”, which provide a counterpoint to a purely axiomatic classification of voting rules. We further investigate the relation of axiomatic analysis to our approach by evaluating how frequently committees computed by our rules satisfy proportionality properties.": 0.17348527908325195}, "What is the title of program 1560 in the Main Track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.09564447402954102, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_6>>Ji Liu": 0.1028013825416565, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.1063544750213623, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Professional title>>Program Chair": 0.10770750045776367, "IJCAI2023>>program>>Main Track>>2459>>title>>Scalable Coupling of Deep Learning with Logical Reasoning": 0.10801911354064941, "IJCAI2023>>program>>Main Track>>2676>>authors>>authors_3>>Jean Christoph Jung": 0.10897600650787354, "IJCAI2023>>program>>Main Track>>1505>>authors>>authors_6>>Jun Liu": 0.10899567604064941, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.10947197675704956, "IJCAI2023>>program>>Main Track>>1456>>title>>Bi-level Dynamic Learning  for Jointly Multi-modality Image Fusion and Beyond": 0.10965955257415771, "IJCAI2023>>program>>Main Track>>2716>>authors>>authors_3>>Jing Tang": 0.10967791080474854, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.10982221364974976, "IJCAI2023>>program>>Main Track>>656>>authors>>authors_9>>Lijuan Wang": 0.11033499240875244, "IJCAI2023>>program>>Main Track>>5155>>authors>>authors_4>>Jing Jiang": 0.11044049263000488, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.11078900098800659, "IJCAI2023>>program>>Main Track>>3655>>authors>>authors_1>>Jiaming Liu": 0.11148989200592041, "IJCAI2023>>program>>Main Track>>1476>>authors>>authors_1>>Ren-Jian Wang": 0.11150109767913818, "IJCAI2023>>program>>Main Track>>1456>>authors>>authors_1>>Zhu Liu": 0.11162835359573364, "IJCAI2023>>program>>Main Track>>2261>>title>>Contour-based Interactive Segmentation": 0.11187279224395752, "IJCAI2023>>program>>Main Track>>3654>>authors>>authors_1>>Minghao Liu": 0.11204296350479126, "IJCAI2023>>program>>Main Track>>2816>>authors>>authors_1>>Jiangjiang Zhao": 0.11206001043319702}, "Who are the authors of the program 1560 in the Main Track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.09061598777770996, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.09089881181716919, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_2>>Richard Klein": 0.09466511011123657, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_6>>Ji Liu": 0.09511327743530273, "IJCAI2023>>program>>Main Track>>2676>>authors>>authors_3>>Jean Christoph Jung": 0.09837156534194946, "IJCAI2023>>program>>Main Track>>1476>>authors>>authors_1>>Ren-Jian Wang": 0.09842556715011597, "IJCAI2023>>program>>Main Track>>856>>authors>>authors_1>>Xiang Zhuang": 0.0991218090057373, "IJCAI2023>>program>>Main Track>>1505>>authors>>authors_6>>Jun Liu": 0.09938329458236694, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_1>>Barath Mohan Umapathi": 0.09965574741363525, "IJCAI2023>>program>>Main Track>>3930>>authors>>authors_1>>Santhini K. A.": 0.09976446628570557, "IJCAI2023>>program>>Main Track>>1560>>authors>>authors_2>>Giuseppe De Giacomo": 0.10072505474090576, "IJCAI2023>>program>>Main Track>>3930>>authors>>authors_2>>Raghu Raman Ravi": 0.10092240571975708, "IJCAI2023>>program>>Main Track>>1456>>authors>>authors_1>>Zhu Liu": 0.10112923383712769, "IJCAI2023>>program>>Main Track>>2969>>authors>>authors_4>>Devarajan Sridharan": 0.10138708353042603, "IJCAI2023>>program>>Main Track>>2459>>authors>>authors_3>>Thomas Schiex": 0.10168123245239258, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_6>>Mengdi Zhang": 0.10182833671569824, "IJCAI2023>>program>>Main Track>>200>>authors>>authors_2>>Arjun Sridhar": 0.10223686695098877, "IJCAI2023>>program>>Main Track>>1679>>authors>>authors_1>>Matthias Lanzinger": 0.10235172510147095, "IJCAI2023>>program>>Main Track>>2562>>authors>>authors_3>>Zhengkui Wang": 0.10269170999526978, "IJCAI2023>>program>>Main Track>>1593>>authors>>authors_4>>Shu-Tao Xia": 0.10279130935668945}, "What is the main area of research or the keywords of the program 1560 in the Main Track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>1826>>keywords>>keywords_1>>Search -> S: Search and machine learning": 0.10185587406158447, "IJCAI2023>>program>>Main Track>>3955>>keywords>>keywords_3>>Search -> S: Search and machine learning": 0.10435128211975098, "IJCAI2023>>program>>Main Track>>1630>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.10809570550918579, "IJCAI2023>>program>>Main Track>>847>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.1118510365486145, "IJCAI2023>>program>>Main Track>>1604>>keywords>>keywords_1>>Machine Learning -> ML: Feature extraction, selection and dimensionality reduction": 0.11187511682510376, "IJCAI2023>>program>>Main Track>>2072>>keywords>>keywords_2>>Humans and AI -> HAI: Brain sciences": 0.11225879192352295, "IJCAI2023>>program>>Main Track>>953>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11252272129058838, "IJCAI2023>>program>>Main Track>>607>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11260092258453369, "IJCAI2023>>program>>Main Track>>536>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11262863874435425, "IJCAI2023>>program>>Main Track>>541>>keywords>>keywords_1>>Machine Learning -> ML: Other": 0.11267220973968506, "IJCAI2023>>program>>Main Track>>3037>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11313754320144653, "IJCAI2023>>program>>Main Track>>2869>>keywords>>keywords_2>>Humans and AI -> HAI: Brain sciences": 0.11328208446502686, "IJCAI2023>>program>>Main Track>>1361>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11347663402557373, "IJCAI2023>>program>>Main Track>>2160>>keywords>>keywords_1>>Computer Vision -> CV: 3D computer vision": 0.11349105834960938, "IJCAI2023>>program>>Main Track>>683>>keywords>>keywords_2>>Computer Vision -> CV: 3D computer vision": 0.11356455087661743, "IJCAI2023>>program>>Main Track>>1032>>keywords>>keywords_2>>Humans and AI -> HAI: Brain sciences": 0.11358624696731567, "IJCAI2023>>program>>Main Track>>1685>>keywords>>keywords_3>>Machine Learning -> ML: Feature extraction, selection and dimensionality reduction": 0.11375999450683594}, "What is the abstract of the program 1560 in the Main Track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.10116231441497803, "IJCAI2023>>program>>Main Track>>1588>>authors>>authors_6>>Ji Liu": 0.10608071088790894, "IJCAI2023>>program>>Main Track>>3127>>authors>>authors_2>>Ahmed A. O. Abouzeid": 0.10657793283462524, "IJCAI2023>>program>>Main Track>>2676>>authors>>authors_3>>Jean Christoph Jung": 0.10883796215057373, "IJCAI2023>>program>>Main Track>>2716>>authors>>authors_3>>Jing Tang": 0.11000329256057739, "IJCAI2023>>program>>Main Track>>856>>authors>>authors_1>>Xiang Zhuang": 0.11079978942871094, "IJCAI2023>>program>>Main Track>>4148>>authors>>authors_1>>Abhinav Joshi": 0.11081498861312866, "IJCAI2023>>program>>Main Track>>656>>authors>>authors_9>>Lijuan Wang": 0.11088800430297852, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_8>>Zhi-Hua Zhou": 0.11117196083068848, "IJCAI2023>>program>>Main Track>>656>>authors>>authors_10>>Zicheng Liu": 0.11121469736099243, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.11206436157226562, "IJCAI2023>>program>>Main Track>>2816>>authors>>authors_1>>Jiangjiang Zhao": 0.11250072717666626, "IJCAI2023>>program>>Main Track>>2693>>authors>>authors_1>>Yiheng Zhu": 0.11251890659332275, "IJCAI2023>>program>>Main Track>>1505>>authors>>authors_6>>Jun Liu": 0.11309748888015747, "IJCAI2023>>program>>Main Track>>2671>>authors>>authors_3>>Jihua Zhu": 0.11317873001098633, "IJCAI2023>>program>>Main Track>>1476>>authors>>authors_1>>Ren-Jian Wang": 0.11318051815032959, "IJCAI2023>>program>>Main Track>>1456>>authors>>authors_1>>Zhu Liu": 0.11345010995864868, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.11352777481079102, "IJCAI2023>>program>>Main Track>>3151>>authors>>authors_1>>Abdullah Al Maruf": 0.11361539363861084, "IJCAI2023>>program>>Main Track>>752>>authors>>authors_3>>Xinting Liao": 0.11365365982055664}, "Can the agent always execute the nondeterministic abstract actions to completion at the concrete level in the program 1560 in the Main Track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>1560>>abstract>>We develop a general framework for abstracting the behavior of an agent that operates in a nondeterministic domain, i.e., where the agent does not control\nthe outcome of the nondeterministic actions, based on the nondeterministic situation calculus and the ConGolog programming language. We assume that\nwe have both an abstract and a concrete nondeterministic basic action theory, and a refinement mapping which  specifies how abstract actions, decomposed into agent actions and environment reactions, are implemented by concrete ConGolog programs. This new setting supports strategic reasoning and strategy synthesis, by allowing us to quantify separately on agent actions and environment reactions. We show that if the agent has a (strong FOND) plan/strategy to achieve a goal/complete a task at the abstract level, and it can always execute the nondeterministic abstract actions to completion at the concrete level, then there exist a refinement of it that is a (strong FOND) plan/strategy to achieve the refinement of the goal/task at the concrete level.": 0.10490918159484863, "IJCAI2023>>program>>Main Track>>1560>>title>>Abstraction of Nondeterministic Situation Calculus Action Theories": 0.10719609260559082, "IJCAI2023>>program>>Main Track>>4276>>title>>Analyzing Intentional Behavior in Autonomous Agents under Uncertainty": 0.1259745955467224, "IJCAI2023>>program>>Journal Track>>J5688>>title>>Rethinking Formal Models of Partially Observable Multiagent Decision Making (Extended Abstract)": 0.13048642873764038, "IJCAI2023>>program>>Main Track>>1034>>title>>Multi-Agent Systems with Quantitative Satisficing Goals": 0.13750940561294556, "IJCAI2023>>program>>Main Track>>1679>>title>>Temporal Datalog with Existential Quantification": 0.14165037870407104, "IJCAI2023>>program>>Main Track>>5308>>title>>Can I Really Do That? Verification of Meta-Operators via Stackelberg Planning": 0.1420106291770935, "IJCAI2023>>program>>Main Track>>978>>title>>Helpful Information Sharing for Partially Informed Planning Agents": 0.14226675033569336, "IJCAI2023>>program>>Main Track>>3873>>title>>Principal-Agent Boolean Games": 0.14242208003997803, "IJCAI2023>>program>>Main Track>>4419>>title>>Learning to Act for Perceiving in Partially Unknown Environments": 0.14306092262268066, "IJCAI2023>>program>>Main Track>>4431>>title>>Preferences and Constraints in Abstract Argumentation": 0.1436290740966797}, "What is the title of the paper with id 3863?": {"IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.16889244318008423, "IJCAI2023>>program>>Main Track>>3863>>authors>>authors_7>>Hua Wu": 0.16891729831695557, "IJCAI2023>>program>>Journal Track>>J5939>>authors>>authors_3>>Alexander Tornede": 0.17147380113601685, "IJCAI2023>>program>>Journal Track>>J5933>>authors>>authors_3>>Marc Garcia": 0.17225539684295654, "IJCAI2023>>program>>Main Track>>3636>>authors>>authors_6>>Hui Xiong": 0.17260503768920898, "IJCAI2023>>program>>Main Track>>3863>>authors>>authors_3>>Yan Chen": 0.17309129238128662, "IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.1732228398323059, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.17364680767059326, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.17426860332489014, "IJCAI2023>>program>>Journal Track>>J5936>>authors>>authors_2>>Deyi Xiong": 0.17471301555633545, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.17477214336395264, "IJCAI2023>>program>>Main Track>>3686>>authors>>authors_3>>Xuanhua Shi": 0.17512238025665283, "IJCAI2023>>program>>Main Track>>3566>>authors>>authors_1>>Peiying Li": 0.17539089918136597, "IJCAI2023>>program>>Journal Track>>J5943>>authors>>authors_3>>Joao Marques-Silva": 0.17550069093704224, "IJCAI2023>>program>>Main Track>>3686>>authors>>authors_1>>Li-Jun Chen": 0.17605000734329224, "IJCAI2023>>program>>Main Track>>4026>>authors>>authors_3>>Timothy Parker": 0.17611432075500488, "IJCAI2023>>program>>Main Track>>3848>>authors>>authors_6>>Diederik M. Roijers": 0.17624884843826294, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC14>>authors>>authors_3>>Yazmin Ibanez-Garcia": 0.1767314076423645, "IJCAI2023>>program>>Main Track>>3863>>authors>>authors_4>>Jing Liu": 0.17674565315246582}, "Who are the authors of the paper with id 3863?": {"IJCAI2023>>program>>Journal Track>>J5931>>authors>>authors_1>>Jonathan Francis": 0.15737086534500122, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_2>>Alan M. Frisch": 0.15745699405670166, "IJCAI2023>>program>>Main Track>>3863>>authors>>authors_7>>Hua Wu": 0.15852349996566772, "IJCAI2023>>program>>Journal Track>>J5933>>authors>>authors_3>>Marc Garcia": 0.16032612323760986, "IJCAI2023>>program>>Main Track>>3832>>authors>>authors_4>>Ian Miguel": 0.1611398458480835, "IJCAI2023>>program>>Main Track>>3848>>authors>>authors_6>>Diederik M. Roijers": 0.16116678714752197, "IJCAI2023>>program>>Main Track>>3667>>authors>>authors_2>>Jakob Jørgensen": 0.1618441939353943, "IJCAI2023>>program>>Journal Track>>J5939>>authors>>authors_3>>Alexander Tornede": 0.16185379028320312, "IJCAI2023>>program>>Main Track>>3863>>authors>>authors_3>>Yan Chen": 0.16219568252563477, "IJCAI2023>>program>>Main Track>>2847>>authors>>authors_5>>Francisco Barahona": 0.1622697114944458, "IJCAI2023>>program>>Journal Track>>J5685>>authors>>authors_1>>Eugénio Ribeiro": 0.16233867406845093, "IJCAI2023>>program>>Main Track>>3834>>authors>>authors_1>>Thomas Erlebach": 0.16252678632736206, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.1629543900489807, "IJCAI2023>>program>>Main Track>>1868>>authors>>authors_3>>Wesley Kerr": 0.163052499294281, "IJCAI2023>>program>>Main Track>>4461>>authors>>authors_2>>Patrick Koopmann": 0.16330605745315552, "IJCAI2023>>program>>Main Track>>3686>>authors>>authors_3>>Xuanhua Shi": 0.1636316180229187, "IJCAI2023>>program>>Main Track>>2929>>authors>>authors_5>>Eric Rice": 0.16393417119979858, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_4>>Christopher Jefferson": 0.16396713256835938, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.1641099452972412}, "What is the abstract of the paper titled 'Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation'?": {"IJCAI2023>>program>>Main Track>>3863>>title>>Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation": 0.0812796950340271, "IJCAI2023>>program>>Main Track>>3863>>abstract>>Recent research has revealed that deep neural networks often take dataset biases as a shortcut to make decisions rather than understand tasks, leading to failures in real-world applications. In this study, we focus on the spurious correlation between word features and labels that models learn from the biased data distribution of training data. In particular, we define the word highly co-occurring with a specific label as biased word, and the example containing biased word as biased example. Our analysis shows that biased examples are easier for models to learn, while at the time of prediction, biased words make a significantly higher contribution to the models’ predictions, and models tend to assign predicted labels over-relying on the spurious correlation between words and labels. To mitigate models’ over-reliance on the shortcut (i.e. spurious correlation), we propose a training strategy Less-Learn-Shortcut (LLS): our strategy quantifies the biased degree of the biased examples and down-weights them accordingly. Experimental results on Question Matching, Natural Language Inference and Sentiment Analysis tasks show that LLS is a task-agnostic strategy and can improve the model performance on adversarial data while maintaining good performance on in-domain data.": 0.14309298992156982, "IJCAI2023>>program>>Main Track>>382>>title>>Learning to Learn from Corrupted Data for Few-Shot Learning": 0.15759509801864624, "IJCAI2023>>program>>Journal Track>>J5936>>title>>Unsupervised and Few-Shot Parsing from Pretrained Language Models (Extended Abstract)": 0.15827149152755737, "IJCAI2023>>program>>Main Track>>2144>>title>>Stochastic Feature Averaging for Learning with Long-Tailed Noisy Labels": 0.16209089756011963, "IJCAI2023>>program>>Main Track>>4184>>title>>Towards Sharp Analysis for Distributed Learning with Random Features": 0.1624985933303833, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC4>>title>>On the Versatile Uses of Partial Distance Correlation in Deep Learning": 0.1627134084701538, "IJCAI2023>>program>>Main Track>>2106>>title>>Handling Learnwares Developed from Heterogeneous Feature Spaces without Auxiliary Data": 0.16524267196655273, "IJCAI2023>>program>>Main Track>>3386>>title>>Statistically Significant Concept-based Explanation of Image Classifiers via Model Knockoffs": 0.16804605722427368}, "What are the keywords associated with the paper id 3863?": {"IJCAI2023>>program>>Doctoral Consortium Track>>DC5769>>keywords>>keywords_2>>General -> General": 0.16178756952285767, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC12>>keywords>>keywords_4>>Sister Conferences Best Papers -> Search": 0.16283047199249268, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5756>>keywords>>keywords_1>>General -> General": 0.16310524940490723, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_1>>Planning": 0.16425961256027222, "IJCAI2023>>program>>Main Track>>3863>>keywords>>keywords_2>>Natural Language Processing -> NLP: Interpretability and analysis of models for NLP": 0.1646783947944641, "IJCAI2023>>program>>Journal Track>>J5936>>keywords>>keywords_2>>Natural Language Processing -> General": 0.16512924432754517, "IJCAI2023>>program>>Journal Track>>J5931>>keywords>>keywords_1>>Robotics -> General": 0.16563469171524048, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5901>>keywords>>keywords_1>>General -> General": 0.16564470529556274, "IJCAI2023>>program>>Survey Track>>SV5639>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.16748285293579102, "IJCAI2023>>program>>Survey Track>>SV5648>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.1684802770614624, "IJCAI2023>>program>>Survey Track>>SV5579>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.16937744617462158, "IJCAI2023>>program>>Survey Track>>SV5592>>keywords>>keywords_3>>Survey -> Multidisciplinary Topics and Applications": 0.16973906755447388, "IJCAI2023>>program>>Survey Track>>SV5526>>keywords>>keywords_2>>Survey -> Multidisciplinary Topics and Applications": 0.17053544521331787, "IJCAI2023>>program>>Journal Track>>J5920>>keywords>>keywords_2>>Data Mining -> General": 0.17108255624771118, "IJCAI2023>>program>>Survey Track>>SV5653>>keywords>>keywords_1>>Survey -> Multidisciplinary Topics and Applications": 0.17151618003845215, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC12>>keywords>>keywords_2>>Sister Conferences Best Papers -> Knowledge Representation and Reasoning": 0.17196959257125854, "IJCAI2023>>calls>>Journal Track>>Accepted Papers List>>J5950>>keywords>>keywords_3>>Mixed Planning": 0.1720079779624939}, "What is the proposed strategy in the study 'Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation'?": {"IJCAI2023>>program>>Main Track>>3863>>title>>Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation": 0.08081722259521484, "IJCAI2023>>program>>Main Track>>3863>>abstract>>Recent research has revealed that deep neural networks often take dataset biases as a shortcut to make decisions rather than understand tasks, leading to failures in real-world applications. In this study, we focus on the spurious correlation between word features and labels that models learn from the biased data distribution of training data. In particular, we define the word highly co-occurring with a specific label as biased word, and the example containing biased word as biased example. Our analysis shows that biased examples are easier for models to learn, while at the time of prediction, biased words make a significantly higher contribution to the models’ predictions, and models tend to assign predicted labels over-relying on the spurious correlation between words and labels. To mitigate models’ over-reliance on the shortcut (i.e. spurious correlation), we propose a training strategy Less-Learn-Shortcut (LLS): our strategy quantifies the biased degree of the biased examples and down-weights them accordingly. Experimental results on Question Matching, Natural Language Inference and Sentiment Analysis tasks show that LLS is a task-agnostic strategy and can improve the model performance on adversarial data while maintaining good performance on in-domain data.": 0.13035953044891357, "IJCAI2023>>program>>Main Track>>382>>title>>Learning to Learn from Corrupted Data for Few-Shot Learning": 0.1524944305419922}, "What is the title of the research presented at the IJCAI2023 conference Main Track with the ID 5014?": {"IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.1076856255531311, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_4>>Jing Xiao": 0.10894906520843506, "IJCAI2023>>program>>Main Track>>4418>>authors>>authors_2>>John Grant": 0.10898751020431519, "IJCAI2023>>program>>Main Track>>5155>>authors>>authors_4>>Jing Jiang": 0.10940152406692505, "IJCAI2023>>program>>Main Track>>5164>>authors>>authors_1>>Wei Zhang": 0.10965877771377563, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.11042273044586182, "IJCAI2023>>program>>Main Track>>4195>>authors>>authors_3>>Xuan Liu": 0.11043643951416016, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_3>>Jianzong Wang": 0.11081016063690186, "IJCAI2023>>program>>Main Track>>5126>>authors>>authors_5>>Tian Wang": 0.11098921298980713, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_2>>Jie Liu": 0.11108541488647461, "IJCAI2023>>program>>Main Track>>5145>>authors>>authors_1>>Chenghao Liu": 0.11114609241485596, "IJCAI2023>>program>>Main Track>>5012>>authors>>authors_2>>Liang Zhang": 0.11147701740264893, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11201190948486328, "IJCAI2023>>program>>Main Track>>2611>>authors>>authors_5>>Da-Hui Wang": 0.11240184307098389, "IJCAI2023>>program>>Main Track>>5051>>authors>>authors_2>>Liang-Jian Deng": 0.11269152164459229, "IJCAI2023>>program>>Main Track>>5048>>authors>>authors_3>>Zhicheng Wang": 0.1129109263420105, "IJCAI2023>>program>>Main Track>>5176>>authors>>authors_6>>Xin Jiang": 0.11291611194610596, "IJCAI2023>>program>>Main Track>>451>>authors>>authors_6>>Yong-Jin Liu": 0.11317723989486694, "IJCAI2023>>program>>Main Track>>5014>>authors>>authors_5>>Pengfei Wang": 0.11322939395904541, "IJCAI2023>>program>>Main Track>>752>>authors>>authors_1>>Weiming Liu": 0.11326158046722412, "IJCAI2023>>program>>Main Track>>5011>>authors>>authors_4>>Yuansheng Liu": 0.11344575881958008}, "Who are the authors of the research 'Adaptive Path-Memory Network for Temporal Knowledge Graph Reasoning' presented at IJCAI2023?": {"IJCAI2023>>program>>Main Track>>5014>>title>>Adaptive Path-Memory Network for Temporal Knowledge Graph Reasoning": 0.08421939611434937, "IJCAI2023>>program>>Main Track>>5014>>abstract>>Temporal knowledge graph (TKG) reasoning aims to predict the future missing facts based on historical information and has gained increasing research interest recently. Lots of works have been made to model the historical structural and temporal characteristics for the reasoning task. Most existing works model the graph structure mainly depending on entity representation. However, the magnitude of TKG entities in real-world scenarios is considerable, and an increasing number of new entities will arise as time goes on. Therefore, we propose a novel architecture modeling with relation feature of TKG, namely aDAptivE path-MemOry Network (DaeMon), which adaptively models the temporal path information between query subject and each object candidate across history time. It models the historical information without depending on entity representation. Specifically, DaeMon uses path memory to record the temporal path information derived from path aggregation unit across timeline considering the memory passing strategy between adjacent timestamps. Extensive experiments conducted on four real-world TKG datasets demonstrate that our proposed model obtains substantial performance improvement and outperforms the state-of-the-art up to 4.8% absolute in MRR.": 0.1350880265235901, "IJCAI2023>>program>>Main Track>>1813>>title>>A Dual Semantic-Aware Recurrent Global-Adaptive Network for Vision-and-Language Navigation": 0.1361020803451538, "IJCAI2023>>program>>Main Track>>2366>>title>>Enabling Abductive Learning to Exploit Knowledge Graph": 0.148872971534729, "IJCAI2023>>program>>Tutorials>>Tutorials_11>>Title>>Open-Environment Knowledge Graph Construction and Reasoning: Challenges, Approaches, and Opportunities": 0.1510027050971985, "IJCAI2023>>program>>Survey Track>>SV5569>>title>>Temporal Knowledge Graph Completion: A Survey": 0.15166586637496948, "IJCAI2023>>program>>Main Track>>2178>>authors>>authors_4>>Martin Takac": 0.1517176628112793, "IJCAI2023>>program>>Main Track>>283>>title>>A Canonicalization-Enhanced Known Fact-Aware Framework For Open Knowledge Graph Link Prediction": 0.15302574634552002, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.15382862091064453}, "What is the abstract of the research 'Adaptive Path-Memory Network for Temporal Knowledge Graph Reasoning' presented at IJCAI2023?": {"IJCAI2023>>program>>Main Track>>5014>>title>>Adaptive Path-Memory Network for Temporal Knowledge Graph Reasoning": 0.06239253282546997, "IJCAI2023>>program>>Main Track>>5014>>abstract>>Temporal knowledge graph (TKG) reasoning aims to predict the future missing facts based on historical information and has gained increasing research interest recently. Lots of works have been made to model the historical structural and temporal characteristics for the reasoning task. Most existing works model the graph structure mainly depending on entity representation. However, the magnitude of TKG entities in real-world scenarios is considerable, and an increasing number of new entities will arise as time goes on. Therefore, we propose a novel architecture modeling with relation feature of TKG, namely aDAptivE path-MemOry Network (DaeMon), which adaptively models the temporal path information between query subject and each object candidate across history time. It models the historical information without depending on entity representation. Specifically, DaeMon uses path memory to record the temporal path information derived from path aggregation unit across timeline considering the memory passing strategy between adjacent timestamps. Extensive experiments conducted on four real-world TKG datasets demonstrate that our proposed model obtains substantial performance improvement and outperforms the state-of-the-art up to 4.8% absolute in MRR.": 0.10510039329528809, "IJCAI2023>>program>>Main Track>>1813>>title>>A Dual Semantic-Aware Recurrent Global-Adaptive Network for Vision-and-Language Navigation": 0.12016785144805908, "IJCAI2023>>program>>Main Track>>2366>>title>>Enabling Abductive Learning to Exploit Knowledge Graph": 0.12774807214736938, "IJCAI2023>>program>>Main Track>>1817>>title>>Explainable Multi-Agent Reinforcement Learning for Temporal Queries": 0.1312534213066101, "IJCAI2023>>program>>Survey Track>>SV5569>>title>>Temporal Knowledge Graph Completion: A Survey": 0.135206937789917, "IJCAI2023>>program>>Main Track>>4206>>title>>In Which Graph Structures Can We Efficiently Find Temporally Disjoint Paths and Walks?": 0.13597720861434937, "IJCAI2023>>program>>Tutorials>>Tutorials_11>>Title>>Open-Environment Knowledge Graph Construction and Reasoning: Challenges, Approaches, and Opportunities": 0.13643896579742432, "IJCAI2023>>program>>Main Track>>1738>>title>>Generative Flow Networks for Precise Reward-Oriented Active Learning on Graphs": 0.1384810209274292}, "What are the keywords associated with the research 'Adaptive Path-Memory Network for Temporal Knowledge Graph Reasoning' at IJCAI2023?": {"IJCAI2023>>program>>Main Track>>5014>>title>>Adaptive Path-Memory Network for Temporal Knowledge Graph Reasoning": 0.0612909197807312, "IJCAI2023>>program>>Main Track>>5014>>abstract>>Temporal knowledge graph (TKG) reasoning aims to predict the future missing facts based on historical information and has gained increasing research interest recently. Lots of works have been made to model the historical structural and temporal characteristics for the reasoning task. Most existing works model the graph structure mainly depending on entity representation. However, the magnitude of TKG entities in real-world scenarios is considerable, and an increasing number of new entities will arise as time goes on. Therefore, we propose a novel architecture modeling with relation feature of TKG, namely aDAptivE path-MemOry Network (DaeMon), which adaptively models the temporal path information between query subject and each object candidate across history time. It models the historical information without depending on entity representation. Specifically, DaeMon uses path memory to record the temporal path information derived from path aggregation unit across timeline considering the memory passing strategy between adjacent timestamps. Extensive experiments conducted on four real-world TKG datasets demonstrate that our proposed model obtains substantial performance improvement and outperforms the state-of-the-art up to 4.8% absolute in MRR.": 0.10481882095336914, "IJCAI2023>>program>>Main Track>>1813>>title>>A Dual Semantic-Aware Recurrent Global-Adaptive Network for Vision-and-Language Navigation": 0.11999356746673584, "IJCAI2023>>program>>Journal Track>>J5940>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> General": 0.12778115272521973, "IJCAI2023>>program>>Main Track>>2366>>title>>Enabling Abductive Learning to Exploit Knowledge Graph": 0.1278933882713318, "IJCAI2023>>program>>Tutorials>>Tutorials_11>>Title>>Open-Environment Knowledge Graph Construction and Reasoning: Challenges, Approaches, and Opportunities": 0.12981045246124268, "IJCAI2023>>program>>Journal Track>>J5922>>keywords>>keywords_1>>Knowledge Representation and Reasoning -> KRR: Learning and reasoning": 0.13006019592285156, "IJCAI2023>>program>>Survey Track>>SV5615>>keywords>>keywords_1>>Survey -> Knowledge Representation and Reasoning": 0.13102537393569946, "IJCAI2023>>program>>Survey Track>>SV5526>>keywords>>keywords_1>>Survey -> Knowledge Representation and Reasoning": 0.1313995122909546}, "What is the novel architecture that the paper 'Adaptive Path-Memory Network for Temporal Knowledge Graph Reasoning' is proposing?": {"IJCAI2023>>program>>Main Track>>5014>>title>>Adaptive Path-Memory Network for Temporal Knowledge Graph Reasoning": 0.10783040523529053, "IJCAI2023>>program>>Main Track>>5014>>abstract>>Temporal knowledge graph (TKG) reasoning aims to predict the future missing facts based on historical information and has gained increasing research interest recently. Lots of works have been made to model the historical structural and temporal characteristics for the reasoning task. Most existing works model the graph structure mainly depending on entity representation. However, the magnitude of TKG entities in real-world scenarios is considerable, and an increasing number of new entities will arise as time goes on. Therefore, we propose a novel architecture modeling with relation feature of TKG, namely aDAptivE path-MemOry Network (DaeMon), which adaptively models the temporal path information between query subject and each object candidate across history time. It models the historical information without depending on entity representation. Specifically, DaeMon uses path memory to record the temporal path information derived from path aggregation unit across timeline considering the memory passing strategy between adjacent timestamps. Extensive experiments conducted on four real-world TKG datasets demonstrate that our proposed model obtains substantial performance improvement and outperforms the state-of-the-art up to 4.8% absolute in MRR.": 0.11797523498535156, "IJCAI2023>>program>>Main Track>>2459>>abstract>>In the ongoing quest for hybridizing discrete reasoning with neural nets, there is an increasing interest in neural architectures that can learn how to solve discrete reasoning or optimization problems from natural inputs. In this paper, we introduce a scalable neural architecture and loss function dedicated to learning the constraints and criteria of NP-hard reasoning problems expressed as discrete Graphical Models. We empirically show our loss function is able to efficiently learn how to solve NP-hard reasoning problems from natural inputs as the symbolic, visual or many-solutions Sudoku problems as well as the energy optimization formulation of the protein design problem, providing data efficiency, interpretability, and a posteriori control over predictions.": 0.15357893705368042, "IJCAI2023>>program>>Main Track>>1813>>title>>A Dual Semantic-Aware Recurrent Global-Adaptive Network for Vision-and-Language Navigation": 0.15437716245651245}, "What is the title of the paper with ID 71 in the Main Track program?": {"IJCAI2023>>program>>Main Track>>1812>>authors>>authors_3>>Joseph Y. Halpern": 0.15202337503433228, "IJCAI2023>>program>>Main Track>>619>>authors>>authors_7>>Hongtu Zhu": 0.1520739197731018, "IJCAI2023>>program>>Main Track>>2716>>authors>>authors_2>>Yihong Luo": 0.15267318487167358, "IJCAI2023>>program>>Main Track>>1274>>authors>>authors_1>>Yiduo Li": 0.15295201539993286, "IJCAI2023>>program>>Main Track>>2611>>authors>>authors_7>>Xiaohua Xie": 0.15440577268600464, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.1544421911239624, "IJCAI2023>>program>>Main Track>>71>>authors>>authors_3>>Zhen Huang": 0.15502727031707764, "IJCAI2023>>program>>Main Track>>4714>>authors>>authors_1>>Daniel Hernandez": 0.15508711338043213, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_7>>Yuan Jiang": 0.1551365852355957, "IJCAI2023>>program>>Main Track>>451>>authors>>authors_1>>Aihua Mao": 0.15517961978912354, "IJCAI2023>>program>>Main Track>>5281>>authors>>authors_4>>Irwin King": 0.15531575679779053, "IJCAI2023>>program>>Main Track>>2229>>authors>>authors_1>>Halvard Hummel": 0.15549278259277344, "IJCAI2023>>program>>Main Track>>1251>>authors>>authors_1>>Tianrui Hui": 0.15552151203155518, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.15607881546020508, "IJCAI2023>>program>>Main Track>>4371>>authors>>authors_7>>Jian Xu": 0.15609371662139893, "IJCAI2023>>program>>Main Track>>736>>authors>>authors_1>>Huanhuan Yuan": 0.15617549419403076, "IJCAI2023>>program>>Main Track>>5092>>authors>>authors_2>>Irwin King": 0.15642070770263672, "IJCAI2023>>program>>Main Track>>1748>>authors>>authors_5>>Tianlei Hu": 0.15642660856246948, "IJCAI2023>>program>>Main Track>>981>>authors>>authors_4>>Hongji Zhu": 0.15682101249694824, "IJCAI2023>>program>>Main Track>>4383>>authors>>authors_7>>Anil Vullikanti": 0.15684616565704346, "IJCAI2023>>program>>Main Track>>3832>>authors>>authors_4>>Ian Miguel": 0.15699803829193115}, "Who are the authors of the paper with ID 71?": {"IJCAI2023>>program>>Main Track>>1679>>authors>>authors_2>>Markus Nissl": 0.1751408576965332, "IJCAI2023>>program>>Main Track>>1812>>authors>>authors_3>>Joseph Y. Halpern": 0.17703157663345337, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.17766207456588745, "IJCAI2023>>program>>Doctoral Consortium Track>>DC5898>>authors>>authors_1>>Wiebke Hutiri": 0.1796061396598816, "IJCAI2023>>program>>Main Track>>1274>>authors>>authors_1>>Yiduo Li": 0.17992687225341797, "IJCAI2023>>program>>Main Track>>71>>authors>>authors_5>>Shuai Wang": 0.18038076162338257, "IJCAI2023>>program>>Journal Track>>J5948>>authors>>authors_5>>Ian Miguel": 0.18075031042099, "IJCAI2023>>program>>Main Track>>2229>>authors>>authors_1>>Halvard Hummel": 0.18132221698760986, "IJCAI2023>>program>>Main Track>>71>>authors>>authors_3>>Zhen Huang": 0.18141549825668335, "IJCAI2023>>program>>Main Track>>4714>>authors>>authors_1>>Daniel Hernandez": 0.18198877573013306, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC26>>authors>>authors_1>>Sander J.J. Leemans": 0.1824168562889099, "IJCAI2023>>program>>Main Track>>721>>authors>>authors_3>>Eduard Eiben": 0.18330705165863037, "IJCAI2023>>program>>Survey Track>>SV5653>>authors>>authors_4>>Irwin King": 0.1834399700164795, "IJCAI2023>>program>>Demonstrations Track>>DM5728>>authors>>authors_1>>Anuradha Bhamidipaty": 0.18360179662704468, "IJCAI2023>>program>>Journal Track>>J5950>>authors>>authors_5>>Subbarao Kambhampati": 0.18360275030136108, "IJCAI2023>>program>>Survey Track>>SV5648>>authors>>authors_3>>Diederik M. Roijers": 0.1836230754852295, "IJCAI2023>>program>>Main Track>>3832>>authors>>authors_4>>Ian Miguel": 0.18383675813674927, "IJCAI2023>>program>>Main Track>>2366>>authors>>authors_6>>Wei Hu": 0.18385028839111328, "IJCAI2023>>program>>Main Track>>4051>>authors>>authors_1>>Anna L.D. Latour": 0.18394804000854492}, "What is the main idea of the paper titled 'Teaching What You Should Teach: A Data-Based Distillation Method'?": {"IJCAI2023>>program>>Main Track>>71>>title>>Teaching What You Should Teach: A Data-Based Distillation Method": 0.08667415380477905, "IJCAI2023>>program>>Main Track>>71>>abstract>>In real teaching scenarios, an excellent teacher always teaches what he (or she) is good at but the student is not. This gives the student the best assistance in making up for his (or her) weaknesses and becoming a good one overall. Enlightened by this, we introduce the \"Teaching what you Should Teach\" strategy into a knowledge distillation framework, and propose a data-based distillation method named \"TST\" that searches for desirable augmented samples to assist in distilling more efficiently and rationally. To be specific, we design a neural network-based data augmentation module with priori bias to find out what meets the teacher’s strengths but the student’s weaknesses, by learning magnitudes and probabilities to generate suitable data samples. By training the data augmentation module and the generalized distillation paradigm alternately, a student model is learned with excellent generalization ability. To verify the effectiveness of our method, we conducted extensive comparative experiments on object recognition, detection, and segmentation tasks. The results on the CIFAR-100, ImageNet-1k, MS-COCO, and Cityscapes datasets demonstrate that our method achieves state-of-the-art performance on almost all teacher-student pairs. Furthermore, we conduct visualization studies to explore what magnitudes and probabilities are needed for the distillation process.": 0.1321955919265747, "IJCAI2023>>program>>Survey Track>>SV5487>>abstract>>Dataset distillation is attracting more attention in machine learning as training sets continue to grow and the cost of training state-of-the-art models becomes increasingly high. By synthesizing datasets with high information density, dataset distillation offers a range of potential applications, including support for continual learning, neural architecture search, and privacy protection. Despite recent advances, we lack a holistic understanding of the approaches and applications. Our survey aims to bridge this gap by first proposing a taxonomy of dataset distillation, characterizing existing approaches, and then systematically reviewing the data modalities, and related applications. In addition, we summarize the challenges and discuss future directions for this field of research.": 0.16000896692276}, "What are the main application areas of the method proposed in the paper 'Teaching What You Should Teach: A Data-Based Distillation Method'?": {"IJCAI2023>>program>>Main Track>>71>>title>>Teaching What You Should Teach: A Data-Based Distillation Method": 0.09159678220748901, "IJCAI2023>>program>>Main Track>>71>>abstract>>In real teaching scenarios, an excellent teacher always teaches what he (or she) is good at but the student is not. This gives the student the best assistance in making up for his (or her) weaknesses and becoming a good one overall. Enlightened by this, we introduce the \"Teaching what you Should Teach\" strategy into a knowledge distillation framework, and propose a data-based distillation method named \"TST\" that searches for desirable augmented samples to assist in distilling more efficiently and rationally. To be specific, we design a neural network-based data augmentation module with priori bias to find out what meets the teacher’s strengths but the student’s weaknesses, by learning magnitudes and probabilities to generate suitable data samples. By training the data augmentation module and the generalized distillation paradigm alternately, a student model is learned with excellent generalization ability. To verify the effectiveness of our method, we conducted extensive comparative experiments on object recognition, detection, and segmentation tasks. The results on the CIFAR-100, ImageNet-1k, MS-COCO, and Cityscapes datasets demonstrate that our method achieves state-of-the-art performance on almost all teacher-student pairs. Furthermore, we conduct visualization studies to explore what magnitudes and probabilities are needed for the distillation process.": 0.12271225452423096, "IJCAI2023>>program>>Survey Track>>SV5487>>abstract>>Dataset distillation is attracting more attention in machine learning as training sets continue to grow and the cost of training state-of-the-art models becomes increasingly high. By synthesizing datasets with high information density, dataset distillation offers a range of potential applications, including support for continual learning, neural architecture search, and privacy protection. Despite recent advances, we lack a holistic understanding of the approaches and applications. Our survey aims to bridge this gap by first proposing a taxonomy of dataset distillation, characterizing existing approaches, and then systematically reviewing the data modalities, and related applications. In addition, we summarize the challenges and discuss future directions for this field of research.": 0.13712859153747559, "IJCAI2023>>program>>Survey Track>>SV5487>>title>>A Survey on Dataset Distillation: Approaches, Applications and Future Directions": 0.15837109088897705}, "What kind of evaluation was conducted to verify the effectiveness of the method proposed in the paper 'Teaching What You Should Teach: A Data-Based Distillation Method'?": {"IJCAI2023>>program>>Main Track>>71>>title>>Teaching What You Should Teach: A Data-Based Distillation Method": 0.1139034628868103, "IJCAI2023>>program>>Main Track>>71>>abstract>>In real teaching scenarios, an excellent teacher always teaches what he (or she) is good at but the student is not. This gives the student the best assistance in making up for his (or her) weaknesses and becoming a good one overall. Enlightened by this, we introduce the \"Teaching what you Should Teach\" strategy into a knowledge distillation framework, and propose a data-based distillation method named \"TST\" that searches for desirable augmented samples to assist in distilling more efficiently and rationally. To be specific, we design a neural network-based data augmentation module with priori bias to find out what meets the teacher’s strengths but the student’s weaknesses, by learning magnitudes and probabilities to generate suitable data samples. By training the data augmentation module and the generalized distillation paradigm alternately, a student model is learned with excellent generalization ability. To verify the effectiveness of our method, we conducted extensive comparative experiments on object recognition, detection, and segmentation tasks. The results on the CIFAR-100, ImageNet-1k, MS-COCO, and Cityscapes datasets demonstrate that our method achieves state-of-the-art performance on almost all teacher-student pairs. Furthermore, we conduct visualization studies to explore what magnitudes and probabilities are needed for the distillation process.": 0.1443893313407898, "IJCAI2023>>program>>Survey Track>>SV5487>>abstract>>Dataset distillation is attracting more attention in machine learning as training sets continue to grow and the cost of training state-of-the-art models becomes increasingly high. By synthesizing datasets with high information density, dataset distillation offers a range of potential applications, including support for continual learning, neural architecture search, and privacy protection. Despite recent advances, we lack a holistic understanding of the approaches and applications. Our survey aims to bridge this gap by first proposing a taxonomy of dataset distillation, characterizing existing approaches, and then systematically reviewing the data modalities, and related applications. In addition, we summarize the challenges and discuss future directions for this field of research.": 0.17272132635116577, "IJCAI2023>>program>>Survey Track>>SV5487>>title>>A Survey on Dataset Distillation: Approaches, Applications and Future Directions": 0.1764669418334961}, "Has the method proposed in the paper 'Teaching What You Should Teach: A Data-Based Distillation Method' been tested on any real datasets?": {"IJCAI2023>>program>>Main Track>>71>>title>>Teaching What You Should Teach: A Data-Based Distillation Method": 0.1053571105003357, "IJCAI2023>>program>>Main Track>>71>>abstract>>In real teaching scenarios, an excellent teacher always teaches what he (or she) is good at but the student is not. This gives the student the best assistance in making up for his (or her) weaknesses and becoming a good one overall. Enlightened by this, we introduce the \"Teaching what you Should Teach\" strategy into a knowledge distillation framework, and propose a data-based distillation method named \"TST\" that searches for desirable augmented samples to assist in distilling more efficiently and rationally. To be specific, we design a neural network-based data augmentation module with priori bias to find out what meets the teacher’s strengths but the student’s weaknesses, by learning magnitudes and probabilities to generate suitable data samples. By training the data augmentation module and the generalized distillation paradigm alternately, a student model is learned with excellent generalization ability. To verify the effectiveness of our method, we conducted extensive comparative experiments on object recognition, detection, and segmentation tasks. The results on the CIFAR-100, ImageNet-1k, MS-COCO, and Cityscapes datasets demonstrate that our method achieves state-of-the-art performance on almost all teacher-student pairs. Furthermore, we conduct visualization studies to explore what magnitudes and probabilities are needed for the distillation process.": 0.12808823585510254, "IJCAI2023>>program>>Survey Track>>SV5487>>abstract>>Dataset distillation is attracting more attention in machine learning as training sets continue to grow and the cost of training state-of-the-art models becomes increasingly high. By synthesizing datasets with high information density, dataset distillation offers a range of potential applications, including support for continual learning, neural architecture search, and privacy protection. Despite recent advances, we lack a holistic understanding of the approaches and applications. Our survey aims to bridge this gap by first proposing a taxonomy of dataset distillation, characterizing existing approaches, and then systematically reviewing the data modalities, and related applications. In addition, we summarize the challenges and discuss future directions for this field of research.": 0.14210033416748047, "IJCAI2023>>program>>Survey Track>>SV5487>>title>>A Survey on Dataset Distillation: Approaches, Applications and Future Directions": 0.15750765800476074}, "What does the TST stand for in the proposed method in the paper?": {"IJCAI2023>>program>>Main Track>>2077>>abstract>>Most infrared small target detection (ISTD) networks focus on building effective neural blocks or feature fusion modules but none describes the ISTD process from the image evolution perspective. The directional evolution of image pixels influenced by convolution, pooling and surrounding pixels is analogous to the movement of fluid elements constrained by surrounding variables ang particles. Inspired by this, we explore a novel research routine by abstracting the movement of pixels in the ISTD process as the flow of fluid in fluid dynamics (FD). Specifically, a new Fluid Dynamics-Inspired Network (FDI-Net) is devised for ISTD. Based on Taylor Central Difference (TCD) method, the TCD feature extraction block is designed, where convolution and Transformer structures are combined for local and global information. The pixel motion equation during the ISTD process is derived from the Navier–Stokes (N-S) equation, constructing a N-S Refinement Module that refines extracted features with edge details. Thus, the TCD feature extraction block determines the primary movement direction of pixels during detection, while the N-S Refinement Module corrects some skewed directions of the pixel stream to supplement the edge details. Experiments on IRSTD-1k and SIRST demonstrate that our method achieves SOTA performance in terms of evaluation metrics.": 0.1893330216407776}, "What kind of tasks does the method 'Teaching What You Should Teach: A Data-Based Distillation Method' apply to?": {"IJCAI2023>>program>>Main Track>>71>>title>>Teaching What You Should Teach: A Data-Based Distillation Method": 0.09661608934402466, "IJCAI2023>>program>>Main Track>>71>>abstract>>In real teaching scenarios, an excellent teacher always teaches what he (or she) is good at but the student is not. This gives the student the best assistance in making up for his (or her) weaknesses and becoming a good one overall. Enlightened by this, we introduce the \"Teaching what you Should Teach\" strategy into a knowledge distillation framework, and propose a data-based distillation method named \"TST\" that searches for desirable augmented samples to assist in distilling more efficiently and rationally. To be specific, we design a neural network-based data augmentation module with priori bias to find out what meets the teacher’s strengths but the student’s weaknesses, by learning magnitudes and probabilities to generate suitable data samples. By training the data augmentation module and the generalized distillation paradigm alternately, a student model is learned with excellent generalization ability. To verify the effectiveness of our method, we conducted extensive comparative experiments on object recognition, detection, and segmentation tasks. The results on the CIFAR-100, ImageNet-1k, MS-COCO, and Cityscapes datasets demonstrate that our method achieves state-of-the-art performance on almost all teacher-student pairs. Furthermore, we conduct visualization studies to explore what magnitudes and probabilities are needed for the distillation process.": 0.11899101734161377, "IJCAI2023>>program>>Survey Track>>SV5487>>abstract>>Dataset distillation is attracting more attention in machine learning as training sets continue to grow and the cost of training state-of-the-art models becomes increasingly high. By synthesizing datasets with high information density, dataset distillation offers a range of potential applications, including support for continual learning, neural architecture search, and privacy protection. Despite recent advances, we lack a holistic understanding of the approaches and applications. Our survey aims to bridge this gap by first proposing a taxonomy of dataset distillation, characterizing existing approaches, and then systematically reviewing the data modalities, and related applications. In addition, we summarize the challenges and discuss future directions for this field of research.": 0.1548263430595398}, "What are the primary concerns of the paper with ID 71 in the Main Track program?": {"IJCAI2023>>program>>Main Track>>5293>>title>>Proportionality Guarantees in Elections with Interdependent Issues": 0.1717454195022583, "IJCAI2023>>program>>Main Track>>5195>>title>>More for Less: Safe Policy Improvement with Stronger Performance Guarantees": 0.1773107647895813, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Name>>Edith Elkind": 0.1773310899734497, "IJCAI2023>>program>>Main Track>>792>>title>>Optimal Seat Arrangement: What Are the Hard and Easy Cases?": 0.1778736710548401, "IJCAI2023>>program>>Main Track>>1274>>authors>>authors_1>>Yiduo Li": 0.17976653575897217, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Professional title>>Program Chair": 0.18054038286209106, "IJCAI2023>>calls>>Call For Papers: Survey Track>>Call For Papers: Survey Track_4>>What Is a Suitable Topic?>>The IJCAI 2023 Survey Track provides an opportunity for established researchers in the AI community to give a broad talk on a well-established body of research, which provides a big-picture view of the topic rather than discussing a particular aspect. The topic should be of interest to current AI practitioners. Of particular interest are papers that describe how lessons learned from the topic can contribute to new ideas and visions that can stimulate the research community to pursue new directions, e.g., new problems.": 0.18081873655319214, "IJCAI2023>>program>>Main Track>>4413>>title>>Sequential Attention Source Identification Based on Feature Representation": 0.18103986978530884, "IJCAI2023>>program>>Main Track>>1834>>title>>A Unifying Formal Approach to Importance Values in Boolean Functions": 0.18114608526229858, "IJCAI2023>>program>>Main Track>>827>>title>>Learning Monocular Depth in Dynamic Environment via Context-aware Temporal Attention": 0.18121838569641113, "IJCAI2023>>program>>Main Track>>4309>>title>>Quantifying Consistency and Information Loss for Causal Abstraction Learning": 0.1815584897994995, "IJCAI2023>>program>>Main Track>>1812>>authors>>authors_3>>Joseph Y. Halpern": 0.18156546354293823, "IJCAI2023>>program>>Main Track>>1831>>authors>>authors_2>>Munindar P. Singh": 0.18157464265823364}, "Where does the 'Teaching What You Should Teach: A Data-Based Distillation Method' demonstrate state-of-the-art performance?": {"IJCAI2023>>program>>Main Track>>71>>title>>Teaching What You Should Teach: A Data-Based Distillation Method": 0.09809255599975586, "IJCAI2023>>program>>Main Track>>71>>abstract>>In real teaching scenarios, an excellent teacher always teaches what he (or she) is good at but the student is not. This gives the student the best assistance in making up for his (or her) weaknesses and becoming a good one overall. Enlightened by this, we introduce the \"Teaching what you Should Teach\" strategy into a knowledge distillation framework, and propose a data-based distillation method named \"TST\" that searches for desirable augmented samples to assist in distilling more efficiently and rationally. To be specific, we design a neural network-based data augmentation module with priori bias to find out what meets the teacher’s strengths but the student’s weaknesses, by learning magnitudes and probabilities to generate suitable data samples. By training the data augmentation module and the generalized distillation paradigm alternately, a student model is learned with excellent generalization ability. To verify the effectiveness of our method, we conducted extensive comparative experiments on object recognition, detection, and segmentation tasks. The results on the CIFAR-100, ImageNet-1k, MS-COCO, and Cityscapes datasets demonstrate that our method achieves state-of-the-art performance on almost all teacher-student pairs. Furthermore, we conduct visualization studies to explore what magnitudes and probabilities are needed for the distillation process.": 0.13081586360931396, "IJCAI2023>>program>>Survey Track>>SV5487>>abstract>>Dataset distillation is attracting more attention in machine learning as training sets continue to grow and the cost of training state-of-the-art models becomes increasingly high. By synthesizing datasets with high information density, dataset distillation offers a range of potential applications, including support for continual learning, neural architecture search, and privacy protection. Despite recent advances, we lack a holistic understanding of the approaches and applications. Our survey aims to bridge this gap by first proposing a taxonomy of dataset distillation, characterizing existing approaches, and then systematically reviewing the data modalities, and related applications. In addition, we summarize the challenges and discuss future directions for this field of research.": 0.16082197427749634, "IJCAI2023>>program>>Survey Track>>SV5487>>title>>A Survey on Dataset Distillation: Approaches, Applications and Future Directions": 0.17240560054779053}, "What is the title of the paper in the Special Track on AI for Good in the IJCAI2023 program?": {"IJCAI2023>>calls>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)_5>>Also, just as the research papers submitted to the main track of IJCAI 2023, papers in this track should be anonymous. Unlike for papers in the main track, there will be no author rebuttal, and no summary reject phase. Accepted research papers in the AI for Good track will be included in the IJCAI proceedings. An award will be given to honour outstanding research papers in this track.": 0.0822443962097168, "IJCAI2023>>calls>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)_6>>Submission of Research Papers>>Submission of Research Papers_2>>Also, just as the research papers submitted to the main track of IJCAI 2023, papers in this track should beanonymous. Unlike for papers in the main track, there will beno author rebuttal, andno summary rejectphase. Accepted research papers in the AI for Good track will be included in the IJCAI proceedings. An award will be given to honour outstanding research papers in this track.": 0.08247590065002441, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5773>>authors>>authors_3>>Xiaowei Jia": 0.08667826652526855, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5458>>authors>>authors_8>>Jianguang Zheng": 0.08692395687103271, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG1573>>authors>>authors_3>>Xiaoming Shi": 0.08722567558288574, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5755>>authors>>authors_3>>Changjun Jiang": 0.08723181486129761, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5694>>authors>>authors_3>>Azza Abouzied": 0.087238609790802, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5458>>authors>>authors_10>>Changjun Jiang": 0.08742731809616089, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5859>>authors>>authors_1>>Adel Khorramrouz": 0.08746379613876343}, "Who are the authors of the paper 'Optimizing Crop Management with Reinforcement Learning and Imitation Learning'?": {"IJCAI2023>>program>>Main Track>>2929>>authors>>authors_5>>Eric Rice": 0.17930740118026733, "IJCAI2023>>program>>Main Track>>3072>>authors>>authors_1>>Margot Herin": 0.18301773071289062, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_2>>Richard Klein": 0.18446135520935059, "IJCAI2023>>program>>Main Track>>2873>>authors>>authors_5>>Claudia Linnhoff-Popien": 0.18561279773712158, "IJCAI2023>>program>>Main Track>>648>>authors>>authors_2>>Weiming Liu": 0.18564873933792114, "IJCAI2023>>program>>Main Track>>1679>>authors>>authors_2>>Markus Nissl": 0.18601489067077637, "IJCAI2023>>program>>Main Track>>3848>>authors>>authors_6>>Diederik M. Roijers": 0.18634521961212158, "IJCAI2023>>program>>Survey Track>>SV5648>>authors>>authors_3>>Diederik M. Roijers": 0.18640506267547607, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5772>>authors>>authors_5>>Roy Ka-Wei Lee": 0.18651467561721802, "IJCAI2023>>program>>Main Track>>752>>authors>>authors_1>>Weiming Liu": 0.1868014931678772, "IJCAI2023>>program>>Main Track>>3078>>authors>>authors_1>>Xin Li": 0.1877450942993164, "IJCAI2023>>program>>Main Track>>71>>authors>>authors_4>>Linrui Gong": 0.18790578842163086, "IJCAI2023>>program>>Main Track>>607>>authors>>authors_1>>Haoming Li": 0.18796271085739136, "IJCAI2023>>program>>Main Track>>109>>authors>>authors_6>>Xian-Ling Mao": 0.18819409608840942, "IJCAI2023>>program>>Main Track>>2847>>authors>>authors_7>>Ryan Riegel": 0.1883527636528015, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5836>>authors>>authors_1>>Kaiming Xiao": 0.18836796283721924, "IJCAI2023>>program>>Main Track>>526>>authors>>authors_4>>Jean-Charles Régin": 0.18839150667190552, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5788>>authors>>authors_2>>Paulo Cavalin": 0.1886366605758667, "IJCAI2023>>program>>Main Track>>536>>authors>>authors_3>>Qian Li": 0.1887291669845581}, "What is the main focus of the paper presented in the Special Track on AI for Good?": {"IJCAI2023>>calls>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)_2>>This special track is dedicated to research triggered by real-world key questions, is carried out in collaboration with civil society stakeholders, and uses AI to work towards the SDGs and LNOB. The track aims to encourage the application of AI to solve current global and local challenges and to strengthen the civil society-science-policy interface. Multidisciplinary research, including computer, social and natural sciences, as well as multilateral collaborations with NGOs, community organizations and government agencies, is, therefore, an essential characteristic of the submissions to this track.": 0.10703378915786743, "IJCAI2023>>calls>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)_4>>Three primary selection criteria for all AI and Social Good submissions will be 1) the scientific quality of the work and contribution to AI and social or natural sciences state of the art, 2) the relevance and impact to the SDGs and LNOB principle, and 3) the collaboration with civil society stakeholders that have first-hand knowledge of the topic (taking into consideration the location of IJCAI 2023 Conference in Macao SAR, team work with local and regional African NGOs will be especially appreciated). All submissions should clearly state what specific real-world challenge is being tackled, identify or refer to the expert stakeholders that provide in-the-field know-how, explain how the topic relates to SDGs and LNOB principle and what is the contribution to the AI, social or natural sciences state of the art.": 0.11068683862686157, "IJCAI2023>>calls>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)>>Call For Papers And Projects: Multi-Year Track On AI And Social Good (Special Track)_5>>Also, just as the research papers submitted to the main track of IJCAI 2023, papers in this track should be anonymous. Unlike for papers in the main track, there will be no author rebuttal, and no summary reject phase. Accepted research papers in the AI for Good track will be included in the IJCAI proceedings. An award will be given to honour outstanding research papers in this track.": 0.11380141973495483}, "What simulation tool does the paper 'Optimizing Crop Management with Reinforcement Learning and Imitation Learning' use?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>abstract>>Crop management has a significant impact on crop yield, economic profit, and the environment. Although management guidelines exist, finding the optimal management practices is challenging. Previous work used reinforcement learning (RL) and crop simulators to solve the problem, but the trained policies either have limited performance or are not deployable in the real world. In this paper, we present an intelligent crop management system that optimizes nitrogen fertilization and irrigation simultaneously via RL, imitation learning (IL), and crop simulations using the Decision Support System for Agrotechnology Transfer (DSSAT). We first use deep RL, in particular, deep Q-network, to train management policies that require a large number of state variables from the simulator as observations (denoted as full observation). We then invoke IL to train management policies that only need a few state variables that can be easily obtained or measured in the real world (denoted as partial observation) by mimicking the actions of the RL policies trained under full observation. Simulation experiments using the maize crop in Florida (US) and Zaragoza (Spain) demonstrate that the trained policies from both RL and IL techniques achieved more than 45\\% improvement in economic profit while causing less environmental impact compared with a baseline method. Most importantly, the IL-trained management policies are directly deployable in the real world as they use readily available information.": 0.11103200912475586, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>title>>Optimizing Crop Management with Reinforcement Learning and Imitation Learning": 0.11428934335708618, "IJCAI2023>>program>>Main Track>>2873>>title>>CROP: Towards Distributional-Shift Robust Reinforcement Learning Using Compact Reshaped Observation Processing": 0.15218502283096313}, "What are the key techniques used in the paper 'Optimizing Crop Management with Reinforcement Learning and Imitation Learning'?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>title>>Optimizing Crop Management with Reinforcement Learning and Imitation Learning": 0.11275321245193481, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>abstract>>Crop management has a significant impact on crop yield, economic profit, and the environment. Although management guidelines exist, finding the optimal management practices is challenging. Previous work used reinforcement learning (RL) and crop simulators to solve the problem, but the trained policies either have limited performance or are not deployable in the real world. In this paper, we present an intelligent crop management system that optimizes nitrogen fertilization and irrigation simultaneously via RL, imitation learning (IL), and crop simulations using the Decision Support System for Agrotechnology Transfer (DSSAT). We first use deep RL, in particular, deep Q-network, to train management policies that require a large number of state variables from the simulator as observations (denoted as full observation). We then invoke IL to train management policies that only need a few state variables that can be easily obtained or measured in the real world (denoted as partial observation) by mimicking the actions of the RL policies trained under full observation. Simulation experiments using the maize crop in Florida (US) and Zaragoza (Spain) demonstrate that the trained policies from both RL and IL techniques achieved more than 45\\% improvement in economic profit while causing less environmental impact compared with a baseline method. Most importantly, the IL-trained management policies are directly deployable in the real world as they use readily available information.": 0.11995339393615723, "IJCAI2023>>program>>Main Track>>2873>>title>>CROP: Towards Distributional-Shift Robust Reinforcement Learning Using Compact Reshaped Observation Processing": 0.15016579627990723}, "What is the primary aim of the system presented in the 'Optimizing Crop Management with Reinforcement Learning and Imitation Learning' paper?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>abstract>>Crop management has a significant impact on crop yield, economic profit, and the environment. Although management guidelines exist, finding the optimal management practices is challenging. Previous work used reinforcement learning (RL) and crop simulators to solve the problem, but the trained policies either have limited performance or are not deployable in the real world. In this paper, we present an intelligent crop management system that optimizes nitrogen fertilization and irrigation simultaneously via RL, imitation learning (IL), and crop simulations using the Decision Support System for Agrotechnology Transfer (DSSAT). We first use deep RL, in particular, deep Q-network, to train management policies that require a large number of state variables from the simulator as observations (denoted as full observation). We then invoke IL to train management policies that only need a few state variables that can be easily obtained or measured in the real world (denoted as partial observation) by mimicking the actions of the RL policies trained under full observation. Simulation experiments using the maize crop in Florida (US) and Zaragoza (Spain) demonstrate that the trained policies from both RL and IL techniques achieved more than 45\\% improvement in economic profit while causing less environmental impact compared with a baseline method. Most importantly, the IL-trained management policies are directly deployable in the real world as they use readily available information.": 0.11678898334503174, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>title>>Optimizing Crop Management with Reinforcement Learning and Imitation Learning": 0.11834520101547241, "IJCAI2023>>program>>Main Track>>2873>>title>>CROP: Towards Distributional-Shift Robust Reinforcement Learning Using Compact Reshaped Observation Processing": 0.1474066972732544}, "What are the main benefits of the AI system presented in 'Optimizing Crop Management with Reinforcement Learning and Imitation Learning'?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>abstract>>Crop management has a significant impact on crop yield, economic profit, and the environment. Although management guidelines exist, finding the optimal management practices is challenging. Previous work used reinforcement learning (RL) and crop simulators to solve the problem, but the trained policies either have limited performance or are not deployable in the real world. In this paper, we present an intelligent crop management system that optimizes nitrogen fertilization and irrigation simultaneously via RL, imitation learning (IL), and crop simulations using the Decision Support System for Agrotechnology Transfer (DSSAT). We first use deep RL, in particular, deep Q-network, to train management policies that require a large number of state variables from the simulator as observations (denoted as full observation). We then invoke IL to train management policies that only need a few state variables that can be easily obtained or measured in the real world (denoted as partial observation) by mimicking the actions of the RL policies trained under full observation. Simulation experiments using the maize crop in Florida (US) and Zaragoza (Spain) demonstrate that the trained policies from both RL and IL techniques achieved more than 45\\% improvement in economic profit while causing less environmental impact compared with a baseline method. Most importantly, the IL-trained management policies are directly deployable in the real world as they use readily available information.": 0.09675294160842896, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>title>>Optimizing Crop Management with Reinforcement Learning and Imitation Learning": 0.09836548566818237}, "What advantage does the system developed in the paper 'Optimizing Crop Management with Reinforcement Learning and Imitation Learning' have for real-world applications?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>abstract>>Crop management has a significant impact on crop yield, economic profit, and the environment. Although management guidelines exist, finding the optimal management practices is challenging. Previous work used reinforcement learning (RL) and crop simulators to solve the problem, but the trained policies either have limited performance or are not deployable in the real world. In this paper, we present an intelligent crop management system that optimizes nitrogen fertilization and irrigation simultaneously via RL, imitation learning (IL), and crop simulations using the Decision Support System for Agrotechnology Transfer (DSSAT). We first use deep RL, in particular, deep Q-network, to train management policies that require a large number of state variables from the simulator as observations (denoted as full observation). We then invoke IL to train management policies that only need a few state variables that can be easily obtained or measured in the real world (denoted as partial observation) by mimicking the actions of the RL policies trained under full observation. Simulation experiments using the maize crop in Florida (US) and Zaragoza (Spain) demonstrate that the trained policies from both RL and IL techniques achieved more than 45\\% improvement in economic profit while causing less environmental impact compared with a baseline method. Most importantly, the IL-trained management policies are directly deployable in the real world as they use readily available information.": 0.10092592239379883, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>title>>Optimizing Crop Management with Reinforcement Learning and Imitation Learning": 0.11820340156555176}, "Which crops and regions were used for the experiments in 'Optimizing Crop Management with Reinforcement Learning and Imitation Learning'?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>title>>Optimizing Crop Management with Reinforcement Learning and Imitation Learning": 0.10476744174957275, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>abstract>>Crop management has a significant impact on crop yield, economic profit, and the environment. Although management guidelines exist, finding the optimal management practices is challenging. Previous work used reinforcement learning (RL) and crop simulators to solve the problem, but the trained policies either have limited performance or are not deployable in the real world. In this paper, we present an intelligent crop management system that optimizes nitrogen fertilization and irrigation simultaneously via RL, imitation learning (IL), and crop simulations using the Decision Support System for Agrotechnology Transfer (DSSAT). We first use deep RL, in particular, deep Q-network, to train management policies that require a large number of state variables from the simulator as observations (denoted as full observation). We then invoke IL to train management policies that only need a few state variables that can be easily obtained or measured in the real world (denoted as partial observation) by mimicking the actions of the RL policies trained under full observation. Simulation experiments using the maize crop in Florida (US) and Zaragoza (Spain) demonstrate that the trained policies from both RL and IL techniques achieved more than 45\\% improvement in economic profit while causing less environmental impact compared with a baseline method. Most importantly, the IL-trained management policies are directly deployable in the real world as they use readily available information.": 0.11121279001235962, "IJCAI2023>>program>>Main Track>>2873>>title>>CROP: Towards Distributional-Shift Robust Reinforcement Learning Using Compact Reshaped Observation Processing": 0.14644670486450195}, "What are the keywords for the paper 'Optimizing Crop Management with Reinforcement Learning and Imitation Learning'?": {"IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>title>>Optimizing Crop Management with Reinforcement Learning and Imitation Learning": 0.09303444623947144, "IJCAI2023>>program>>Special Track on AI for Good>>AI4SG5611>>abstract>>Crop management has a significant impact on crop yield, economic profit, and the environment. Although management guidelines exist, finding the optimal management practices is challenging. Previous work used reinforcement learning (RL) and crop simulators to solve the problem, but the trained policies either have limited performance or are not deployable in the real world. In this paper, we present an intelligent crop management system that optimizes nitrogen fertilization and irrigation simultaneously via RL, imitation learning (IL), and crop simulations using the Decision Support System for Agrotechnology Transfer (DSSAT). We first use deep RL, in particular, deep Q-network, to train management policies that require a large number of state variables from the simulator as observations (denoted as full observation). We then invoke IL to train management policies that only need a few state variables that can be easily obtained or measured in the real world (denoted as partial observation) by mimicking the actions of the RL policies trained under full observation. Simulation experiments using the maize crop in Florida (US) and Zaragoza (Spain) demonstrate that the trained policies from both RL and IL techniques achieved more than 45\\% improvement in economic profit while causing less environmental impact compared with a baseline method. Most importantly, the IL-trained management policies are directly deployable in the real world as they use readily available information.": 0.12037718296051025, "IJCAI2023>>program>>Main Track>>2873>>title>>CROP: Towards Distributional-Shift Robust Reinforcement Learning Using Compact Reshaped Observation Processing": 0.14677029848098755, "IJCAI2023>>program>>Main Track>>204>>keywords>>keywords_2>>Machine Learning -> ML: Reinforcement learning": 0.1494070291519165, "IJCAI2023>>program>>Journal Track>>J5921>>keywords>>keywords_1>>Machine Learning -> ML: Reinforcement learning": 0.15034693479537964, "IJCAI2023>>program>>Main Track>>974>>keywords>>keywords_1>>Machine Learning -> ML: Reinforcement learning": 0.15067589282989502, "IJCAI2023>>program>>Main Track>>1078>>keywords>>keywords_1>>Machine Learning -> ML: Reinforcement learning": 0.15123260021209717}, "What is the title of the paper with ID 621 in the Main Track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>619>>authors>>authors_3>>Xin Wang": 0.10748690366744995, "IJCAI2023>>program>>Main Track>>621>>authors>>authors_1>>Xiang Li": 0.10824501514434814, "IJCAI2023>>program>>Main Track>>1242>>authors>>authors_6>>Jian Zhang": 0.10874521732330322, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.11005765199661255, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.11024880409240723, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_4>>Yu Xiang": 0.11053717136383057, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.11059778928756714, "IJCAI2023>>program>>Main Track>>2611>>authors>>authors_7>>Xiaohua Xie": 0.11065036058425903, "IJCAI2023>>program>>Main Track>>5126>>authors>>authors_5>>Tian Wang": 0.11085885763168335, "IJCAI2023>>program>>Main Track>>648>>authors>>authors_7>>Jun Wang": 0.11093485355377197, "IJCAI2023>>program>>Main Track>>607>>authors>>authors_1>>Haoming Li": 0.11116248369216919, "IJCAI2023>>program>>Main Track>>2120>>authors>>authors_5>>Jian Xu": 0.11171472072601318, "IJCAI2023>>program>>Main Track>>892>>authors>>authors_6>>Xiangyang Ji": 0.11178719997406006, "IJCAI2023>>program>>Main Track>>656>>authors>>authors_9>>Lijuan Wang": 0.11185711622238159, "IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.11191189289093018, "IJCAI2023>>program>>Main Track>>752>>authors>>authors_1>>Weiming Liu": 0.11203646659851074, "IJCAI2023>>program>>Main Track>>3195>>authors>>authors_3>>Yijun Tian": 0.11218893527984619, "IJCAI2023>>program>>Main Track>>3263>>authors>>authors_1>>Huimin Zeng": 0.11227148771286011, "IJCAI2023>>program>>Main Track>>3243>>authors>>authors_3>>Zhen Wang": 0.11246544122695923, "IJCAI2023>>program>>Main Track>>1327>>authors>>authors_3>>Jun Liu": 0.11258906126022339, "IJCAI2023>>program>>Main Track>>1078>>authors>>authors_1>>Xianghua Zeng": 0.11274105310440063}, "Who are the authors of the paper 'Compositional Zero-Shot Artistic Font Synthesis'?": {"IJCAI2023>>program>>Main Track>>4441>>authors>>authors_2>>Matthew C. Fontaine": 0.19196796417236328, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS5605>>authors>>authors_6>>Francesco Foscarin": 0.19199734926223755, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS1142>>authors>>authors_6>>Lei Zhao": 0.19376415014266968, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS5652>>authors>>authors_1>>Jingwei Zhao": 0.19411981105804443, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS5508>>authors>>authors_4>>Zhensong Zhang": 0.19599097967147827, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS1743>>authors>>authors_1>>Zhen Ye": 0.19604432582855225, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS1472>>authors>>authors_1>>Zuzeng Lin": 0.1964493989944458, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS1142>>authors>>authors_3>>Zhanjie Zhang": 0.1967540979385376, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS5112>>authors>>authors_3>>Tong Zhang": 0.19732582569122314, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS1472>>authors>>authors_3>>Zhewei Huang": 0.19907444715499878, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS1142>>authors>>authors_5>>Zhiwen Zuo": 0.1992943286895752, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS5607>>authors>>authors_1>>Matthias Plasser": 0.20047610998153687, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS5605>>authors>>authors_1>>Carlos Cancino-Chacón": 0.2006683349609375, "IJCAI2023>>program>>Survey Track>>SV5487>>authors>>authors_7>>Zhiming Zhao": 0.20069187879562378, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS5508>>authors>>authors_6>>Weihong Bao": 0.20085620880126953}, "What is the main problem the paper 'Compositional Zero-Shot Artistic Font Synthesis' aims to address?": {"IJCAI2023>>program>>Main Track>>621>>title>>Compositional Zero-Shot Artistic Font Synthesis": 0.10281294584274292, "IJCAI2023>>program>>Main Track>>621>>abstract>>Recently, many researchers have made remarkable achievements in the field of artistic font synthesis, with impressive glyph style and effect style in the results. However, due to less exploration in style disentanglement, it is difficult for existing methods to envision a kind of unseen style (glyph-effect) compositions of artistic font, and thus can only learn the seen style compositions. To solve this problem, we propose a novel compositional zero-shot artistic font synthesis gan (CAFS-GAN), which allows the synthesis of unseen style compositions by exploring the visual independence and joint compatibility of encoding semantics between glyph and effect. Specifically, we propose two contrast-based style encoders to achieve style disentanglement due to glyph and effect intertwining in the image. Meanwhile, to preserve more glyph and effect detail, we propose a generator based on hierarchical dual styles AdaIN to reorganize content-styles representations from structure to texture gradually. Extensive experiments demonstrate the superiority of our model in generating high-quality artistic font images with unseen style compositions against other state-of-the-art methods. The source code and data is available at moonlight03.github.io/CAFS-GAN/.": 0.13485276699066162, "IJCAI2023>>program>>Main Track>>3369>>abstract>>Compositional Zero-Shot Learning (CZSL) aims to imitate the powerful generalization ability of human beings to recognize novel compositions of known primitive concepts that correspond to a state and an object, e.g., purple apple. To fully capture the intra- and inter-class correlations between compositional concepts, in this paper, we propose to learn them in a hierarchical manner. Specifically, we set up three hierarchical embedding spaces that respectively model the states, the objects, and their compositions, which serve as three “experts” that can be combined in inference for more accurate predictions. We achieve this based on the recent success of large-scale pretrained vision-language models, e.g., CLIP, which provides a strong initial knowledge of image-text relationships. To better adapt this knowledge to CZSL, we propose to learn three hierarchical prompts by explicitly fixing the unrelated word tokens in the three embedding spaces. Despite its simplicity, our proposed method consistently yields superior performance over current state-of-the-art approaches on three widely-used CZSL benchmarks.": 0.17253351211547852}, "What method is proposed in the paper 'Compositional Zero-Shot Artistic Font Synthesis' to solve the problem at hand?": {"IJCAI2023>>program>>Main Track>>621>>title>>Compositional Zero-Shot Artistic Font Synthesis": 0.09550362825393677, "IJCAI2023>>program>>Main Track>>621>>abstract>>Recently, many researchers have made remarkable achievements in the field of artistic font synthesis, with impressive glyph style and effect style in the results. However, due to less exploration in style disentanglement, it is difficult for existing methods to envision a kind of unseen style (glyph-effect) compositions of artistic font, and thus can only learn the seen style compositions. To solve this problem, we propose a novel compositional zero-shot artistic font synthesis gan (CAFS-GAN), which allows the synthesis of unseen style compositions by exploring the visual independence and joint compatibility of encoding semantics between glyph and effect. Specifically, we propose two contrast-based style encoders to achieve style disentanglement due to glyph and effect intertwining in the image. Meanwhile, to preserve more glyph and effect detail, we propose a generator based on hierarchical dual styles AdaIN to reorganize content-styles representations from structure to texture gradually. Extensive experiments demonstrate the superiority of our model in generating high-quality artistic font images with unseen style compositions against other state-of-the-art methods. The source code and data is available at moonlight03.github.io/CAFS-GAN/.": 0.12904715538024902, "IJCAI2023>>program>>Main Track>>3369>>abstract>>Compositional Zero-Shot Learning (CZSL) aims to imitate the powerful generalization ability of human beings to recognize novel compositions of known primitive concepts that correspond to a state and an object, e.g., purple apple. To fully capture the intra- and inter-class correlations between compositional concepts, in this paper, we propose to learn them in a hierarchical manner. Specifically, we set up three hierarchical embedding spaces that respectively model the states, the objects, and their compositions, which serve as three “experts” that can be combined in inference for more accurate predictions. We achieve this based on the recent success of large-scale pretrained vision-language models, e.g., CLIP, which provides a strong initial knowledge of image-text relationships. To better adapt this knowledge to CZSL, we propose to learn three hierarchical prompts by explicitly fixing the unrelated word tokens in the three embedding spaces. Despite its simplicity, our proposed method consistently yields superior performance over current state-of-the-art approaches on three widely-used CZSL benchmarks.": 0.15893012285232544}, "In which fields does the paper 'Compositional Zero-Shot Artistic Font Synthesis' fall?": {"IJCAI2023>>program>>Main Track>>621>>title>>Compositional Zero-Shot Artistic Font Synthesis": 0.0942389965057373, "IJCAI2023>>program>>Main Track>>621>>abstract>>Recently, many researchers have made remarkable achievements in the field of artistic font synthesis, with impressive glyph style and effect style in the results. However, due to less exploration in style disentanglement, it is difficult for existing methods to envision a kind of unseen style (glyph-effect) compositions of artistic font, and thus can only learn the seen style compositions. To solve this problem, we propose a novel compositional zero-shot artistic font synthesis gan (CAFS-GAN), which allows the synthesis of unseen style compositions by exploring the visual independence and joint compatibility of encoding semantics between glyph and effect. Specifically, we propose two contrast-based style encoders to achieve style disentanglement due to glyph and effect intertwining in the image. Meanwhile, to preserve more glyph and effect detail, we propose a generator based on hierarchical dual styles AdaIN to reorganize content-styles representations from structure to texture gradually. Extensive experiments demonstrate the superiority of our model in generating high-quality artistic font images with unseen style compositions against other state-of-the-art methods. The source code and data is available at moonlight03.github.io/CAFS-GAN/.": 0.143421471118927, "IJCAI2023>>program>>Main Track>>3369>>abstract>>Compositional Zero-Shot Learning (CZSL) aims to imitate the powerful generalization ability of human beings to recognize novel compositions of known primitive concepts that correspond to a state and an object, e.g., purple apple. To fully capture the intra- and inter-class correlations between compositional concepts, in this paper, we propose to learn them in a hierarchical manner. Specifically, we set up three hierarchical embedding spaces that respectively model the states, the objects, and their compositions, which serve as three “experts” that can be combined in inference for more accurate predictions. We achieve this based on the recent success of large-scale pretrained vision-language models, e.g., CLIP, which provides a strong initial knowledge of image-text relationships. To better adapt this knowledge to CZSL, we propose to learn three hierarchical prompts by explicitly fixing the unrelated word tokens in the three embedding spaces. Despite its simplicity, our proposed method consistently yields superior performance over current state-of-the-art approaches on three widely-used CZSL benchmarks.": 0.17569822072982788}, "What is the title of the paper presented in the main track of IJCAI2023?": {"IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Professional title>>Program Chair": 0.10364663600921631, "IJCAI2023>>program>>Main Track>>1132>>authors>>authors_1>>Jie Liu": 0.1096300482749939, "IJCAI2023>>program>>Main Track>>1540>>authors>>authors_2>>Junji Jiang": 0.11066913604736328, "IJCAI2023>>program>>Main Track>>1231>>authors>>authors_3>>Seyed-Mohammad Seyed-Javadi": 0.11182749271392822, "IJCAI2023>>program>>Main Track>>3573>>authors>>authors_3>>Jian Li": 0.11237382888793945, "IJCAI2023>>program>>Main Track>>2094>>authors>>authors_3>>Jie Tang": 0.11258900165557861, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_6>>Professional title>>Workflow Chair": 0.1127517819404602, "IJCAI2023>>committees>>Program Committee>>IJCAI 2023 Main Track>>IJCAI 2023 Main Track_1>>Name>>Edith Elkind": 0.11292564868927002, "IJCAI2023>>program>>Main Track>>2120>>authors>>authors_5>>Jian Xu": 0.11319077014923096, "IJCAI2023>>program>>Main Track>>4580>>authors>>authors_3>>Jorge A. Baier": 0.11395853757858276, "IJCAI2023>>program>>Main Track>>2738>>authors>>authors_6>>Wei Wang": 0.1139635443687439, "IJCAI2023>>program>>Main Track>>1572>>authors>>authors_3>>Steven James": 0.1142454743385315, "IJCAI2023>>program>>Main Track>>752>>authors>>authors_1>>Weiming Liu": 0.11426633596420288, "IJCAI2023>>program>>Main Track>>1068>>authors>>authors_1>>Hua Jiang": 0.11429452896118164, "IJCAI2023>>program>>Main Track>>2193>>authors>>authors_1>>Jie Qiao": 0.1143156886100769, "IJCAI2023>>program>>Main Track>>2611>>authors>>authors_5>>Da-Hui Wang": 0.11435484886169434, "IJCAI2023>>program>>Main Track>>4184>>authors>>authors_1>>Jian Li": 0.11445719003677368, "IJCAI2023>>program>>Main Track>>2106>>authors>>authors_3>>Yuan Jiang": 0.11467379331588745, "IJCAI2023>>program>>Main Track>>1412>>authors>>authors_5>>Jian Li": 0.1146841049194336}, "Who are the authors of the paper 'Artificial Agents Inspired by Human Motivation Psychology for Teamwork in Hazardous Environments'?": {"IJCAI2023>>program>>Main Track>>1363>>title>>Artificial Agents Inspired by Human Motivation Psychology for Teamwork in Hazardous Environments": 0.0894923210144043, "IJCAI2023>>program>>Main Track>>1363>>abstract>>Multi-agent literature explores personifying artificial agents with personality, emotions or cognitive biases to produce “typical”, believable agents. In\nthis study, we demonstrate the potential of endowing artificial agents with a motivation, using human implicit motivation psychology theory that introduces 3 motive profiles – power, achievement and affiliation, to create diverse, risk-aware agents. We first devise a framework to model these motivated agents (or agents with any inherent behavior), that can activate different strategies depending on the circumstances. We conduct experiments on a fire-fighting task domain, evaluate how motivated teams perform, and draw conclusions on appropriate team compositions to be deployed in environments with different risk levels. Our framework generates predictable agents as their resulting behaviors align with the inherent characteristics of their motives. We find that motivational diversity within teams is beneficial in dynamic collaborative environments, especially as the task risk level increases. Furthermore, we observed that the best composition in terms of the performance metrics used to evaluate team compositions, does not remain the same as the collaboration level required to achieve goals changes. These results have implications for future designs of risk-aware autonomous teams and Human-AI teams, as they highlight the prospects of creating better artificial teammates and performance gains that could be achieved through anthropomorphized motivated agents.": 0.1269090175628662, "IJCAI2023>>program>>Main Track>>1856>>title>>Towards a Better Understanding of Learning with Multiagent Teams": 0.1636589765548706, "IJCAI2023>>program>>Journal Track>>J5922>>title>>Creative Problem Solving in Artificially Intelligent Agents: A Survey and Framework (Extended Abstract)": 0.17057418823242188, "IJCAI2023>>program>>Journal Track>>J5650>>title>>Q-Learning-Based Model Predictive Variable Impedance Control for Physical Human-Robot Collaboration (Extended Abstract)": 0.17248189449310303, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS5558>>authors>>authors_4>>Roger Wattenhofer": 0.17250728607177734, "IJCAI2023>>program>>Special Track on AI, the Arts and Creativity>>ARTS5605>>authors>>authors_7>>Gerhard Widmer": 0.17261016368865967}, "What are the areas of focus related to the paper 'Artificial Agents Inspired by Human Motivation Psychology for Teamwork in Hazardous Environments'?": {"IJCAI2023>>program>>Main Track>>1363>>title>>Artificial Agents Inspired by Human Motivation Psychology for Teamwork in Hazardous Environments": 0.0891871452331543, "IJCAI2023>>program>>Main Track>>1363>>abstract>>Multi-agent literature explores personifying artificial agents with personality, emotions or cognitive biases to produce “typical”, believable agents. In\nthis study, we demonstrate the potential of endowing artificial agents with a motivation, using human implicit motivation psychology theory that introduces 3 motive profiles – power, achievement and affiliation, to create diverse, risk-aware agents. We first devise a framework to model these motivated agents (or agents with any inherent behavior), that can activate different strategies depending on the circumstances. We conduct experiments on a fire-fighting task domain, evaluate how motivated teams perform, and draw conclusions on appropriate team compositions to be deployed in environments with different risk levels. Our framework generates predictable agents as their resulting behaviors align with the inherent characteristics of their motives. We find that motivational diversity within teams is beneficial in dynamic collaborative environments, especially as the task risk level increases. Furthermore, we observed that the best composition in terms of the performance metrics used to evaluate team compositions, does not remain the same as the collaboration level required to achieve goals changes. These results have implications for future designs of risk-aware autonomous teams and Human-AI teams, as they highlight the prospects of creating better artificial teammates and performance gains that could be achieved through anthropomorphized motivated agents.": 0.12116736173629761, "IJCAI2023>>program>>Competitions and Challenges>>Competitions and Challenges_6>>Description>>The recent strides in robotics and artificial intelligence over the last decade have resulted in more and more robots sharing space and working together with humans in everyday life. This situation puts forth a lot of challenges and concerns that need to be addressed. Of these, understanding the interacting human’s mindset and their subjective satisfaction with the robot’s performance are very critical. One way to address these challenges is analysing the psychophysiological data of the interacting human. This competition encourages the participating teams to develop cutting-edge Signal Processing and/or Machine Learning approaches for the detection of erroneous behaviours using single-trial EEG data and test them on real hardware.": 0.15408051013946533, "IJCAI2023>>program>>Journal Track>>J5924>>keywords>>keywords_2>>Humans and AI -> HAI: Human-AI collaboration": 0.16314148902893066}, "What is the key methodology used in the paper presented in the main track of IJCAI2023?": {"IJCAI2023>>program>>Main Track>>4339>>keywords>>keywords_1>>Machine Learning -> ML: Experimental methodology": 0.12607401609420776, "IJCAI2023>>calls>>Call For Papers: Survey Track>>Call For Papers: Survey Track_4>>What Is a Suitable Topic?>>The IJCAI 2023 Survey Track provides an opportunity for established researchers in the AI community to give a broad talk on a well-established body of research, which provides a big-picture view of the topic rather than discussing a particular aspect. The topic should be of interest to current AI practitioners. Of particular interest are papers that describe how lessons learned from the topic can contribute to new ideas and visions that can stimulate the research community to pursue new directions, e.g., new problems.": 0.12651288509368896, "IJCAI2023>>program>>Best Papers from Sister Conferences Track>>SC3>>keywords>>keywords_3>>Sister Conferences Best Papers -> Humans and AI": 0.13222765922546387, "IJCAI2023>>program>>Main Track>>2459>>title>>Scalable Coupling of Deep Learning with Logical Reasoning": 0.13370388746261597, "IJCAI2023>>program>>Journal Track>>J5586>>title>>Data-Informed Knowledge and Strategies (Extended Abstract)": 0.1339392066001892, "IJCAI2023>>calls>>Call For Papers: Survey Track>>Call For Papers: Survey Track_1>>The IJCAI 2023 Survey Track enables the AI community to learn from AI researchers who are experts on a topic by allowing them to give a talk presenting a synthetic survey of that topic. Papers accepted to the Survey Track will be published in the IJCAI 2023 proceedings. At least one author of each accepted paper must register for the conference and present the work.": 0.13613653182983398, "IJCAI2023>>calls>>Call For Papers>>Call For Papers_5>>A selection of the best papers submitted to IJCAI 2023 will be invited for a fast track in the Artificial Intelligence Journal and/or the Journal of AI Research.": 0.1370580792427063}, "According to the paper 'Artificial Agents Inspired by Human Motivation Psychology for Teamwork in Hazardous Environments', what kind of diversity is beneficial in dynamic collaborative environments?": {"IJCAI2023>>program>>Main Track>>1363>>abstract>>Multi-agent literature explores personifying artificial agents with personality, emotions or cognitive biases to produce “typical”, believable agents. In\nthis study, we demonstrate the potential of endowing artificial agents with a motivation, using human implicit motivation psychology theory that introduces 3 motive profiles – power, achievement and affiliation, to create diverse, risk-aware agents. We first devise a framework to model these motivated agents (or agents with any inherent behavior), that can activate different strategies depending on the circumstances. We conduct experiments on a fire-fighting task domain, evaluate how motivated teams perform, and draw conclusions on appropriate team compositions to be deployed in environments with different risk levels. Our framework generates predictable agents as their resulting behaviors align with the inherent characteristics of their motives. We find that motivational diversity within teams is beneficial in dynamic collaborative environments, especially as the task risk level increases. Furthermore, we observed that the best composition in terms of the performance metrics used to evaluate team compositions, does not remain the same as the collaboration level required to achieve goals changes. These results have implications for future designs of risk-aware autonomous teams and Human-AI teams, as they highlight the prospects of creating better artificial teammates and performance gains that could be achieved through anthropomorphized motivated agents.": 0.13141852617263794, "IJCAI2023>>program>>Main Track>>1363>>title>>Artificial Agents Inspired by Human Motivation Psychology for Teamwork in Hazardous Environments": 0.13685524463653564, "IJCAI2023>>program>>Main Track>>1856>>abstract>>While it has long been recognized that a team of individual learning agents can be greater than the sum of its parts, recent work has shown that larger teams are not necessarily more effective than smaller ones. In this paper, we study why and under which conditions certain team structures promote effective learning for a population of individual learning agents. We show that, depending on the environment, some team structures help agents learn to specialize into specific roles, resulting in more favorable global results. However, large teams create credit assignment challenges that reduce coordination, leading to large teams performing poorly compared to smaller ones. We support our conclusions with both theoretical analysis and empirical results.": 0.15019655227661133}}