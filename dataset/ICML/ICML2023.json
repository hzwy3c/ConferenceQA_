{
    "ICML2023": {
        "Dates": {
            "ICML 2023 Meeting Dates": {
                "date": "Sun. Jul 23rd through Sat the 29th, 2023",
                "location": "the Hawaii Convention Center",
                "Sessions": [
                    {
                        "Session": "Expo",
                        "Start Date": "Sun Jul 23rd"
                    },
                    {
                        "Session": "Virtual Pass",
                        "Start Date": "Sun Jul 23rd through Sat the 29th"
                    },
                    {
                        "Session": "Tutorials",
                        "Start Date": "Mon Jul 24th"
                    },
                    {
                        "Session": "Conference Sessions",
                        "Start Date": "Tue Jul 25th through Thu the 27th"
                    },
                    {
                        "Session": "Workshops",
                        "Start Date": "Fri Jul 28th through Sat the 29th"
                    }
                ],
                "Dates by Category": {
                    "Attendees": {
                        "Registration Open": "Feb 03 '23 02:00 PM UTC",
                        "Early pricing before this date": "Jun 17 '23 06:59 AM UTC",
                        "Last chance for a refund on registration fees": "Jul 01 '23 11:59 PM UTC"
                    },
                    "Financial Assistance": {
                        "Grant Application Deadline": "Apr 14 '23 (Anywhere on Earth)",
                        "Grant Application Notification": "May 06 '23 01:00 AM UTC"
                    },
                    "Paper Submissions": {
                        "Paper Submissions Open on OpenReview": "Jan 09 '23 02:00 PM UTC",
                        "Full Paper Submission Deadline": "Jan 26 '23 07:59 PM UTC",
                        "Review release to authors": "Mar 13 '23 (Anywhere on Earth)",
                        "Author rebuttal period ends": "Mar 19 '23 07:00 PM UTC",
                        "Author Reviewer Discussion Ends": "Mar 26 '23 07:00 PM UTC",
                        "Reviewer-AC Discussion Starts": "Mar 27 '23 07:00 PM UTC",
                        "Reviewer-AC Discussion Ends": "Apr 02 '23 07:00 PM UTC",
                        "Metareview Deadline": "Apr 02 '23 07:00 PM UTC",
                        "SAC Agreement Period Start": "Apr 03 '23 02:00 PM UTC",
                        "SAC Agreement Period Ends": "Apr 09 '23 07:00 PM UTC",
                        "Paper Decision notification": "Apr 24 '23 (Anywhere on Earth)",
                        "Camera-ready version deadline": "May 31 '23 (Anywhere on Earth)",
                        "Poster Printing Service Deadline": "Jun 22 '23 (Anywhere on Earth)",
                        "SlidesLive Video Upload Deadline": "Jun 29 '23 (Anywhere on Earth)"
                    },
                    "Socials": {
                        "Socials Application Open": "Feb 01 '23 (Anywhere on Earth)",
                        "Social Deadline Date": "Jun 11 '23 (Anywhere on Earth)",
                        "Social Notification Date": "Jun 18 '23 (Anywhere on Earth)"
                    },
                    "Sponsors / Expo": {
                        "Sponsor Portal Open": "Dec 18 '22 07:59 PM UTC",
                        "Expo Calls Open": "Dec 26 '22 (Anywhere on Earth)",
                        "Expo Calls Deadline": "Jun 01 '23 04:00 AM UTC",
                        "Expo Decision Notifications": "Jun 07 '23 (Anywhere on Earth)"
                    },
                    "Tutorials": {
                        "Tutorial Proposal Submission Deadline": "Feb 17 '23 (Anywhere on Earth)",
                        "Tutorial Proposal Announcements": "May 12 '23 (Anywhere on Earth)"
                    },
                    "Volunteers": {
                        "Volunteer Application Closes": "May 23 '23 (Anywhere on Earth)",
                        "Volunteer Available Dates Due": "Jun 22 '23 (Anywhere on Earth)"
                    },
                    "Workshops": {
                        "Workshop Application Open": "Feb 01 '23 05:00 PM UTC",
                        "Workshop Application Deadline": "Feb 16 '23 (Anywhere on Earth)",
                        "Workshop Application Notification": "Mar 16 '23 10:00 PM UTC",
                        "Poster Printing Service Deadline": "Jun 22 '23 (Anywhere on Earth)"
                    }
                }
            }
        },
        "Calls": {
            "Call For Tutorials": {
                "introduction": [
                    "The ICML 2023 Organizing Committee invites proposals for tutorials to be given on Monday July 24th, 2023, immediately preceding the main conference.",
                    "We welcome proposals for tutorials on core machine learning topics and on topics of emerging importance for machine learning broadly. We encourage submission of tutorial proposals on any topic provided the tutorial is of interest to part of the ICML audience. Selection will take into account topic relevance and coverage, speaker experience and diversity considerations.",
                    "We plan to host a mix of invited and submitted tutorials. We anticipate hosting nine tutorials. Each tutorial will be two hours long, and will be given by one or two presenters.",
                    "Tutorial proposals should be submitted via this form by Friday, February 17th 2023. Please submit a PDF of approx. 5 pages excluding references. Acceptance and rejection decisions will be announced on Friday, May 12th 2023."
                ],
                "Tutorial proposals should answer the following questions": [
                    "Title",
                    "Brief description and outline: What will the tutorial be about? Please provide an outline of what you plan to cover, including references and details on how much time you will spend on each topic. We encourage the presenters to demonstrate coverage and representativeness of the chosen area of research, not to focus solely on their own results or tools. ",
                    "Goals: What objectives does the tutorial serve? Why is it important to include it as a part of ICML 2023?",
                    "Target audience: Who is your target audience? How many participants do you expect to see? What kind of background do you expect them to have?",
                    "Presenters: Please include the names and email addresses of the presenters, along with brief bios and the description of each presenter’s expertise in the tutorial area. We suggest that each tutorial is given by at most two presenters. If there is more than one presenter, please describe how time will be split. If available, please include samples of your past talks (or other relevant) slides or links to video recordings on the topic.",
                    "Previous tutorials: What are the related or similar tutorials presented in the past 3 years at ICML or at other venues? Please list the dates and venues, and describe the similarities and differences to the proposal.",
                    "The tutorial presenters need to strongly commit to present the tutorial in person. Note that ICML may be able to partially reimburse travel, lodging, and conference costs for tutorial presenters who would otherwise not be able to attend the conference."
                ],
                "Tutorial proposals should be submitted via this form(url)": "https://docs.google.com/forms/d/e/1FAIpQLSfyrcQz5J3zjd-U6I8NmvVw_8k7UrtSJpG1hsWD3hRCN0uKyA/viewform",
                "contact way": "tutorial@icml.cc .",
                "Tutorial Chairs, ICML 2023": "Bo Li, Hanie Sedghi, Martin Jaggi"
            },
            "Call For Papers": {
                "introduction": [
                    "The 40th International Conference on Machine Learning (ICML 2022) will be held in Honolulu, Hawaii USA July 23rd - July 29th, 2023, and is planned to be an in person conference with virtual elements. In addition to the main conference sessions, the conference will also include Expo, Tutorials, and Workshops. Please submit proposals to the appropriate chairs.",
                    "We invite submissions of papers on all topics related to machine learning for the main conference proceedings. All papers will be reviewed in a double-blind process and accepted papers will be presented at the conference. As with last year, papers need to be prepared and submitted as a single file: 8 pages as main paper, with unlimited pages for references and appendix. There will be no separate deadline for the submission of supplementary material. In addition, we require that, barring exceptional circumstances (such as visa problems) upon the acceptance of their papers, at least one of the authors must attend the conference, in person.",
                    "Papers published at ICML are indexed in the Proceedings of Machine Learning Research through the Journal of Machine Learning Research."
                ],
                "Important Dates:": {
                    "notice": "As noted above, this year, ICML will use a single paper submission deadline with a single review cycle, as follows.",
                    "Submissions open": "Jan 9th, 2023",
                    "Full paper submission deadline": "Jan 26th, 2023 3pm EST"
                },
                "Abstracts and papers can be submitted through OpenReview": " https://openreview.net/group?id=ICML.cc/2023/Conference",
                "Topics of interest include (but are not limited to)": [
                    "General Machine Learning (active learning, clustering, online learning, ranking, reinforcement learning, supervised, semi- and self-supervised learning, time series analysis, etc.)",
                    "Deep Learning (architectures, generative models, deep reinforcement learning, etc.)",
                    "Learning Theory (bandits, game theory, statistical learning theory, etc.)",
                    "Optimization (convex and non-convex optimization, matrix/tensor methods, stochastic, online, non-smooth, composite, etc.)",
                    "Probabilistic Inference (Bayesian methods, graphical models, Monte Carlo methods, etc.)",
                    "Trustworthy Machine Learning (accountability, causality, fairness, privacy, robustness, etc.)",
                    "Applications (computational biology, crowdsourcing, healthcare, neuroscience, social good, climate science, etc.)"
                ],
                "Proceedings of Machine Learning Research(url)": "https://proceedings.mlr.press/",
                "Policies": {
                    "Deadlines": "Abstract and paper submission deadlines are strict. In no circumstances will extensions be given.",
                    "Changes of title/abstract/authorship": "Authors should include a full title for their paper, as well as a complete paper by the paper submission deadline. Submission titles should not be modified after the paper submission deadline. Submissions violating these rules may be deleted after the paper submission deadline without reviewing. The author list at the paper submission deadline will be considered final, and no changes in authorship will be permitted for accepted papers.",
                    "Double-Blind Review": [
                        "All submissions must be anonymized and may not contain any information with the intention or consequence of violating the double-blind reviewing policy, including (but not limited to) citing previous works of the authors or sharing links in a way that can infer any author’s identity or institution, actions that reveal the identities of the authors to potential reviewers.",
                        "Authors are allowed to post versions of their work on preprint servers such as arXiv. They are also allowed to give talks to restricted audiences on the work(s) submitted to ICML during the review. If you have posted or plan to post a non-anonymized version of your paper online before the ICML decisions are made, the submitted version must not refer to the non-anonymized version.",
                        "ICML strongly discourages advertising the preprint on social media or in the press while under submission to ICML. Under no circumstances should your work be explicitly identified as ICML submission at any time during the review period, i.e., from the time you submit the paper to the communication of the accept/reject decisions."
                    ],
                    "Dual Submission": "It is not appropriate to submit papers that are identical (or substantially similar) to versions that have been previously published, accepted for publication, or submitted in parallel to other conferences or journals. Such submissions violate our dual submission policy, and the organizers have the right to reject such submissions, or to remove them from the proceedings. Note that submissions that have been or are being presented at workshops do not violate the dual-submission policy, as long as there’s no associated archival publication.",
                    "Reviewing Criteria": "Accepted papers must be based on original research and must contain novel results of significant interest to the machine learning community. Results can be either theoretical or empirical. Results will be judged on the degree to which they have been objectively established and/or their potential for scientific and technological impact. Reproducibility of results and easy availability of code will be taken into account in the decision-making process whenever appropriate.",
                    "Ethics": {
                        "introduction": "Authors and members of the program committee, including reviewers, are expected to follow standard ethical guidelines. Plagiarism in any form is strictly forbidden as is unethical use of privileged information by reviewers, ACs, and SACs, such as sharing this information or using it for any other purpose than the reviewing process. Papers that include text generated from a large-scale language model (LLM) such as ChatGPT are prohibited unless these produced text is presented as a part of the paper’s experimental analysis. All suspected unethical behaviors will be investigated by an ethics board and individuals found violating the rules may face sanctions. This year, we will collect names of individuals that have been found to have violated these standards; if individuals representing conferences, journals, or other organizations request this list for decision making purposes, we may make this information available to them. ",
                        "Details of the LLM guideline": {
                            "Clarification on Large Language Model Policy LLM": [
                                "We (Program Chairs) have included the following statement in the Call for Papers for ICML represented by 2023:",
                                "Papers that include text generated from a large-scale language model (LLM) such as ChatGPT are prohibited unless the produced text is presented as a part of the paper’s experimental analysis.",
                                "This statement has raised a number of questions from potential authors and led some to proactively reach out to us. We appreciate your feedback and comments and would like to clarify further the intention behind this statement and how we plan to implement this policy for ICML 2023.",
                                "TLDR;",
                                "The Large Language Model (LLM) policy for ICML 2023 prohibits text produced entirely by LLMs (i.e., “generated”).  This does not prohibit authors from using LLMs for editing or polishing author-written text. ",
                                "The LLM policy is largely predicated on the principle of being conservative with respect to guarding against potential issues of using LLMs, including plagiarism.",
                                "The LLM policy applies to ICML 2023. We expect this policy may evolve in future conferences as we understand LLMs and their impacts on scientific publishing better.  "
                            ],
                            "Intention": [
                                "During the past few years, we have observed and been part of rapid progress in large-scale language models (LLM), both in research and deployment. This progress has not slowed down but only sped up during the past few months. As many, including ourselves, have noticed, LLMs released in the past few months, such as OpenAI’s chatGPT, are now able to produce text snippets that are often difficult to distinguish from human-written text. Undoubtedly this is  exciting progress in natural language processing and generation.",
                                "Such rapid progress often comes with unanticipated consequences as well as unanswered questions. As we have already seen during the past few weeks alone, there is, for instance, a question on whether text as well as images generated by large-scale generative models are considered novel or mere derivatives of existing work. There is also a question on the ownership of text snippets, images or any media sampled from these generative models: which one of these owns it, a user of the generative model, a developer who trained the model, or content creators who produced training examples? It is certain that these questions, and many more, will be answered over time, as these large-scale generative models are more widely adopted. However, we do not yet have any clear answers to any of these questions. ",
                                "Since how we answer these questions directly affects our reviewing process, which in turn affects members of our research community and their careers, we must be careful and somewhat conservative in considering this new technology. OpenAI released the beta version of ChatGPT at the end of November 2022, which is less than two months ago. Unfortunately, we have not had enough time to observe, investigate and consider its implications for our reviewing and publication process. We thus decided to prohibit producing/generating ICML paper text using large-scale language models this year (2023).  ",
                                "Although we are prohibiting text generated by LLMs this year, we plan to investigate and discuss the impact, both positive and negative, of LLMs on reviewing and publishing in the field of machine learning and AI. This decision will be revisited for future iterations of ICML. "
                            ],
                            "Implementation and Enforcement": [
                                "Regardless of what kind of technologies are available, we understand that many authors use external assistive technologies. Such assistive technologies include semi-automated editing tools, such as Grammarly, and various forms of online dictionaries and machine translation systems. Along these lines, we do not prohibit authors from using LLMs for light editing of their own text. In other words, as long as these LLM tools are used similarly to automate grammar checks, word autocorrect, and other editing tools, this new policy does not apply. ",
                                "As some have pointed out, and as we are also well aware of ourselves, it is difficult to detect whether any given text snippet was produced by a language model. The ICML leadership team does not plan to implement any automated or semi-automated system to be run on submissions to check for the violation of the LLM policy this year (2023). Instead, we plan to investigate any potential violation of the LLM policy when a submission is brought to our attention with a significant concern about a potential violation.. Any submission flagged for the potential violation of this LLM policy will go through the same process as any other submission flagged for plagiarism.",
                                "As we learn more about consequences and impacts of LLMs in academic publication, and as we redesign the LLM policy in future conferences (after ICML 2023), we will consider different options and technologies to implement and enforce the latest LLM policy in future iterations."
                            ]
                        }
                    },
                    "Financial aid": "Each paper submission may, by providing a corresponding icml.cc account email address, designate up to one student author who, should the paper be accepted, would not be able to present the work unless partially supported by a grant from the conference.  Doing so confirms (1) financial need, (2) intention to attend and present in person and (3) willingness to volunteer at the conference for two 4 hour shifts.  ICML aims to provide free conference registration and hotel registration for at least part of the week.  The number of such awards are limited.",
                    "notice": "Author Instructions, Style Files and an Example Paper. Submitted papers that do not conform to these policies will be rejected without review. Authors are kindly asked to make their submissions as accessible as possible for everyone including people with disabilities and sensory or neurological differences.",
                    "OpenReview and Rankings": "This year we will use OpenReview and we will require that authors of multiple submissions, upon submission confirmation, submit a rank ordering of their papers from their own perspective. For this year, we seek this information to assess consistency of self-perception with respect to review outcomes. We will not share rankings with co-authors, reviewers, ACs, or SACs. Rankings will not be used in decision-making processes.",
                    "Author Instructions(url)": "https://icml.cc/Conferences/2023/StyleAuthorInstructions",
                    "Style Files(url)": "https://media.icml.cc/Conferences/ICML2023/Styles/icml2023.zip",
                    "Example Paper(url)": "https://media.icml.cc/Conferences/ICML2023/Styles/example_paper.pdf"
                },
                "Author Instructions": {
                    "Registration": "We require that each accepted paper have at least one author with a in-person conference registration even if in-person attendance is not possible.",
                    "Videos": "Each paper will be given the opportunity to record a 5 min video. This video will be available on the website on your papers page. SlidesLive will send out an email with the details",
                    "MyStuff(url)": "https://icml.cc/MyStuff",
                    "Orals": "If your paper was selected as an oral you will also have the opportunity to present a 8 min presentation in-person at the conference. The orals in-person only there will be no pre-recordered or remote oral presentations",
                    "Posters": {
                        "introductions": [
                            "Poster upload and printing instructions",
                            "For instructions on how to request a change in your assigned your poster session visit this page "
                        ],
                        "Poster Upload": {
                            "Instructions": [
                                "Please upload your poster and thumbnail on this page so it will be avaiable to attendees who visit the website.",
                                "Also upload a thumbnail of the most visually appealing figure in your paper. ",
                                "If you don't see your papers listed, check the wiki.",
                                "If you expected to see paper(s) listed here, read about what can cause this issue on our wiki page."
                            ],
                            "wiki(url)": "https://wiki.eventhosts.cc/en/reference/posteruploads#what-if-i-dont-see-my-paper-listed-on-the-poster-uploads-page"
                        },
                        "Poster Board Sizes": {
                            "Main Conference": "The poster boards are in landscape orientation, and can be up to 72'w x 36'h",
                            "Workshops": "Posters will be in portrait orientation and up to 24'w x 36'h"
                        },
                        "Poster Printing": {
                            "Poster Printing Service": {
                                "We offer a optional Poster Printing Service ": [
                                    "Instructions",
                                    "Deadline to order is June 22",
                                    "Pick it up onsite"
                                ],
                                "instructions": {
                                    "url": "https://icml.cc/posterprinting/",
                                    "Onsite Poster Printing Service": [
                                        "We are beta testing the ICML poster printing service, which allows you to upload a poster PDF or Adobe Illustrator image to be printed and available for pickup onsite at the convention center (Hawaii Convention Center, Honolulu). ",
                                        "The deadline to upload artwork for printing a poster is June 25, 2023, 2:59 p.m. You or your co-authors may update your artwork by re-uploading a new image any time before the deadline. The deadline has past ."
                                    ],
                                    "Requirements": [
                                        "You must have a poster .",
                                        "For each poster you have, click it's name in the poster list below to upload. Pay after you have uploaded images for all your posters.",
                                        "We cannot cancel an order once it's submitted, although you may update your poster image before the deadline. Once you have paid, you cannot change the size of the poster. Coordinate with your co-authors to make sure there is only one upload per paper.",
                                        "Accepted File Forms: PDF, Adobe Illustrator. If Adobe Illustrator, outline all fonts. Embed all linked assets and fonts. If your image contains images, they must be high resolution (150-300 dpi at full size).",
                                        "If you need help, contact us."
                                    ]
                                },
                                "Wiki Instructions": {
                                    "Virtual Poster Instructions": "https://wiki.eventhosts.cc/en/reference/poster-presenter-instructions",
                                    "Physical Poster Instructions.": "https://wiki.eventhosts.cc/en/reference/physical-poster-presenter-instructions"
                                }
                            }
                        }

                    },
                    "Submissions": {
                        "instructions": [
                            "Submitted papers are composed of a main body, which can be up to eight pages long, followed by unlimited pages for references and an appendix, all in a single file. Note that upon the acceptance of the paper, ICML will publish the submission as a whole: That is, the camera ready version will include the appendices (and references). For details concerning the format of the papers, please see the LaTeX style files, an example paper, and the Call For Papers. There is no support for any software other than LaTeX. All submissions must be via OpenReview, anonymized, and must closely follow the formatting guidelines in the templates; otherwise, they will automatically be rejected. In particular, any submission whose main body goes over the 8 page limit will be automatically rejected. (For the final version, an extra page will be allowed. See the example paper for further information.)",
                            "As in previous years, authors have the option of uploading extra files to provide further details of their work. The files included in the supplementary may contain code that supports experimental findings, or extra data, or other (anonymized) papers of the authors whose results are needed by the submitted paper. It is entirely up to the reviewers to decide whether they wish to consult any of the appendices in the submitted paper or this additional material. Therefore, if there is material critical to the evaluation of the paper, it needs to be included in the main body of the paper.",
                            "Authors are encouraged to submit code to foster reproducibility. Reproducibility of results and easy availability of code will be taken into account in the decision-making process. Authors should avoid submitting links to non-anonymized repositories and instead submit the code base itself or anonymized repositories.",
                            "Previously published papers with substantial overlap written by the authors must be cited in such a way so as to preserve author anonymity. Differences relative to these earlier papers must be explained in the text of the submission. For example: “This work builds on [reference], which showed that…”. "
                        ],
                        "LaTeX style files(url)": "https://media.icml.cc/Conferences/ICML2023/Styles/icml2023.zip",
                        "example paper(url)": "https://media.icml.cc/Conferences/ICML2023/Styles/example_paper.pdf",
                        "Call For Papers(url)": "https://icml.cc/Conferences/2023/CallForPapers"
                    },
                    "Accessibility and Inclusiveness": {
                        "introduction": "We kindly ask all authors to follow our guidelines for writing accessible papers. In particular, we expect that authors (1) review guidelines for accessibility to color-blind and visually impaired; (2) ensure their bibliography is up-to-date, including up-to-date names and venues; (3) use inclusive and respectful language throughout when talking about people.",
                        "our guidelines(url)": "https://icml.cc/Conferences/2023/AccessiblePapersAndTalks"
                    },
                    "Double-Blind Reviewing": "Reviewing for ICML 2023 is double-blind; i.e., reviewers will not know the authors’ identity (and vice versa). Detailed instructions for how to ensure anonymity are also contained in the above example paper. In brief, authors should refer to their prior work in the third person wherever possible. They should refrain from including acknowledgements, grant numbers, or public github repository links in their submissions. If an anonymous reference is needed in the paper (e.g., for referring to the authors’ own work that is under review elsewhere), include the referred work as supplementary material as noted above. Note that anonymizing the submissions is mandatory, and papers that explicitly or implicitly reveal the authors’ identities will be rejected. A reviewer may be able to deduce the authors’ identities by using external resources, such as technical reports published on the web. The availability of information on the web that may allow reviewers to infer the authors’ identities does not constitute a breach of the double-blind submission policy. Reviewers are explicitly asked not to seek this information.",
                    "Supplementary Material": [
                        "ICML 2023 supports the submission of two kinds of supplementary material -- supplementary manuscripts and code/data. In particular, if an anonymous reference is made in the paper, authors should upload the referenced papers, so that the reviewers can check the results in the referred paper. The supplementary material must also be anonymized.",
                        "For code submissions, we expect authors to anonymize the submitted code. This means that author names and licenses should be removed. Submission of code through anonymous GitHub repositories is allowed; however, they have to be on a branch that will not be modified after the submission deadline. Please enter the GitHub link in a standalone text file in a submitted zip file.",
                        "Data submissions (provided that the authors have the right to do so) in anonymous repositories are welcome.",
                        "The supplementary code can be submitted as either a zip file or a pdf.",
                        "Supplementary material will not be published or archived, and there are no format restrictions. Authors are therefore responsible for the archival and access of the supplementary if they want to refer to it in the final version of their paper."
                    ],
                    "Reviewer Matching": "ICML uses the Toronto Paper Matching System (TPMS) in the process of assigning submissions to reviewers and area chairs. During the submission process, authors will be asked to agree to the use of TPMS.",
                    "Dual Submission Policy": [
                        "It is not appropriate to submit papers that are substantially similar (or identical) in content to versions that have been previously published, or accepted for publication, or that are under review at other peer reviewed conferences or journals at any time while they are also under consideration for ICML. Such submissions violate our dual submission policy and will be rejected.",
                        "Submission is permitted for papers presented or to be presented at conferences or workshops without proceedings (e.g., ICML or NeurIPS workshops), or with only abstracts (limited to at most 4 pages) published.",
                        "Submission is permitted for papers that have previously been made available as a technical report or preprint. In this case, we suggest the authors not cite the report to preserve anonymity."
                    ],
                    "Single-phase reviewing process": "This year, ICML is following a single-phase reviewing process. In phase 1, all papers will be allocated to three or more reviewers. After all reviews are received, reviews will be made available to the authors, who are given a chance in a rebuttal process to provide feedback to the reviewers, which will be used in a reviewer discussion and the final decision making process. All decisions made are final.",
                    "Author Feedback": [
                        "From March 13 to March 19, authors can see the reviews and respond to their content.",
                        "The response will be used by the Program Committee in their judgment of the paper. This year, the response must be submitted via OpenReview.",
                        "Authors can submit multiple responses per submission. Any of the authors of a paper can enter/edit the response, and the response can be returned to and edited up to the deadline for author feedback.",
                        "As reviewing is double-blind, authors should not include any identifying information in their response. No non-anonymized URLs can be included in the response.",
                        "We recommend using judgment when crafting a response. There is no need to respond to every minor question or suggestion for improvement. Rather, the response is a good opportunity for addressing issues like a reviewer’s uncertainty about a point, a reviewer making an incorrect assumption, or a reviewer misunderstanding some part of the paper. A professional and polite language is generally the most effective."
                    ],
                    "Miscellaneous information related to the author feedback and reviews": {

                        "introductions": [
                            "We aim to provide three reviews for every paper. The reviewer numbers are arbitrary, do not read much into them. The reviews do not include scores. Further information on what the reviews should include, consult the reviewer tutorial, the annotated review form and a presentation on how to be a good reviewer that was sent to all the reviewers.",
                            "The structure of the author response is up to the authors. It is typical to organize the response by reviewers. Here, use the reviewer numbers to refer to the particular reviews. ",
                            "The author feedback will be visible to the reviewers, meta-reviewers, senior meta-reviewers (just those assigned to the paper) and the program chairs.",
                            "There is no option to upload a revised version of the paper during the author feedback period. Upon the acceptance of the paper, it is up to the authors to include any changes to improve the paper (without essentially changing its content, compared to what the reviewers have seen) in the final, camera ready version of the paper."
                        ],
                        "reviewer tutorial(url)": "https://icml.cc/Conferences/2023/ReviewerTutorial",
                        "annotated review form(url)": "https://icml.cc/Conferences/2023/ReviewForm",
                        "presentation": "https://drive.google.com/file/d/15hPTA64h31ShaoybLWeU3moZan7zVbr_/view?pli=1"
                    },
                    "Details about submitting rebuttals on OpenReview": [
                        "Rebuttals are per review.",
                        "Rebuttals do not need to be submitted at the same time, and at any time up to the deadline (Sunday 3/19/23 3pm ET).",
                        "While the length is short, multiple rebuttals per review are allowed in OpenReview.",
                        "Links are allowed, but the link must be anonymous to preserve double-blind review, both in the URL and the destination.",
                        "Use the “Rebuttal” button instead of “Official comment” for your rebuttals. If you previously submitted a rebuttal as a comment, please delete that and add it as a rebuttal.",
                        "Currently, the “Rebuttal” text is only available to PCs, but it will be released to reviewers, ACs, and SACs as of Sunday at 3pm ET.",
                        "Use “Official comment” to talk directly with ACs or SACs, to request a new review or discuss an existing review. To do this, select the “Reader groups” to include just the ACs, SACs, or PCs, but not reviewers.",
                        "You will have an opportunity to respond to any review submitted before the rebuttal deadline. ",
                        "Reviews will not be made public regardless of the paper acceptance. Only papers that have been accepted will have their titles, abstracts, authors, and PDFs released publicly."
                    ],
                    "Code of Conduct": "Authors will be asked to confirm that their submissions accord with the ICML code of conduct."
                },
                "Paper Guidelines": {
                    "introduction": [
                        "The ICML Paper Guidelines is based on the NeurIPS 2022 Paper checklist, introduced in 2021 (see blog post). Our goal is to promote best practices for responsible machine learning research, including reproducibility, ethics, transparency, and impact on society. You should check your paper and supplemental materials in the context of each part of our guidelines.",
                        "Reviewers will be asked to also consider these guidelines as a factor in their evaluations. "
                    ],
                    "NeurIPS 2022 Paper checklist": {
                        "url": "https://neurips.cc/Conferences/2022/PaperInformation/PaperChecklist",
                        "guidelines": [
                            "The NeurIPS Paper Checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. For each question in the checklist:",
                            "You should answer yes, no, or n/a.",
                            "You should reference the section(s) of the paper that provide support for your answer.",
                            "You can also optionally write a short (1–2 sentence) justification of your answer.",
                            "You are encouraged to take a look at the checklist early on as it likely will positively influence the way you do your research and write the paper, rather than treating it as an afterthought.",
                            "Reviewers will be asked to use the checklist as one of the factors in their evaluation. The questions are mostly framed in terms of transparency: \"Did you include [information]?\" While \"yes\" is generally preferable to \"no\", it is perfectly acceptable to answer \"no\" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"no\" or \"n/a\" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgement and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material.",
                            "We provide guidance on how to answer each question below. You may additionally refer to the blog post from 2021 introducing the checklist to learn more about its motivation and how it was created.",
                            "1. For all authors...",
                            "(a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?",
                            "Claims in the paper should match theoretical and experimental results in terms of how much the results can be expected to generalize.",
                            "The paper's contributions should be clearly stated in the abstract and introduction, along with any important assumptions and limitations. It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.",
                            "(b) Have you read the ethics review guidelines and ensured that your paper conforms to them?",
                            "Please read the ethics review guidelines.",
                            "(c) Did you discuss any potential negative societal impacts of your work?",
                            "Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), environmental impact (e.g., training huge models), fairness considerations (e.g., deployment of technologies that could further disadvantage historically disadvantaged groups), privacy considerations (e.g., a paper on model/data stealing), and security considerations (e.g., adversarial attacks).",
                            "We expect many papers to be foundational research and not tied to particular applications, let alone deployments, but being foundational does not imply that research has no societal impacts. If you see a direct path to any negative applications, you should point it out, even if it's not specific to your work. In a theoretical paper on algorithmic fairness, you might caution against overreliance on mathematical metrics for quantifying fairness and examples of ways this can go wrong. If you improve the quality of generative models, you might point out that your approach can be used to generate Deepfakes for disinformation. On the other hand, if you develop a generic algorithm for optimizing neural networks, you do not need to mention that this could enable people to train models that generate Deepfakes faster.",
                            "Consider different stakeholders that could be impacted by your work. It is possible that research benefits some stakeholders while harming others. Pay special attention to vulnerable or marginalized communities.",
                            "Consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.",
                            "If there are negative societal impacts, you should also discuss any mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).",
                            "For more information, see this unofficial guidance from last year and other resources at the broader impacts workshop at NeurIPS 2020.",
                            "(d) Did you describe the limitations of your work?",
                            "You are encouraged to create a separate \"Limitations\" section in your paper.",
                            "Point out any strong assumptions and how robust your results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). Reflect on how these assumptions might be violated in practice and what the implications would be.",
                            "Reflect on the scope of your claims, e.g., if you only tested your approach on a few datasets or did a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.",
                            "Reflect on the factors that influence the performance of your approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be able to be reliably used to provide closed captions for online lectures because it fails to handle technical jargon.",
                            "We understand that authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection. It is worth keeping in mind that a worse outcome might be if reviewers discover limitations that aren't acknowledged in the paper. In general, we advise authors to use their best judgement and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.",
                            "2. If you are including theoretical results...",
                            "(a) Did you state the full set of assumptions of all theoretical results?",
                            "All assumptions should be clearly stated or referenced in the statement of any theorems.",
                            "(b) Did you include complete proofs of all theoretical results?",
                            "The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, authors are encouraged to provide a short proof sketch to provide intuition.",
                            "You are encouraged to discuss the relationship between your results and related results in the literature. ",
                            "3. If you ran experiments...",
                            "(a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)?",
                            "The instructions should contain the exact command and environment needed to run to reproduce the results.",
                            "Please see the NeurIPS code and data submission guidelines for more details.",
                            "Main experimental results include your new method and baselines. You should try to capture as many of the minor experiments in the paper as possible. If a subset of experiments are reproducible, you should state which ones are.",
                            "While we encourage release of code and data, we understand that this might not be possible, so \"no because the code is proprietary\" is an acceptable answer.",
                            "At submission time, to preserve anonymity, remember to release anonymized versions.",
                            "(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?",
                            "The full details can be provided with the code, but the important details should be in the main paper.",
                            "(c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?",
                            "Answer \"yes\" if you report error bars, confidence intervals, or statistical significance tests for your main experiments.",
                            "(d) Did you include the amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?",
                            "Ideally, you would provide the compute required for each of the individual experimental runs as well as the total compute.",
                            "Note that your full research project might have required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). The total compute used may be harder to characterize, but if you can do that, that would be even better.",
                            "You are also encouraged to use a CO2 emissions tracker and provide that information. See, for example, the experiment impact tracker (Henderson et al.), the ML CO2 impact calculator (Lacoste et al.), and CodeCarbon.",
                            "4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...",
                            "(a) If your work uses existing assets, did you cite the creators?",
                            "Cite the original paper that produced the code package or dataset.",
                            "Remember to state which version of the asset you're using.",
                            "If possible, include a URL.",
                            "(b) Did you mention the license of the assets?",
                            "State the name of the license (e.g., CC-BY 4.0) for each asset.",
                            "If you scraped data from a particular source (e.g., website), you should state the copyright and terms of service of that source.",
                            "If you are releasing assets, you should include a license, copyright information, and terms of use in the package. If you are using a popular dataset, please check paperswithcode.com/datasets, which has curated licenses for some datasets. You are also encouraged to use their licensing guide to help determine the license of a dataset.",
                            "If you are repackaging an existing dataset, you should state the original license as well as the one for the derived asset (if it has changed).",
                            "If you cannot find this information online, you are encouraged to reach out to the asset's creators.",
                            "(c) Did you include any new assets either in the supplemental material or as a URL?",
                            "During submission time, remember to anonymize your assets. You can either create an anonymized URL or include an anonymized zip file.",
                            "If you cannot release (e.g., the asset contains proprietary information), state the reason.",
                            "(d) Did you discuss whether and how consent was obtained from people whose data you're using/curating?",
                            "For example, if you collected data from via crowdsourcing, did your instructions to crowdworkers explain how the data would be used?",
                            "Even if you used an existing dataset, you should check how data was collected and whether consent was obtained. We acknowledge this might be difficult, so please try your best; the goal is to raise awareness of possible issues that might be ingrained in our community.",
                            "(e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content?",
                            "There are some settings where the existence of this information is not necessarily bad (e.g., swear words occur naturally in text). This question is just to encourage discussion of potentially undesirable properties.",
                            "Explain how you checked this (e.g., with a script, manually on a sample, etc.).",
                            "5. If you used crowdsourcing or conducted research with human subjects...",
                            "(a) Did you include the full text of instructions given to participants and screenshots, if applicable?",
                            "Including this information in the supplemental material is fine, but if the main contribution of your paper involves human subjects, then we strongly encourage you to include as much detail as possible in the main paper.",
                            "(b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable?",
                            "Examples of risks include a crowdsourcing experiment which might show offensive content or collect personal identifying information (PII). Ideally, the participants should be warned.",
                            "Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.  For initial submissions, do not include any information that would break anonymity, such as the institution conducting the review.",
                            "(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?",
                            "First, provide the amount paid for each task (including any bonuses), and discuss how you determined the amount of time a task would take."
                        ],
                        "blog post(url)": "https://neuripsconf.medium.com/introducing-the-neurips-2021-paper-checklist-3220d6df500b",
                        "ethics review guidelines.(url)": "https://neurips.cc/public/EthicsGuidelines",
                        "unofficial guidance(url)": "https://medium.com/@GovAI/a-guide-to-writing-the-neurips-impact-statement-4293b723f832",
                        "broader impacts workshop(url)": "https://nbiair.com/",
                        "code and data submission guidelines(url)": {
                            "url": "https://nips.cc/Conferences/2021/PaperInformation/CodeSubmissionPolicy",
                            "NeurIPS 2021 Code and Data Submission Guidelines": [
                                "If any of the main contributions of your paper depends on an experimental result, you are strongly encouraged to submit code that produces this result. If you are using a new dataset, you are also encouraged to submit the dataset.",
                                "If you are submitting your code or data for reviewing, you must anonymize it and include it in a single zip file along with any additional supplementary material (e.g., appendices). Small datasets can also be included in such zip file (which must be <100MB). Large datasets can instead be linked to via an anonymous URL. Reviewers will be asked to keep any submitted code and data in strict confidentiality and use it only for reviewing purposes. The supplementary material deadline is one week after the paper submission deadline.",
                                "If you are including code or data with the camera-ready version of your accepted paper, you should de-anonymize it (including any URLs). If any of the main contributions of your accepted paper depends on an experimental result, it’s best practice for responsible research to include code that produces this result."
                            ],
                            "Code Guidelines": {
                                "introductions": [
                                    "our code submission should include training and evaluation code, specification of dependencies, etc. See https://github.com/paperswithcode/releasing-research-code for more detailed guidelines.",
                                    "Your code submission ideally should be self-contained and executable. If this is not the case, you must explain why. Possible reasons might include:",
                                    "1. Specialized hardware is required to run the experiment (e.g., specialized accelerators or robotic platforms).",
                                    "2. The code depends on non-open-sourced or non-free libraries, which do not include the algorithm that is claimed as the scientific contribution of the paper (e.g., paid-for mathematical programming solvers, commercial simulators, MATLAB)."
                                ],
                                "detailed guidelines(url)": "https://github.com/paperswithcode/releasing-research-code"
                            },
                            "Data Guidelines": {
                                "introductions": [
                                    "If you are submitting a new dataset, please carefully consider the relevant questions in the NeurIPS 2021 paper checklist. You are also encouraged to conform to the following best practices:",
                                    "Link to the dataset from the paper (anonymized for reviewing, de-anonymized for camera ready).",
                                    "Place the dataset in a repository that ensures long-term preservation of the data.",
                                    "The dataset should have a persistent identifier such as Digital Object Identifier or Compact Identifier.",
                                    "The dataset should adhere to Schema.org or DCAT metadata standards.",
                                    "The license and/or any data access restrictions should be described in the paper.",
                                    "If it is impossible to conform to the above suggestions, then you should include a justification."
                                ],
                                "NeurIPS 2021 paper checklist(url)": "https://github.com/paperswithcode/releasing-research-code"
                            }
                        },
                        "experiment impact tracker": {
                            "author": "Henderson et al.",
                            "url": "https://github.com/Breakend/experiment-impact-tracker"
                        },
                        "ML CO2 impact calculator": {
                            "url": "https://mlco2.github.io/impact/",
                            "author": "Lacoste et al."
                        },
                        "CodeCarbon(url)": "https://codecarbon.io/",
                        "paperswitchcode.com/datasets(url)": "https://paperswithcode.com/datasets",
                        "licensing guide(url)": "https://paperswithcode.com/datasets/license"
                    },
                    "best research practices": {
                        "Have you read the publication ethics guidelines and ensured that your paper conforms to them?": {},
                        "Did you discuss any potential negative societal impacts (for example, disinformation, privacy, fairness) of your work?": [
                            "Have you read the publication ethics guidelines and ensured that your paper conforms to them?",
                            "Did you discuss any potential negative societal impacts (for example, disinformation, privacy, fairness) of your work?",
                            "For example, these could include if you see a direct path to negative applications, some stakeholders may be impacted negatively even if others are benefited, consider possible harms through intended use or misuse. ",
                            "You may also find this unofficial guidance and other resources at the broader impacts workshop at NeurIPS 2020 helpful.",
                            "If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...",
                            "If your work uses existing assets, did you cite the creators and the version?",
                            "Did you mention the license of the assets?",
                            "If you scraped data from a particular source (e.g., Twitter), you should state the copyright and terms of service of that source.",
                            "If you are releasing assets, you should include a license, copyright information, and terms of use in the package.",
                            "If you are using an existing dataset, check paperswithcode.com/datasets, which has curated licenses for some datasets. Use their licensing guide to determine the license of a dataset.",
                            "If you are repackaging an existing dataset, you should state the original license as well as the one for the derived asset (if it has changed).",
                            "Did you include any new assets either in the supplemental material or as a URL?",
                            "For initial review, anonymize your assets. You can either create an anonymized URL or include an anonymized zip file.",
                            "If you cannot release (e.g., the asset contains proprietary info), state why.",
                            "Where possible, discuss whether and how consent was obtained from people whose data you're using/curating ",
                            "Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content?",
                            "This question is to encourage discussion of potentially undesirable properties and the goals of the research.",
                            "Offensive material (as data) in your manuscript may target specific vulnerable populations, and a reviewer may be a member of that population. Please refer to the Code of Conduct when selecting materials for inclusion in the manuscript to avoid this type of targeting.",
                            "If you used crowdsourcing or conducted research with human subjects...",
                            "Did you include the instructions given to participants including the consent form?",
                            "Did you describe any potential participant risks?",
                            "Examples of risks include a crowdsourcing experiment that might show offensive content or collect personal identifying information (PII).",
                            "If you obtained IRB approval, you should clearly state this in the paper. For initial submissions, do not include information that would break anonymity.",
                            "Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation?"
                        ],
                        "Next, we review best practices for paper writing and structure…": [
                            "Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?",
                            "Did you describe the limitations of your work?",
                            "For more guidance, please refer to this 2022 FAccT paper by Smith, et al.",
                            "If you are including theoretical results...",
                            "Did you state the full set of assumptions of all theoretical results?",
                            "Did you include complete proofs of all theoretical results?",
                            "If you ran experiments...",
                            "Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL, in an anonymized way at the review time)?",
                            "Please include a README about how to reproduce the results in the paper using the provided code. ",
                            "While we encourage release of code and data, we understand that this might not be possible, so no because the code is proprietary is acceptable. ",
                            "Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?",
                            "Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?",
                            "Did you include the amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?"
                        ]
                    }
                },
                "Accessiblity Instructions": {
                    "title": "Making ICML Papers, Talks, and Posters Accessible and Inclusive",
                    "introduction": "To foster inclusive culture and ensure that as many people as possible can participate in the conference and enjoy your paper when published, everyone is expected to make their papers and talks accessible and inclusive. Below are expectations around each.",
                    "Papers": {
                        "Accessibility": {
                            "introduction": "Having an accessible paper means that your work can be reviewed by all of our reviewers and enjoyed by the broadest possible audience, including disabled and neurodivergent people. Please follow the guidelines below to assure your paper is accessible. We have developed these guidelines in collaboration with the NAACL 2022 team, and the NAACL 2022 blog post contains additional details and resources.",
                            "NAACL 2022 blog post(url)": "https://2022.naacl.org/blog/publication-accessibility-quality-inclusivity/",
                            "details": [
                                "Create figures that are high contrast and high resolution, so they remain clear when zooming in.",
                                "Ensure that fonts are sufficiently large, especially in figures. The font size in figures should be no smaller than the font size of the caption of the figure.",
                                "Ensure that your visuals are legible to people with all types of color vision by following the recommendations of How to Design for Color Blindness and Color Universal Design:",
                                "Choose color schemes that can be easily identified by people with all types of color vision, in consideration with the actual lighting conditions and usage environment.",
                                "Do not rely on color to convey information, but also use a combination of different shapes, positions, line types, and coloring patterns.",
                                "Ensure that the PDF of your paper is accessible by following the steps in the SIGACCESS Accessible PDF Author Guide. This means in particular:",
                                "Check that all fonts are embedded in the PDF.",
                                "Set the title and language for the PDF.",
                                "Add tags to the PDF. Tags capture the underlying logical structure, reading order, etc. and allow the use of assistive technologies such as screen readers.",
                                "Add alternative text to all figures, tables, charts, images, diagrams, and other visuals in your paper. This is what will be spoken to readers who cannot see the visuals. Use plain, concise language that captures both the content and the function of the visuals in the paper. Highlight the aspects of the visuals that are salient to the paper, rather than merely describing the visuals or repeating their captions. Follow the SIGACCESS guidelines, which include several examples. For further examples see Appendix F of 2kenize: Tying Subword Sequences for Chinese Script Conversion.",
                                "Set the tab order for the PDF.",
                                "Mark table headers in the PDF."
                            ],
                            "How to Design for Color Blindness(url)": "https://www.getfeedback.com/resources/ux/how-to-design-for-color-blindness/",
                            "Color Universal Design(url)": "https://jfly.uni-koeln.de/color/",
                            "SIGACCESS Accessible PDF Author Guide(url)": "http://www.sigaccess.org/welcome-to-sigaccess/resources/accessible-pdf-author-guide/",
                            "screen readers(url)": "https://en.wikipedia.org/wiki/Screen_reader",
                            "SIGACCESS guidelines(url)": "https://www.sigaccess.org/welcome-to-sigaccess/resources/describing-figures/",
                            "2kenize: Tying Subword Sequences for Chinese Script Conversion(url)": "https://arxiv.org/ftp/arxiv/papers/2005/2005.03375.pdf"
                        },
                        "Author Names and Citations": {
                            "introduction": "Many authors (in particular, transgender, non-binary, and/or gender-diverse authors; married and/or divorced authors; etc.) can change their names during their academic careers. You show respect to the authors that you cite by using their updated names. Not using their updated names produces ongoing harms, such as a violation of privacy, denial of credit, denial of dignity, ongoing corrective epistemic labor, epistemic exploitation, and exposure to abuse and trauma, and can even constitute hate speech. Please take the following steps:",
                            "steps": [
                                "1. Ensure that you are using updated author names by checking their website or Semantic Scholar page. ",
                                "2. To obtain bibliographic entries, do not rely on platforms such as Google Scholar that do not properly support author name changes.",
                                "3. Use tools such as Rebiber and manually check your work to spot and fix outdated bibliographic entries and in-text citations.",
                                "4. For works that include examples from citation networks, academic graphs, etc., manually check that none of the examples contain incorrect names, which can occur in publicly available academic graphs."
                            ],
                            "violation of privacy, denial of credit, denial of dignity, ongoing corrective epistemic labor, epistemic exploitation, and exposure to abuse and trauma, and can even constitute hate speech(url)": "https://publicationethics.org/news/vision-more-trans-inclusive-publishing-world",
                            "matters need attention": "It is critical that you follow the above steps in all drafts of your paper, not just in the camera-ready version. Any version of your paper that you upload to arXiv or submit for open review can be indexed or scraped, and if it contains incorrect names, it can result in the harms mentioned above. If you discover or are notified that any of your papers contain incorrect names, make the appropriate corrections immediately."
                        },
                        "Inclusive Language": {
                            "Use inclusive and respectful language throughout your paper:": [
                                "1. Use examples that are understandable and respectful to a diverse, multicultural audience. It is acceptable to include offensive content when it is relevant to the focus of your paper (e.g., to provide examples of toxic data). In this case, we recommend including a trigger or content warning at the beginning of your paper (for an example, see Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies).",
                                "2. When talking about people and their individual characteristics including age, caste, disability, gender, neurodivergence, racial and ethnic identity, religion, sexual orientation, socioeconomic status, etc. follow the APA style guide.",
                                "3. If your paper discusses accessibility issues or refers to people with disabilities, please follow the SIGACCESS Accessible Writing Guide.",
                                "4. Avoid inherently sexist language, such as generic “he” and gendered professional titles (e.g., use “firefighter” instead of “fireman”). Also, avoid using combinations such as “he or she,” “she or he,” “he/she,” and “(s)he” as alternatives to the singular “they” because such constructions imply an exclusively binary nature of gender and exclude individuals who do not use these pronouns. See RECSYS guidelines for additional recommendations.",
                                "5. Consider adding your pronouns (if comfortable) under your name in the camera-ready version to ensure that you and your co-authors are referred to appropriately when your paper is discussed. This practice additionally normalizes pronouns, which creates a more welcoming environment for trans, non-binary, and/or gender-diverse folks. For an example, see Harms of Gender Exclusivity and Challenges in Non-Binary Representation in Language Technologies. If you are not familiar with pronouns, see the oSTEM guide to pronouns. "
                            ],
                            "matters need attention": "The lack of compliance with accessibility and inclusiveness requirements can be brought up during the review and we will check for compliance before papers are published. Following these requirements should not take very long (likely no more than an hour or two) but you should be sure to budget time to accomplish them, particularly if you are not used to going through these steps."
                        }
                    },
                    "Talks and Posters": {
                        "introduction": "There are many great guides to making accessible and inclusive talks and posters; we advise everyone to consider all the points made in the RECSYS guidelines, the ACM guide, and the W3C guide. In particular, we would like to highlight the following items:",
                        "important items": [
                            "Keep your slides and posters clear, simple, and uncrowded. Use large, sans-serif fonts, with ample white space between sentences and paragraphs. Use bold for emphasis (instead of italics, underline, or capitalization), and avoid special text effects (e.g., shadows).",
                            "Choose high contrast colors; dark text on a cream background works best.",
                            "Avoid flashing text or graphics. For any graphics, add a brief text description of the graphic right next to it.",
                            "Choose color schemes that can be easily identified by people with all types of color vision and do not rely on color to convey a message (see How to Design for Color Blindness and Color Universal Design for further details).",
                            "Use examples that are understandable and respectful to a diverse, multicultural audience.",
                            "When beginning a talk, introduce yourself with your chosen name and pronouns (if comfortable), and describe your appearance and background so that blind and visually impaired individuals can picture the talk. Every time you start talking after another person was just talking, say “This is [insert your name],” so that blind and visually impaired folks can easily know who is talking.",
                            "When welcoming, referring to or interacting with your audience:",
                            "Do not use: ladies and gentlemen, boys and girls, men and women, brothers and sisters, he or she, sir/madam.",
                            "Instead, use: esteemed guests, that person, friends and colleagues, students, siblings, everyone, the participants.",
                            "Do not assume the pronouns of any audience member, or publicly ask audience members for their pronouns. Instead, use singular “they” to refer to audience members.",
                            "Avoid inherently sexist language, such as generic “he” and gendered professional titles (e.g., use “firefighter” instead of “fireman”). Also, avoid using combinations such as “he or she,” “she or he,” “he/she,” and “(s)he” as alternatives to the singular “they” because such constructions imply an exclusively binary nature of gender and exclude individuals who do not use these pronouns. See RECSYS guidelines for additional recommendations.",
                            "Avoid intentional and casual ableist language, such as “Oh, I’m dumb!”, “I’m blind”, “Are you deaf?”, “I’m so OCD about these things”, “I hope everyone can see this”, etc. This language alienates and harms disabled and neurodivergent people.",
                            "When speaking, do not assume that all audience members can see the slides: cover everything important in what you say, even if it's already on the slide. Be kind when asked to say content on your slides (especially equations) out loud. ",
                            "Before responding to an audience question, slowly repeat the question so that everyone can catch and process the question. When speaking, repeat important words and ideas to allow everyone to follow along.",
                            "For virtual talks and poster sessions, monitor the chat for questions."
                        ]
                    }
                },
                "Publication Ethics": {
                    "Authors": {
                        "introduction": "Authors submitting their work to ICML need to agree to the following.",
                        "Research ethics": [
                            "Authors submitting their work to ICML must follow the NeurIPS Ethics Guidelines. In particular,",
                            "whenever there are risks associated with the proposed methods, methodology, application or data collection and data usage, authors are expected to elaborate on the rationale of their decision and potential mitigations.",
                            "Authors are expected to make a reasonable effort in identifying risks that warrant the inclusion of this discussion."
                        ],
                        "Paper submissions": {
                            "Authorship": "Authors should comprise exactly those individuals who made a significant contribution to the research. Other contributors should be acknowledged upon the acceptance of the paper in the final camera ready submission. The submitting author must ensure that all co-authors have seen and approved the final version of the manuscript and have agreed to its submission for publication.",
                            "Originality, citations": "The submitted paper is entirely written by the authors of the paper. If the work of others have been used, the work used must be properly cited or quoted. Publications that have significantly influenced the nature of the work must be cited. However, only relevant publications can be cited and self-citation should be kept at minimum.",
                            "Dual submissions": "The rules concerning dual submissions are described in the call for papers.",
                            "Fraud, correctness": "Fraudulent or knowingly inaccurate statements are unacceptable, including but not limited to the use of fabricated data. If before the publication of the final version of the paper, an author discovers a significant error or inaccuracy in the submitted paper, the author needs to promptly notify the program chairs (program-chairs@icml.cc) and either retract the paper, or correct it if a correction is feasible.",
                            "program chairs email": "program-chairs@icml.cc",
                            "Conflict of interest": "Financial or any other substantive conflict of interest that might be construed to influence the results or interpretation of the manuscript must be disclosed to the program chairs and upon the acceptance of the paper, information pertaining to the conflict must be made available in the final version, including all sources of financial support."
                        }
                    },
                    "Program committee and reviewers": {
                        "Aims and goals": "The program committee and reviewers must strive to meet the expectations/needs of conference participants, readers and authors; conference participants and readers have expectations/needs of a high quality and intellectually stimulating program, while the authors have expectations/needs of a fair and professional review process.",
                        "Confidentiality": "All information pertaining to individual submitted manuscripts must be kept confidential. The program committee and reviewers need to protect the author's ideas.",
                        "Fairness": "All submissions must be evaluated only for their contents: soundness, originality, significance, relevance to ICML and quality of writing/presentation as explained on the review form.",
                        "Prudence": "PC members and reviewers must bring to the attention of their superiors (meta-reviewers, senior meta-reviewers, program chairs) any information that may be a reason to reject the publication of the submitted paper, such as the violation of these guidelines.",
                        "Conflicts": "PC members/reviewers must disclose any conflicts of interest to the program chairs. A PC member/reviewer who is conflicted with a paper due to close ties to the authors of the paper cannot participate in deciding the fate of that paper. Program chairs are not exempt to this rule: In case a program chair is conflicted, the non-conflicted program chairs must make the decisions without the involvement of the conflicted program chair."
                    }
                }
            },
            "Call For Workshops": {
                "2023 accepted workshops": {
                    "url": "https://icml.cc/Conferences/2023/Schedule?type=Workshop.",
                    "workshops": [
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Ballroom C None",
                            "workshop": "3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH)",
                            "author": [
                                "Weina Jin",
                                "Ramin Zabih",
                                "S. Kevin Zhou",
                                "Yuyin Zhou",
                                "Xiaoxiao Li",
                                "Yifan Peng",
                                "Zongwei Zhou",
                                "Yucheng Tang",
                                "Yuzhe Yang",
                                "Agni Kumar"
                            ],
                            "content": "Applying machine learning (ML) in healthcare is gaining momentum rapidly. However, the black-box characteristics of the existing ML approach inevitably lead to less interpretability and verifiability in making clinical predictions. To enhance the interpretability of medical intelligence, it becomes critical to develop methodologies to explain predictions as these systems are pervasively being introduced to the healthcare domain, which requires a higher level of safety and security. Such methodologies would make medical decisions more trustworthy and reliable for physicians, which could ultimately facilitate the deployment. In addition, it is essential to develop more interpretable and transparent ML systems. For instance, by exploiting structured knowledge or prior clinical information, one can design models to learn aspects more aligned with clinical reasoning. Also, it may help mitigate biases in the learning process, or identify more relevant variables for making medical decisions.In this workshop, we aim to bring together researchers in ML, computer vision, healthcare, medicine, NLP, public health, computational biology, biomedical informatics, and clinical fields to facilitate discussions including related challenges, definition, formalisms, and evaluation protocols regarding interpretable medical machine intelligence. Our workshop will be in a large-attendance talk format. The expected number of attendees is about 150. The workshop appeals to ICML audiences as interpretability is a major challenge to deploy ML in critical domains such as healthcare. By providing a platform that fosters potential collaborations and discussions between attendees, we hope the workshop is fruitful in offering a step toward building autonomous clinical decision systems with a higher-level understanding of interpretability.",
                            "essays": [
                                {
                                    "essay": "(Un)reasonable Allure of Ante-hoc Interpretability for High-stakes Domains: Transparency Is Necessary but Insufficient for Explainability ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unsupervised Discovery of Steerable Factors in Graphsc ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Efficient Estimation of Local Robustness of Machine Learning Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Verifiable Feature Attributions: A Bridge between Post Hoc Explainability and Inherent Interpretability ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Consistent Explanations in the Face of Model Indeterminacy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adverse event prediction using a task-specific generative model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Echocardiographic Clustering by Machine Learning in Children with Early Surgically Corrected Congenital Heart Disease ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "SepVAE: a contrastive VAE to separate pathological patterns from healthy ones. ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Risk-adjusted Training and Evaluation for Medical Object Detection in Breast Cancer MRI ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Curve your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Generalizing Neural Additive Models via Statistical Multimodal Analysis ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Echocardiographic Clustering by Machine Learning in Children with Early Surgically Corrected Congenital Heart Disease ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Explanation-guided dynamic feature selection for medical risk prediction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Interpretable Classification of Leukocytes based on Deep Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bridging the Gap: From Post Hoc Explanations to Inherently Interpretable Models for Medical Imaging ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Automated Detection of Interpretable Causal Inference Opportunities: Regression Discontinuity Subgroup Discovery ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data-Centric Diet: Effective Multi-center Dataset Pruning for Medical Image Segmentation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Participatory Personalization in Classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Pipeline for Interpretable Clinical Subtyping with Deep Metric Learning ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Signature Activation: A Sparse Signal View for Holistic Saliency ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "ADMIRE++: Explainable Anomaly Detection in the Human Brain via Inductive Learning on Temporal Multiplex Networks ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "An interpretable data augmentation framework for improving generative modeling of synthetic clinical trial data ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Eye-tracking of clinician behaviour with explainable AI decision support: a high-fidelity simulation study ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Transfer Causal Learning: Causal Effect Estimation with Knowledge Transfer ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "What Works in Chest X-Ray Classification? A Case Study of Design Choices ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Deep Learning Approach for Cardiac Electrophysiology Model Correction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robust Ranking Explanations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Understanding the Size of the Feature Importance Disagreement Problem in Real-World Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Auditing for Human Expertise ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Eye-tracking of clinician behaviour with explainable AI decision support: a high-fidelity simulation study ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "TabCBM: Concept-based Interpretable Neural Networks for Tabular Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Better Calibration Error Estimation for Reliable Uncertainty Quantification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Interpretable Alzheimer\u2019s Disease Classification Via a Contrastive Diffusion Autoencoder. ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning replacement variables in interpretable rule-based models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Semi-supervised Ordinal Regression via Cumulative Link Models for Predicting In-Hospital Length-of-Stay ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Designing optimal tests for slow converging Markov chains ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PulseDiff: Improving Diffusion Models for Pulse Imputation with Augmented Template Prior ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Prospectors: Leveraging Short Contexts to Mine Salient Objects in High-dimensional Imagery ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "An interpretable data augmentation framework for improving generative modeling of synthetic clinical trial data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ADMIRE++: Explainable Anomaly Detection in the Human Brain via Inductive Learning on Temporal Multiplex Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Signature Activation: A Sparse Signal View for Holistic Saliency ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Pipeline for Interpretable Clinical Subtyping with Deep Metric Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A ChatGPT Aided Explainable Framework for Zero-Shot Medical Image Diagnosis ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifying Inequity in Treatment Allocation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactual Optimization of Treatment Policies Based on Temporal Point Process ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Continuous Time Evidential Distributions for Irregular Time Series ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Interpreting deep embeddings for disease progression clustering ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifying and Intervening in Key Predictors of Out-of-Hospital Cardiac Arrest Survival Outcome Using Explainable Artificial Intelligence ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Self-verification improves few-shot clinical information extraction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DynDepNet: Learning Time-Varying Dependency Structures from fMRI Data via Dynamic Graph Structure Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DynDepNet: Learning Time-Varying Dependency Structures from fMRI Data via Dynamic Graph Structure Learning ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "DBGDGM: A Dynamic Brain Graph Deep Generative Model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Unifying Framework to the Analysis of Interaction Methods using Synergy Functions ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "A Unifying Framework to the Analysis of Interaction Methods using Synergy Functions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Discovering Mental Health Research Topics with Topic Modeling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning where to intervene with a differentiable top-k operator: Towards data-driven strategies to prevent fatal opioid overdoses ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Longitudinal Variational Autoencoder for Compositional Data Analysis ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Generating Global Factual and Counterfactual Explainer for Molecule under Domain Constraints ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Interpretable Ensemble-based Deep Learning Approach for Automated Detection of Macular Telangiectasia Type 2 by Optical Coherence Tomography ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Feature Importance Measurement based on Decision Tree Sampling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Why Deep Models Often Cannot Beat Non-deep Counterparts on Molecular Property Prediction? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Is Task-Agnostic Explainable AI a Myth? ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "ProtoGate: Prototype-based Neural Networks with Local Feature Selection for Tabular Biomedical Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Is Task-Agnostic Explainable AI a Myth? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Mask, Stitch, and Re-Sample: Enhancing Robustness and Generalizability in Anomaly Detection through Automatic Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Explainable Deep Learning for Disease Activity Prediction in Chronic Inflammatory Joint Diseases ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Generating Explanations to understand Fatigue in Runners Using Time Series Data from Wearable Sensors ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Interpreting Differentiable Latent States for Healthcare Time-series Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "GraphChef: Learning the Recipe of Your Dataset ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "GraphChef: Learning the Recipe of Your Dataset ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Rethinking Medical Report Generation: Disease Revealing Enhancement with Knowledge Graph ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Survey on Knowledge Graphs for Healthcare: Resources, Application Progress, and Promise ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Ballroom A None",
                            "workshop": "2nd ICML Workshop on New Frontiers in Adversarial Machine Learning",
                            "author": [
                                "Sijia Liu",
                                "Pin-Yu Chen",
                                "Dongxiao Zhu",
                                "Eric Wong",
                                "Kathrin Grosse",
                                "Baharan Mirzasoleiman",
                                "Sanmi Koyejo"
                            ],
                            "content": "Given the success of AdvML-inspired research, we propose a new edition from our workshop at ICML’22 (AdvML-Frontiers’22), ‘The 2nd Workshop on New Frontiers in AdvML’ (AdvML-Frontiers’23). We target a high-quality international workshop, coupled with new scientific activities, networking opportunities, and enjoyable social events. Scientifically, we aim to identify the challenges and limitations of current AdvML methods and explore new prospective and constructive views for next-generation AdvML across the full theory/algorithm/application stack. As the sequel to AdvML-Frontiers’22, we will continue exploring the new frontiers of AdvML in theoretical understanding, scalable algorithm and system designs, and scientific development that transcends traditional disciplinary boundaries. We will also add new features and programs in 2023. First, we will expand existing research themes, particularly considering the popularity of large foundational models (e.g., DALL-E 2, Stable Diffusion, and ChatGPT). Examples of topics include AdvML for prompt learning, counteracting AI-synthesized fake images and texts, debugging ML from unified data-model perspectives, and ‘green’ AdvML towards environmental sustainability. Second, we will organize a new section, AI Trust in Industry, by inviting industry experts to introduce the practical trend of AdvML, technological innovations, products, and societal impacts (e.g., AI’s responsibility). Third, we will host a Show-and-Tell Demos in the poster session to allow demonstrations of innovations done by research and engineering groups in the industry, academia, and government entities. Fourth, we will collaborate with ‘Black in AI’ (where Co-Organizer Dr. Sanmi Koyejo is serving as the president) to increase the presence and inclusion of Black people in the field of AdvML by creating spaces for sharing ideas and networking.",
                            "essays": [
                                {
                                    "essay": "Why do universal adversarial attacks work on large language models?: Geometry might be the answer ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Which Models have Perceptually-Aligned Gradients? An Explanation via Off-Manifold Robustness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Navigating Graph Robust Learning against All-Intensity Attacks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Stabilizing GNN for Fairness via Lipschitz Bounds ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Backdoor Attacks for In-Context Learning with Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "CertViT: Certified Robustness of Pre-Trained Vision Transformers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Shrink & Cert: Bi-level Optimization for Certified Robustness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Establishing a Benchmark for Adversarial Robustness of Compressed Deep Learning Models after Pruning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robustness through Loss Consistency Regularization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Few-shot Anomaly Detection via Personalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exposing the Fake: Effective Diffusion-Generated Images Detection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sharpness-Aware Minimization Along can Improve Adversarial Robustness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Teach GPT To Phish ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unsupervised Adversarial Detection without Extra Model: Training Loss Should Change ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Scoring Black-Box Models for Adversarial Robustness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Effective Data Poisoning for Imbalanced Classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Black Box Adversarial Prompting for Foundation Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adversarial Training with Generated Data in High-Dimensional Regression: An Asymptotic Study ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Exponential Families from Truncated Samples ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Feature Partition Aggregation: A Fast Certified Defense Against a Union of \u21130 Attacks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Certifying Ensembles: A General Certification Theory with S-Lipschitzness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Transferable Adversarial Perturbations between Self-Supervised Speech Recognition Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Classifier Robustness Enhancement Via Test-Time Transformation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Don't trust your eyes: on the (un)reliability of feature visualizations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Illusory Attacks: Detectability Matters in Adversarial Attacks on Sequential Decision-Makers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Context-Aware Self-Adaptation for Domain Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adversarial Robustness for Tabular Data through Cost and Utility Awareness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Generalizable Lightweight Proxy for Robust NAS against Diverse Perturbations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PIAT: Parameter Interpolation based Adversarial Training for Image Classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Simple and Yet Fairly Effective Defense for Graph Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "TMI! Finetuned Models Spill Secrets from Pretraining ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Theoretical Perspective on the Robustness of Feature Extractors ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DiffScene: Diffusion-Based Safety-Critical Scenario Generation for Autonomous Vehicles ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Theoretically Principled Trade-off for Stateful Defenses against Query-Based Black-Box Attacks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A physics-orientd method for attacking SAR images using salient regions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "How Can Neuroscience Help Us Build More Robust Deep Neural Networks? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Baselines for Identifying Watermarked Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Rethinking Label Poisoning for GNNs: Pitfalls and Attacks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adversarial Training in Continuous-Time Models and Irregularly Sampled Time-Series: A First Look ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Like Oil and Water: Group Robustness and Poisoning Defenses Don\u2019t Mix ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Future of Cyber Systems: Human-AI Reinforcement Learning with Adversarial Robustness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Introducing Vision into Large Language Models Expands Attack Surfaces and Failure Implications ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Evading Black-box Classifiers Without Breaking Eggs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "AdversNLP: A Practical Guide to Assessing NLP Robustness Against Text Adversarial Attacks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "When Can Linear Learners be Robust to Indiscriminate Poisoning Attacks? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Provably Robust Cost-Sensitive Learning via Randomized Smoothing ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Improve Adversarial Training for Multiple Perturbations through the Lens of Uniform Stability ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PAC-Bayesian Adversarially Robust Generalization Bounds for Deep Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "R-LPIPS: An Adversarially Robust Perceptual Similarity Metric ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Rethinking Robust Contrastive Learning from the Adversarial Perspective ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Near Optimal Adversarial Attack on UCB Bandits ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Certified Calibration: Bounding Worst-Case Calibration under Adversarial Attacks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Mathematical Theory of Adversarial Deep Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robust Semantic Segmentation: Strong Adversarial Attacks and Fast Training of Robust Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adversarial Attacks and Defenses in Explainable Artificial Intelligence: A Survey ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A First Order Meta Stackelberg Method for Robust Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Label Noise: Correcting a Correction Loss ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On feasibility of intent obfuscating attacks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Characterizing the Optimal 0\u22121 Loss for Multi-class Classification with a Test-time Attacker ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Shared Safety Constraints from Multi-task Demonstrations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "RODEO: Robust Out-of-distribution Detection via Exposing Adaptive Outliers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Proximal Composite Optimization for Distributionally Robust Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Out-of-Distribution Adversarial Robustness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Preventing Reward Hacking with Occupancy Measure Regularization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Equal Long-term Benefit Rate: Adapting Static Fairness Notions to Sequential Decision Making ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "FACADE: A Framework for Adversarial Circuit Anomaly Detection and Evaluation. ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Deceptive Alignment Monitoring ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "(Almost) Provable Error Bounds Under Distribution Shift via Disagreement Discrepancy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Benchmarking the Reliability of Post-training Quantization: a Particular Focus on Worst-case Performance ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Tunable Dual-Objective GANs for Stable Training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Accurate, Explainable, and Private Models: Providing Recourse While Minimizing Training Data Leakage ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adapting Robust Reinforcement Learning to Handle Temporally-Coupled Perturbations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Provable Instance Specific Robustness via Linear Constraints ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Toward Testing Deep Learning Library via Model Fuzzing ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PanopticCAP: Refined and Enriched Captions With Vision-Language Model Under Dynamic Conditions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifying Adversarially Attackable and Robust Samples ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sentiment Perception Adversarial Attacks on Neural Machine Translation Systems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robust Deep Learning via Layerwise Tilted Exponentials ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Risk-Averse Predictions on Unseen Domains via Neural Style Smoothing ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Limitations of Model Stealing with Uncertainty Quantification Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Incentivizing Honesty among Competitors in Collaborative Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "MLSMM: Machine Learning Security Maturity Model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adaptive Certified Training: Towards Better Accuracy-Robustness Tradeoffs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Challenge of Differentially Private Screening Rules ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adversarial Training Should Be Cast as a Non-Zero-Sum Game ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Model-tuning Via Prompts Makes NLP Models Adversarially Robust ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 315 None",
                            "workshop": "HiLD: High-dimensional Learning Dynamics Workshop",
                            "author": [
                                "Courtney Paquette",
                                "Zhenyu Liao",
                                "Mihai Nica",
                                "Elliot Paquette",
                                "Andrew Saxe",
                                "Rene Vidal"
                            ],
                            "content": [
                                "Modern applications of machine learning seek to extract insights from high-dimensional datasets. The goal of the High-dimensional Learning Dynamics (HiLD) Workshop is to predict and analyze the dynamics of learning algorithms when the number of samples and parameters are large. This workshop seeks to spur research and collaboration around:",
                                "1. Developing analyzable models and dynamics to explain observed deep neural network phenomena;",
                                "2. Creating mathematical frameworks for scaling limits of neural network dynamics as width and depth grow, which often defy low-dimensional geometric intuitions;",
                                "3. The role of overparameterization and how this leads to conserved quantities in the dynamics and the emergence of geometric invariants, with links to Noether's theorem, etc;",
                                "4. Provable impacts of the choice of optimization algorithm, hyper-parameters, and neural network architectures on training/test dynamics.",
                                "HiLD Workshop aims to bring together experts from classical random matrix theory, optimization, high-dimensional statistics/probability, and statistical physics to share their perspectives while leveraging crossover experts in ML. It seeks to create synergies between these two groups which often do not interact. Through a series of talks, poster sessions, and panel discussions, the workshop will tackle questions on dynamics of learning algorithms at the interface of random matrix theory, high-dimensional statistics, SDEs, and ML."
                            ],
                            "events": [
                                {
                                    "event": "Feature Learning in Two-layer Neural Networks under Structured Data, Murat A. Erdogdu ",
                                    "form": "Plenary Speaker"
                                },
                                {
                                    "event": "Opening Remarks ",
                                    "form": "Remarks"
                                },
                                {
                                    "event": "Contributed talks, Session 1 ",
                                    "form": "Contributed talks"
                                },
                                {
                                    "event": "Poster Session/Coffee Break ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Plenary Speaker 2 ",
                                    "form": "Plenary Speaker"
                                },
                                {
                                    "event": "Lunch ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Multi-level theory of neural representations: Capacity of neural manifolds in biological and artificial neural networks, SueYeon Chung ",
                                    "form": "Plenary Speaker"
                                },
                                {
                                    "event": "Contributed talks, Session 2 ",
                                    "form": "Contributed talks"
                                },
                                {
                                    "event": "Coffee Break ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Plenary Speaker 4 ",
                                    "form": "Plenary Speaker"
                                },
                                {
                                    "event": "Solving overparametrized systems of random equations, Andrea Montanari ",
                                    "form": "Plenary Speaker"
                                },
                                {
                                    "event": "Closing remarks ",
                                    "form": "Remarks"
                                }
                            ],
                            "essays": [

                                {
                                    "essay": "Supervised-Contrastive Loss Learns Orthogonal Frames and Batching Matters ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Generalization and Stability of Interpolating Neural Networks with Minimal Width ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning in the Presence of Low-dimensional Structure: A Spiked Random Matrix Perspective ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Sharp predictions for mini-batched prox-linear iterations in rank one matrix sensing ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Deep Neural Networks Extrapolate Cautiously in High Dimensions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Implicit regularisation in stochastic gradient descent: from single-objective to two-player games ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "How to escape sharp minima ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neural Collapse in the Intermediate Hidden Layers of Classification Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Layerwise Linear Mode Connectivity ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Hessian Inertia in Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Training Process of Many Deep Networks Explores the Same Low-Dimensional Manifold ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Marginal Value of Momentum for Small Learning Rate SGD ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Joint Interaction of Models, Data, and Features ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Margin Maximization in Attention Mechanism ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Advantage of Lion Compared to signSGD with Momentum ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Investigating the Edge of Stability Phenomenon in Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Which Features are Learned by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Training and Generalization Dynamics of Multi-head Attention ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adapting to Gradual Distribution Shifts with Continual Weight Averaging ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Flatter, Faster: Scaling Momentum for Optimal Speedup of SGD ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "How Does Adaptive Optimization Impact Local Neural Network Geometry? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Characterizing and Improving Transformer Solutions for Dyck Grammars ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Implicit regularization of multi-task learning and finetuning in overparameterized neural networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "An improved residual based random forest for robust prediction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On Privileged and Convergent Bases in Neural Network Representations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Does Double Descent Occur in Self-Supervised Learning? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sharpness-Aware Minimization Leads to Low-Rank Features ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning to Plan in Multi-dimensional Stochastic Differential Equations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Benign Overfitting of Two-Layer Neural Networks under Inputs with Intrinsic Dimension ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Equivalence Between Implicit and Explicit Neural Networks: A High-dimensional Viewpoint ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "High-dimensional Learning Dynamics of Deep Neural Nets in the Neural Tangent Regime ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Effects of Overparameterization on Sharpness-Aware Minimization: A Preliminary Investigation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Latent State Transitions in Training Dynamics ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Implicitly Learned Invariance and Equivariance in Linear Regression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Elephant Neural Networks: Born to Be a Continual Learner ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Problem of Transferring Learning Trajectories Between Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Graph Neural Networks Provably Benefit from Structural Information: A Feature Learning Perspective ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "The phases of large learning rate gradient descent through effective parameters ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Spectral Evolution and Invariance in Linear-width Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Universality of Linear Recurrences Followed by Nonlinear Projections ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "An Adaptive Method for Minimizing Non-negative Losses ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Over-Parameterization Exponentially Slows Down Gradient Descent for Learning a Single Neuron ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Predictive Sparse Manifold Transform ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fast Test Error Rates for Gradient-based Algorithms on Separable Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Effectiveness of Sharpness-Aware Minimization with Large Mini-batches ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Hyperparameter Tuning using Loss Landscape ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Network Degeneracy as an Indicator of Training Performance: Comparing Finite and Infinite Width Angle Predictions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Stochastic Dynamical Systems as an Implicit Regularization with Graph Neural Network ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 313 None",
                            "workshop": "Challenges in Deployable Generative AI",
                            "author": [
                                "Swami Sankaranarayanan",
                                "Thomas Hartvigsen",
                                "Camille Bilodeau",
                                "Ryutaro Tanno",
                                "Cheng Zhang",
                                "Florian Tramer",
                                "Phillip Isola"
                            ],
                            "content": "Generative modeling has recently gained massive attention given high-profile successes in natural language processing and computer vision. However, there remain major challenges in deploying generative models for real-world impact in domains like healthcare and biology. This is a challenging agenda that requires collaboration across multiple research fields and industry stakeholders. This workshop aims to advance such interdisciplinary conversations around challenges in deploying generative models – the lessons learned by deploying large language models could be impactful for high stakes domains like medicine and biology. Specifically, we will solicit contributions that prioritize (1) Multimodal capabilities in generative modeling, (2) Deployment-critical features in generative models such as Safety, Interpretability, Robustness, Ethics, Fairness and Privacy, and (3) Human facing evaluation of generative models. The topic of generative modeling is extremely relevant to the core audience of ICML. Modern generative models impact several fields outside machine learning and hence responsible deployment of such powerful algorithms has become a major concern of researchers in academia and industry alike. ICML, being the flagship conference of Machine learning, is the perfect place to facilitate this cross disciplinary sharing of knowledge."
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 323 None",
                            "workshop": "Structured Probabilistic Inference and Generative Modeling",
                            "author": [
                                "Dinghuai Zhang",
                                "Yuanqi Du",
                                "Chenlin Meng",
                                "Shawn Tan",
                                "Yingzhen Li",
                                "Max Welling",
                                "Yoshua Bengio"
                            ],
                            "content": "The workshop focuses on theory, methodology, and application of structured probabilistic inference and generative modeling, both of which are important topics in machine learning.Specifically, probabilistic inference addresses the problem of amortization,sampling, and integration of complex quantities from graphical models, while generative modeling captures the underlying probability distributions of a dataset. Apart from applications in computer vision, natural language processing, and speech recognition, probabilistic inference and generative modeling approaches have also been widely used in natural science domains, including physics, chemistry, molecular biology, and medicine. Despite the promising results, probabilistic methods face challenges when applied to highly structured data, which are ubiquitous in real-world settings, limiting the applications of such methods. This workshop aims to bring experts from diverse backgrounds and related domains together to discuss the applications and challenges of probabilistic methods. The workshop will emphasize challenges in encoding domain knowledge when learning representations, performing inference and generations. By bringing together experts from academia and industry, the workshop will provide a platform for researchers to share their latest results and ideas, fostering collaboration and discussion in the field of probabilistic methods.",
                            "essays": [
                                {
                                    "essay": "Towards Modular Learning of Deep Causal Generative Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Optimizing protein fitness using Bi-level Gibbs sampling with Graph-based Smoothing ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Attention as Implicit Structural Inference ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Lexinvariant Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Anomaly Detection in Networks via Score-Based Generative Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Non-Normal Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "HiGen: Hierarchical Graph Generative Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Augmenting Control over Exploration Space in Molecular Dynamics Simulators to Streamline De Novo Analysis through Generative Control Policies ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Scaling Graphically Structured Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Training Diffusion Models with Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Beyond Intuition, a Framework for Applying GPs to Real-World Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Diffusion Generative Inverse Design ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Morse Neural Networks for Uncertainty Quantification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neuro-Causal Factor Analysis ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Practical and Asymptotically Exact Conditional Sampling in Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Generative semi-supervised learning with a neural seq2seq noisy channel ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Benchmarking Bayesian Causal Discovery Methods for Downstream Treatment Effect Estimation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Conditional Graph Generation with Graph Principal Flow Network ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Pairwise Prony Algorithm: Efficient Inference of Stochastic Block Models with Prescribed Subgraph Densities ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Plug-and-Play Controllable Graph Generation with Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Local Inconsistency Resolution Algorithm ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Pretrained Language Models to Solve Graph Tasks in Natural Language ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Visual Chain-of-Thought Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Collapsed Inference for Bayesian Deep Learning ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Your Diffusion Model is Secretly a Zero-Shot Classifier ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Test-time Adaptation with Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Beyond Confidence: Reliable Models Should Also Consider Atypicality ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Implications of kernel mismatch for OOD data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Diffusion map particle systems for generative modeling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "C-Disentanglement: Discovering Causally-Independent Generative Factors under an Inductive Bias of Confounder ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Decision Stacks: Flexible Reinforcement Learning via Modular Generative Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "BOOT: Data-free Distillation of Denoising Diffusion Models with Bootstrapping ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Solving Inverse Physics Problems with Score Matching ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Nested Diffusion Processes for Anytime Image Generation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Generating Turn-Based Player Behavior via Experience from Demonstrations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Automatic Rao-Blackwellization for Sequential Monte Carlo with Belief Propagation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifying Under-Reported Events in Networks with Spatial Latent Variable Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Generative Marginalization Models ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "MissDiff: Training Diffusion Models on Tabular Data with Missing Values ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Empirically Validating Conformal Prediction on Modern Vision Architectures Under Distribution Shift and Long-tailed Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Linear Causal Representations from Interventions under General Nonlinear Mixing ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifiability of Discretized Latent Coordinate Systems via Density Landmarks Detection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fast and Functional structured data generator ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Structured Neural Networks for Density Estimation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "STable Permutation-based Framework for Table Generation in Sequence-to-Sequence Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Autoregressive Diffusion Models with non-Uniform Generation Order ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "BayesDAG: Gradient-Based Posterior Sampling for Causal Discovery ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "On the Equivalence of Consistency-Type Models: Consistency Models, Consistent Diffusion Models, and Fokker-Planck Regularization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Uncovering Latent Structure Using Random Partition Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Improving Training of Likelihood-based Generative Models with Gaussian Homotopy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Markov Chains ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Balanced Training of Energy-Based Models with Adaptive Flow Sampling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DiffMol: 3D Structured Molecule Generation with Discrete Denoising Diffusion Probabilistic Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Large Dimensional Change Point Detection with FWER Control as Automatic Stopping ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Geometric Constraints in Probabilistic Manifolds: A Bridge from Molecular Dynamics to Structured Diffusion Processes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Parallel Sampling of Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "GSURE-Based Diffusion Model Training with Corrupted Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Hierarchical Graph Generation with K2-trees ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bootstrapped Training of Score-Conditioned Generator for Offline Design of Biological Sequences ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "GFlowNets for Causal Discovery: an Overview ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Concept Algebra for Score-based Conditional Model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Multilevel Control Functional ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Diffusion Probabilistic Models for Structured Node Classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Provable benefits of score matching ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Function Space Bayesian Pseudocoreset for Bayesian Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "AbODE: Ab initio antibody design using conjoined ODEs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Graph Neural Network Powered Bayesian Optimization for Large Molecular Spaces ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PRODIGY: Enabling In-context Learning Over Graphs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "HINT: Hierarchical Coherent Networks For Constrained Probabilistic Forecasting ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PITS: Variational Pitch Inference Without Fundamental Frequency for End-to-End Pitch-Controllable TTS ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Inferring Hierarchical Structure in Multi-Room Maze Environments ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Deep Generative Clustering with Multimodal Variational Autoencoders ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Early Exiting for Accelerated Inference in Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Reinforcement Learning-Driven Linker Design via Fast Attention-based Point Cloud Alignment ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Prediction under Latent Subgroup Shifts with High-dimensional Observations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Generative Model for Text Control in Minecraft ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Regularized Data Programming with Automated Bayesian Prior Selection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exploring Exchangeable Dataset Amortization for Bayesian Posterior Inference ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robust and Scalable Bayesian Online Changepoint Detection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Identifiability of Markov Switching Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Diffusion Probabilistic Models Generalize when They Fail to Memorize ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "BatchGFN: Generative Flow Networks for Batch Active Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Thompson Sampling for Improved Exploration in GFlowNets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Score-based Enhanced Sampling for Protein Molecular Dynamics ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Nonparametric posterior normalizing flows ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Variational Point Encoding Deformation for Dental Modeling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Dimensionality Reduction as Probabilistic Inference ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Tree Variational Autoencoders ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Collaborative Score Distillation for Consistent Visual Synthesis ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Diffusion Based Causal Representation Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Flow Matching for Scalable Simulation-Based Inference ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Causal Discovery with Language Models as Imperfect Experts ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Diffusion Models with Grouped Latents for Interpretable Latent Space ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "An Empirical Study of the Effectiveness of Using a Replay Buffer on Mode Discovery in GFlowNets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "CM-GAN: Stabilizing GAN Training with Consistency Models ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 311 None",
                            "workshop": "Federated Learning and Analytics in Practice: Algorithms, Systems, Applications, and Opportunities",
                            "author": [
                                "Zheng Xu",
                                "Peter Kairouz",
                                "Bo Li",
                                "Tian Li",
                                "John Nguyen",
                                "Jianyu Wang",
                                "Shiqiang Wang",
                                "Ayfer Ozgur"
                            ],
                            "content": "Proposed around 2016 as privacy preserving techniques, federated learning and analytics (FL & FA) made remarkable progress in theory and practice in recent years. However, there is a growing disconnect between theoretical research and practical applications of federated learning. This workshop aims to bring academics and practitioners closer together to exchange ideas: discuss actual systems and practical applications to inspire researchers to work on theoretical and practical research questions that lead to real-world impact; understand the current development and highlight future directions. To achieve this goal, we aim to have a set of keynote talks and panelists by industry researchers focused on deploying federated learning and analytics in practice, and academic research leaders who are interested in bridging the gap between the theory and practice. ",
                            "For more details, please visit the workshop webpage at": "https://fl-icml2023.github.io",
                            "essays": [
                                {
                                    "essay": "Leveraging Side Information for Communication-Efficient Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Federated, Fast, and Private Visualization of Decentralized Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Demystifying Local and Global Fairness Trade-offs in Federated Learning Using Information Theory ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Differentially Private Heavy Hitters using Federated Analytics ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Asynchronous Federated Learning with Bidirectional Quantized Communications and Buffered Aggregation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Privacy Auditing with One (1) Training Run ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adaptive Federated Learning with Auto-Tuned Clients ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Machine Learning with Feature Differential Privacy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Guiding The Last Layer in Federated Learning with Pre-Trained Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Federated Learning with Regularized Client Participation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Convergence of First-Order Algorithms for Meta-Learning with Moreau Envelopes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Strategic Data Sharing between Competitors ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Performance of Gradient Tracking with Local Updates ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neighborhood Gradient Clustering: An Efficient Decentralized Learning Method for Non-IID Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "FED-CURE: A Robust Federated Learning Algorithm with Cubic Regularized Newton ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Resource-Efficient Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards a Better Theoretical Understanding of Independent Subnetwork Training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sketch-and-Project Meets Newton Method: \\ Global O(k\u22122) Convergence with Low-Rank Updates ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Convergent Federated Clustering Algorithm without Initial Condition ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Federated Conformal Predictors for Distributed Uncertainty Quantification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SCAFF-PD: Communication Efficient Fair and Robust Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Momentum Provably Improves Error Feedback! ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Federated Optimization Algorithms with Random Reshuffling and Gradient Compression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Federated Ensemble-Directed Offline Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Distributed Mean Estimation for Multi-Message Shuffled Privacy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On Differentially Private Federated Linear Contextual Bandits ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exact Optimality in Communication-Privacy-Utility Tradeoffs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Federated Heavy Hitter Recovery under Linear Sketching ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Improving Accelerated Federated Learning with Compression and Importance Sampling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Don\u2019t Memorize; Mimic The Past: Federated Class Incremental Learning Without Episodic Memory ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Privacy Amplification via Compression: Achieving the Optimal Privacy-Accuracy-Communication Trade-off in Distributed Mean Estimation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unleashing the Power of Randomization in Auditing Differentially Private ML ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Federated Experiment Design under Distributed Differential Privacy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Beyond Secure Aggregation: Scalable Multi-Round Secure Collaborative Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Hiding in Plain Sight: Disguising Data Stealing Attacks in Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards a Theoretical and Practical Understanding of One-Shot Federated Learning with Fisher Information ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Still Unreasonable Effectiveness of Federated Averaging for Heterogeneous Distributed Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Concept-aware clustering for decentralized deep learning under temporal shift ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Tackling the Data Heterogeneity in Asynchronous Federated Learning with Cached Update Calibration ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Re-Weighted Softmax Cross-Entropy to Control Forgetting in Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Population Expansion for Training Language Models with Private Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Private Federated Learning with Dynamic Power Control via Non-Coherent Over-the-Air Computation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Joint Training-Calibration Framework for Test-Time Personalization with Label Distribution Shift in Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Distributed Architecture Search over Heterogeneous Distributions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fed-CPrompt: Contrastive Prompt for Rehearsal-Free Federated Continual Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Green Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "FedFwd: Federated Learning without Backpropagation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Privacy-Preserving Federated Heavy Hitter Analytics for Non-IID Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Evaluating and Incentivizing Diverse Data Contributions in Collaborative Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Clustering-Guided Federated Learning of Representations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A New Theoretical Perspective on Data Heterogeneity in Federated Optimization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Randomized Quantization is All You Need for Differential Privacy in Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning-augmented private algorithms for multiple quantile release ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fast and Communication Efficient Decentralized Learning with Local Updates ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ELF: Federated Langevin Algorithms with Primal, Dual and Bidirectional Compression ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 301 None",
                            "workshop": "Knowledge and Logical Reasoning in the Era of Data-driven Learning",
                            "author": [
                                "Nezihe Merve G\u00fcrel",
                                "Bo Li",
                                "Theodoros Rekatsinas",
                                "Beliz Gunel",
                                "Alberto Sngiovanni Vincentelli",
                                "Paroma Varma"
                            ],
                            "content": [
                                "Thinking fast and automatic vs. slow and deliberate (respectively System I and II) is a popular analogy when comparing data-driven learning to the good old-fashion symbolic reasoning approaches. Underlying this analogy lies the different capabilities of both systems, or lack thereof. While data-driven learning (System I) has striking performance advantages over symbolic reasoning (System II), it lacks abilities such as abstraction, comprehensibility and contextual awareness. Symbolic reasoning, on the other hand, tackles those issues but tends to lag behind data-driven learning when it comes to speedy, efficient and automated decision-making. In the current state of matters to combat issues on both sides, there is an increasing consensus among the machine learning and artificial intelligence communities to draw out the best of both worlds and unify data-driven approaches with rule-based, symbolic, logical and commonsense reasoning. This workshop aims to discuss emerging advances and challenges on this topic, in particular at the intersection of data-driven paradigms and knowledge and logical reasoning. We focus on both directions of this intersection:",
                                "Knowledge and Logical Reasoning for Data-driven Learning: In this direction, we will investigate the role of rule-based, knowledge and logical reasoning to enable more deliberate and trustworthy data-driven learning.",
                                "Data-driven Learning for Knowledge and Logical Reasoning: In this reverse direction, we will explore the capabilities of data-driven approaches to derive knowledge, logical and commonsense reasoning from data."
                            ],
                            "events": [
                                {
                                    "event": "Opening Remarks ",
                                    "form": "Opening"
                                },
                                {
                                    "event": "Invited Talk 1: Samy Bengio",
                                    "affiliation": "Apple",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Invited Talk 2: Guy Van den Broeck",
                                    "affiliation": "UCLA",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Invited Talk 3: Ishita Dasgupta",
                                    "affiliation": "Google DeepMind",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Contributed Talk 1 ",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Contributed Talk 2 ",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Contributed Talk 3 ",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Poster Session 1 ",
                                    "form": "Poster Session"
                                },
                                {
                                    "event": "Lunch Break ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Invited Talk 4: Subbarao Kambhampati",
                                    "affiliation": "Arizona State University",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Invited Talk 5: Jiajun Wu",
                                    "affiliation": "Stanford University",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Invited Talk 6: Xi Victoria Lin",
                                    "affiliation": "Meta",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Invited Talk 7: Heng Ji",
                                    "affiliation": "UIUC",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Discussion Panel ",
                                    "form": "Panel"
                                },
                                {
                                    "event": "Poster Session 2 ",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Poster Session 2 ",
                                    "form": "Remarks"
                                }
                            ],
                            "essays": [
                                {
                                    "essay": "Learning and Leveraging Verifiers to Improve Planning Capabilities of Pre-trained Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Addressing Descrepancies in Semantic and Visual Alignment in Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Evaluating the Capabilities of Multi-modal Reasoning Models with Synthetic Task Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Pseudo-Semantic Loss for Deep Generative Models with Logical Constraints ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Asynchronous Algorithmic Alignment with Cocycles ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "(Un)interpretability of Transformers: a case study with Dyck grammars ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Disaster Occurrence Detection through GNN Models using Disaster Knowledge Graphs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Training LLMs with Noisy Algorithmic Chain of Thought ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Partial Label Learning meets Active Learning: Enhancing Annotation Efficiency through Binary Questioning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning to Initiate and Reason in Event-Driven Cascading Processes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Deep Neuro-Symbolic Weight Learning in Neural Probabilistic Soft Logic ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Equivariance Is Not All You Need: Characterizing the Utility of Equivariant Graph Neural Networks for Particle Physics Tasks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Augmenting the Knowledge to Large Model from Federated Small Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Explicit Planning Helps Language Models in Logical Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Evaluating the Casual Reasoning Abilities of Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "VAEL: Bridging Variational Autoencoders and Probabilistic Logic Programming ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "dPASP: A Comprehensive Differentiable Probabilistic Answer Set Programming Environment For Neurosymbolic Learning and Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Planning Abilities of Large Language Models - A Critical Investigation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Recursive Algorithmic Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Building One-class Detector for Anything: Open-vocabulary Zero-shot OOD Detection Using Text-image Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neurosymbolic AI for Reasoning on Biomedical Knowledge Graphs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SPRING: Studying Papers and Reasoning to play Games ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "LLM-grounded Text-to-Image Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Latent Space Representations of Neural Algorithmic Reasoners ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "LeanDojo: Theorem Proving with Retrieval-Augmented Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "EXPLAIN, AGREE and LEARN: A Recipe for Scalable Neural-Symbolic Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Revealing the Intrinsic Ability of Generative Language Models in Relation Prediction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards More Likely Models for AI Planning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Describe, Explain, Plan and Select: Interactive Planning with LLMs Enables Open-World Multi-Task Agents ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SQA3D: Situated Question Answering in 3D Scenes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Aggregation of Rules for Knowledge Graph Completion ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning with Explanation Constraints ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exposing Attention Glitches with Flip-Flop Language Modeling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "BoardgameQA: Natural Language Reasoning with Contradictory Information ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards true discovery of the differential equations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Continuous-Discrete Message Passing for Graph Logic Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Model-Theoretic Approach to Natural Language Inference ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "What\u2019s left can\u2019t be right - The remaining positional incompetence of contrastive vision-language models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Plan, Eliminate, and Track --- Language Models are Good Teachers for Embodied Agents. ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On The Ability of Transformers To Learn Recursive Patterns ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Chain of Thought Empowers Transformers to Solve Inherently Serial Problems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exploring the Impact of Disentangling Extraction and Reasoning in Multi-hop Spatial Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Role of Semantic Parsing in Understanding Procedural Text ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Explanatory Learning: Towards Artificial Scientific Discovery ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Parallel Algorithms Align with Neural Execution ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neuro-Symbolic Continual Learning: Knowledge, Reasoning Shortcuts and Concept Rehearsal ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bayesian Neural Networks with Domain Knowledge ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards A Unified Neural Architecture for Visual Recognition and Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Does End-to-End Visual Pretraining Help Reasoning? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neural Priority Queues for GNNs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Large Language Models are Zero-Shot Multi-Tool Users ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Look, Remember and Reason: Visual Reasoning with Grounded Rationales ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Retrieval-Augmented Multimodal Language Modeling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Large Language Model Programs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Semantically Adversarial Scene Generation with Explicit Knowledge Guidance for Autonomous Driving ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A*Net: A Scalable Path-based Reasoning Approach for Knowledge Graphs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Modeling Human Few-Shot Learning using Bayesian Inference over Natural Language ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DiversiGATE: A Comprehensive Framework for Reliable Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Semantic Conditioning at Inference : Improving Neural-based Systems with Logical Background Knowledge ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Evidence of Meaning in Language Models Trained on Programs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Reasoning Ability Emerges in Large Language Models as Aggregation of Reasoning Paths ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 317 A None",
                            "workshop": "Workshop on Theory of Mind in Communicating Agents",
                            "author": [
                                "Hao Zhu",
                                "Jennifer Hu",
                                "Hyunwoo Kim",
                                "Alane Suhr",
                                "Saujas Vaduguru",
                                "Chenghao Yang",
                                "Pei Zhou",
                                "Xuhui Zhou"
                            ],
                            "content": "Theory of Mind (ToM) is the ability to reason about the minds of other agents. The main theme of our workshop is the computational modeling of ToM, with a special focus on the role of natural language in such modeling. Specifically, ToM 2023 pays attention to cognitive foundations and theories of ToM, the acquisition and relationship between language and ToM, leveraging ToM to improve and explain NLP and ML models, and using ToM for positive social impact. This workshop intends to promote the community of researchers that are interested in improving the ability of intelligent agents to reason about others' mental states. Our proposed program provides a space to discuss pathways for understanding and applying ToM in psycholinguistics, pragmatics, human value alignment, social good, model explainability, and many other areas of NLP. ToM 2023 will be a full-day hybrid in-person/virtual workshop with several keynote speeches, and oral/poster/spotlight presentations, followed by a breakout discussion, panel discussion, and best paper award announcement. We also intend to host a mentoring program to broaden participation from a diverse set of researchers.",
                            "essays": [
                                {
                                    "essay": "How To Make Social Decisions in a Heterogeneous Society? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Iterative Machine Teaching for Black-box Markov Learners ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Language Models are Pragmatic Speakers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Preference Proxies: Evaluating Large Language Models in capturing Human Preferences in Human-AI Tasks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Inferring the Goals of Communicating Agents from Actions and Instructions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Neuro-Symbolic Inverse Planning Engine (NIPE): Modeling probabilistic social inferences from linguistic inputs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Hi-ToM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "EPITOME: Experimental Protocol Inventory for Theory Of Mind Evaluation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robust Inverse Reinforcement Learning Through Bayesian Theory of Mind ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for Neural Dialogue Generation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Define, Evaluate, and Improve Task-Oriented Cognitive Capabilities for Instruction Generation Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Discovering User Types: Characterization of User Traits by Task-Specific Behaviors in Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards a better Rational Speech Act framework for context-aware modeling of metaphor understanding ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Do LLMs selectively encode the goal of an agent's reach? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "[Empirical paper track] Deciphering Enemies in the Darkness through Modeling and Examination of Knowledge in Reconnaissance Blind Chess ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Comparing the Evaluation and Production of Loophole Behavior in Children and Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Emergent deception and skepticism via theory of mind ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Between prudence and paranoia: Theory of Mind gone right, and wrong ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The SocialAI School: Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Inferring the Future by Imagining the Past ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Ballroom B None",
                            "workshop": "New Frontiers in Learning, Control, and Dynamical Systems",
                            "author": [
                                "Valentin De Bortoli",
                                "Charlotte Bunne",
                                "Guan-Horng Liu",
                                "Tianrong Chen",
                                "Maxim Raginsky",
                                "Pratik Chaudhari",
                                "Melanie Zeilinger",
                                "Animashree Anandkumar"
                            ],
                            "content": "Recent advances in algorithmic design and principled, theory-driven deep learning architectures have sparked a growing interest in control and dynamical system theory. Complementary, machine learning plays an important role in enhancing existing control theory algorithms in terms of performance and scalability. The boundaries between both disciplines are blurring even further with the rise of modern reinforcement learning, a field at the crossroad of data-driven control theory and machine learning. This workshop aims to unravel the mutual relationship between learning, control, and dynamical systems and to shed light on recent parallel developments in different communities. Strengthening the connection between learning and control will open new possibilities for interdisciplinary research areas.",
                            "essays": [
                                {
                                    "essay": "Diffusion Model-Augmented Behavioral Cloning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Structured State Space Models for In-Context Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Analyzing the Sample Complexity of Model-Free Opponent Shaping ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Preventing Reward Hacking with Occupancy Measure Regularization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Taylor TD-learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Regret Bounds for Risk-sensitive Reinforcement Learning with Lipschitz Dynamic Risk Measures ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On a Connection between Differential Games, Optimal Control, and Energy-based Models for Multi-Agent Interactions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Factor Learning Portfolio Optimization Informed by Continuous-Time Finance Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning from Sparse Offline Datasets via Conservative Density Estimation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Accelerated Policy Gradient: On the Nesterov Momentum for Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Informed POMDP: Leveraging Additional Information in Model-Based RL ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On First-Order Meta-Reinforcement Learning with Moreau Envelopes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Undo Maps: A Tool for Adapting Policies to Perceptual Distortions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bridging RL Theory and Practice with the Effective Horizon ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Simulation-Free Schr\u00f6dinger Bridges via Score and Flow Matching ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning with Learning Awareness using Meta-Values ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Breaking the Curse of Multiagents in a Large State Space: RL in Markov Games with Independent Linear Function Approximation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "AbODE: Ab initio antibody design using conjoined ODEs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unbalanced Optimal Transport meets Sliced-Wasserstein ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Deep Equilibrium Based Neural Operators for Steady-State PDEs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Best Arm Identification Approach for Stochastic Rising Bandits ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exponential weight averaging as damped harmonic motion ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Modeling Accurate Long Rollouts with Temporal Neural PDE Solvers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Parallel Sampling of Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Policy-Decoupled Method for High-Quality Data Augmentation in Offline Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Tendiffpure: Tensorizing Diffusion Models for Purification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Imitation of Non-Markovian Demonstrations: From Low-Level Stability to High-Level Planning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Synthetic Experience Replay ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Embedding Surfaces by Optimizing Neural Networks with Prescribed Riemannian Metric and Beyond ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Balancing exploration and exploitation in Partially Observed Linear Contextual Bandits via Thompson Sampling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Algorithms for Optimal Adaptation ofDiffusion Models to Reward Functions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "In-Context Decision-Making from Supervised Pretraining ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fixed-Budget Hypothesis Best Arm Identification: On the Information Loss in Experimental Design ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Improved sampling via learned diffusions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Transport, VI, and Diffusions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Limited Information Opponent Modeling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Latent Space Editing in Transformer-Based Flow Matching ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Maximum State Entropy Exploration using Predecessor and Successor Representations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PAC-Bayesian Bounds for Learning LTI-ss systems with Input from Empirical Loss ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Variational quantum dynamics of two-dimensional rotor models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neural Optimal Transport with Lagrangian Costs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Efficient RL with Impaired Observability: Learning to Act with Delayed and Missing State Observations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "LEAD: Min-Max Optimization from a Physical Perspective ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Stochastic Linear Bandits with Unknown Safety Constraints and Local Feedback ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Policy Gradient Algorithms Implicitly Optimize by Continuation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fast Approximation of the Generalized Sliced-Wasserstein Distance ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Generalization Capacities of Neural Controlled Differential Equations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Modular Hierarchical Reinforcement Learning for Robotics: Improving Scalability and Generalizability ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Online Control with Adversarial Disturbance for Continuous-time Linear Systems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Flexible Diffusion Model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fairness In a Non-Stationary Environment From an Optimal Control Perspective ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Physics-informed Localized Learning for Advection-Diffusion-Reaction Systems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the effectiveness of neural priors in modeling dynamical systems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bridging Physics-Informed Neural Networks with Reinforcement Learning: Hamilton-Jacobi-Bellman Proximal Policy Optimization (HJBPPO) ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Actor-Critic Methods using Physics-Informed Neural Networks: Control of a 1D PDE Model for Fluid-Cooled Battery Packs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Taylorformer: Probabalistic Modelling for Random Processes including Time Series ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Statistics estimation in neural network training: a recursive identification approach ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Toward Understanding Latent Model Learning in MuZero: A Case Study in Linear Quadratic Gaussian Control ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Model-based Policy Optimization under Approximate Bayesian Inference ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Kernel Mirror Prox and RKHS Gradient Flow for Mixed Functional Nash Equilibrium ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Nonlinear Wasserstein Distributionally Robust Optimal Control ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Visual Dexterity: In-hand Dexterous Manipulation from Depth ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Equivalence Class Learning for GENERIC Systems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Variational Principle and Variational Integrators for Neural Symplectic Forms ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Guide Your Agent with Adaptive Multimodal Rewards ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Offline Goal-Conditioned RL with Latent States as Actions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Distributional Distance Classifiers for Goal-Conditioned Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On learning history-based policies for controlling Markov decision processes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fit Like You Sample: Sample-Efficient Generalized Score Matching from Fast Mixing Markov Chains ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Coupled Gradient Flows for Strategic Non-Local Distribution Shift ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Stability of Multi-Agent Learning: Convergence in Network Games with Many Players ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sample Complexity of Hierarchical Decompositions in Markov Decision Processes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Action and Trajectory Planning for Urban Autonomous Driving with Hierarchical Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Boosting Off-policy RL with Policy Representation and Policy-extended Value Function Approximator ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Parameterized projected Bellman operator ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Randomly Coupled Oscillators for Time Series Processing ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A neural RDE approach for continuous-time non-Markovian stochastic control problems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "What is the Solution for State-Adversarial Multi-Agent Reinforcement Learning? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Trajectory Generation, Control, and Safety with Denoising Diffusion Probabilistic Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sub-linear Regret in Adaptive Model Predictive Control ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Gradient-free training of neural ODEs for system identification and control using ensemble Kalman inversion ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning to Optimize with Recurrent Hierarchical Transformers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Optimization or Architecture: What Matters in Non-Linear Filtering? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unbalanced Diffusion Schr\u00f6dinger Bridge ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Aligned Diffusion Schr\u00f6dinger Bridges ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "When is Agnostic Reinforcement Learning Statistically Tractable? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Leveraging Factored Action Spaces for Off-Policy Evaluation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Continuous Vector Quantile Regression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Vector Quantile Regression on Manifolds ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Dynamic Feature-based Newsvendor ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Game Theoretic Neural ODE Optimizer ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On Convergence of Approximate Schr\"{o}dinger Bridge with Bounded Cost ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Improving Offline-to-Online Reinforcement Learning with Q-Ensembles ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "IQL-TD-MPC: Implicit Q-Learning for Hierarchical Model Predictive Control ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Importance Weighted Actor-Critic for Optimal Conservative Offline Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Randomized methods for computing optimal transport without regularization and their convergence analysis ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 310 None",
                            "workshop": "Differentiable Almost Everything: Differentiable Relaxations, Algorithms, Operators, and Simulators",
                            "author": [
                                "Felix Petersen",
                                "Marco Cuturi",
                                "Mathias Niepert",
                                "Hilde Kuehne",
                                "Michael Kagan",
                                "Willie Neiswanger",
                                "Stefano Ermon"
                            ],
                            "content": "Gradients and derivatives are integral to machine learning, as they enable gradient-based optimization. In many real applications, however, models rest on algorithmic components that implement discrete decisions, or rely on discrete intermediate representations and structures. These discrete steps are intrinsically non-differentiable and accordingly break the flow of gradients. To use gradient-based approaches to learn the parameters of such models requires turning these non-differentiable components differentiable. This can be done with careful considerations, notably, using smoothing or relaxations to propose differentiable proxies for these components. With the advent of modular deep learning frameworks, these ideas have become more popular than ever in many fields of machine learning, generating in a short time-span a multitude of \"differentiable everything\", impacting topics as varied as rendering, sorting and ranking, convex optimizers, shortest-paths, dynamic programming, physics simulations, NN architecture search, top-k, graph algorithms, weakly- and self-supervised learning, and many more."
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 314 None",
                            "workshop": "PAC-Bayes Meets Interactive Learning",
                            "author": [
                                "Hamish Flynn",
                                "Maxime Heuillet",
                                "Audrey Durand",
                                "Melih Kandemir",
                                "Benjamin Guedj"
                            ],
                            "content": "Interactive learning encompasses online learning, continual learning, active learning, bandits, reinforcement learning, and other settings where an algorithm must learn while interacting with a continual stream of data. Such problems often involve exploration-exploitation dilemmas, which can be elegantly handled with probabilistic and Bayesian methods. Deep interactive learning methods leveraging neural networks are typically used when the setting involves rich observations, such as images. As a result, both probabilistic and deep interactive learning methods are growing in popularity. However, acquiring observations in an interactive fashion with the environment can be costly. There is therefore great interest in understanding when sample-efficient learning with probabilistic and deep interactive learning can be expected or guaranteed. Within statistical learning theory, PAC-Bayesian theory is designed for the analysis of probabilistic learning methods. It has recently been shown to be well-suited for the analysis of deep learning methods. This workshop aims to bring together researchers from the broad Bayesian and interactive learning communities in order to foster the emergence of new ideas that could contribute to both theoretical and empirical advancement of PAC-Bayesian theory in interactive learning settings.",
                            "essays": [
                                {
                                    "essay": "Bayesian Risk-Averse Q-Learning with Streaming Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Improved Time-Uniform PAC-Bayes Bounds using Coin Betting ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Improved Time-Uniform PAC-Bayes Bounds using Coin Betting ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "XLDA: Linear Discriminant Analysis for Scaling Continual Learning to Extreme Classification Settings at the Edge ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Information-Theoretic Generalization Bounds for the Subtask Problem ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PAC-Bayesian Error Bound, via R'enyi Divergence, for a Class of Linear Time-Invariant State-Space Models ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "PAC-Bayesian Error Bound, via R'enyi Divergence, for a Class of Linear Time-Invariant State-Space Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Flat minima can fail to transfer to downstream tasks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PAC-Bayesian Domain Adaptation Bounds for Multi-view learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Experiment Planning with Function Approximation ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "PAC-Bayesian Offline Contextual Bandits with Guarantees ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Anytime Model Selection in Linear Bandits ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "PAC-Bayes bounds\u2019 parameter optimization via events\u2019 space discretization: new bounds for losses with general tail behaviors ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "PAC-Bayes bounds\u2019 parameter optimization via events\u2019 space discretization: new bounds for losses with general tail behaviors ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Tighter fast and mixed rate PAC-Bayes bounds ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Anytime Model Selection in Linear Bandits ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PAC-Bayesian Offline Contextual Bandits with Guarantees ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Experiment Planning with Function Approximation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Computing non-vacuous PAC-Bayes generalization bounds for Models under Adversarial Corruptions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bayesian Feasibility Determination with Multiple Constraints ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 316 AB None",
                            "workshop": "The Many Facets of Preference-Based Learning",
                            "author": [
                                "Aadirupa Saha",
                                "Mohammad Ghavamzadeh",
                                "Robert Busa-Fekete",
                                "Branislav Kveton",
                                "Viktor Bengs"
                            ],
                            "content": "Learning from human preferences or preference-based learning has been critical to major advancements in AI and machine learning. Since human beings are naturally more reliable at providing feedback on a relative scale compared to numerical values, collecting preference feedback is more budget-friendly and involves less bias. The broad objective of this workshop is twofold:1) Bring together different communities where preference-based learning has played a major role. This includes dueling bandits, multi-agent games, econometrics, social choice theory, reinforcement learning, optimization, robotics and many more, for which we aim to create a suitable forum to exchange techniques, ideas, learn from each other and potentially create new and innovative research questions. 2) Connect theory to practice by identifying real-world systems which can benefit from incorporating preference feedback, such as marketing, revenue management, search engine optimization, recommender systems, healthcare, language modeling, interactive chatbots, text summarization, robotics, and so on.We will consider our workshop a success if it inspires researchers to embark on novel insights in the general area of preference-based learning: Bringing attention from different communities to foster dissemination, cross-fertilization and discussion at scale. Especially, building bridges between experimental researchers and theorists towards developing better models and practical algorithms, and encouraging participants to propose, sketch, and discuss new starting points, questions or applications."

                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 317 B None",
                            "workshop": "2nd Annual Workshop on Topology, Algebra, and Geometry in Machine Learning (TAG-ML)",
                            "author": [
                                "Tegan Emerson",
                                "Henry Kvinge",
                                "Tim Doster",
                                "Bastian Rieck",
                                "Sophia Sanborn",
                                "Nina Miolane"
                            ],
                            "content": "Much of the data that is fueling current rapid advances in machine learning is high dimensional, structurally complex, and strongly nonlinear. This poses challenges for researcher intuition when they ask (i) how and why current algorithms work and (ii) what tools will lead to the next big break-though. Mathematicians working in topology, algebra, and geometry have more than a hundred years worth of finely-developed machinery whose purpose is to give structure to, help build intuition about, and generally better understand spaces and structures beyond those that we can naturally understand. Following on the success of the first TAG-ML workshop in 2022, this workshop will showcase work which brings methods from topology, algebra, and geometry and uses them to help answer challenging questions in machine learning. Topics include mathematical machine learning, explainability, training schemes, novel algorithms, performance metrics, and performance guarantees. All accepted papers will be included in an associated PMLR volume.",
                            "essays": [
                                {
                                    "essay": "Implicitly Learned Invariance and Equivariance in Linear Regression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Group Invariant Global Pooling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A new perspective on building efficient and expressive 3D equivariant graph neural networks ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Learning Lie Group Symmetry Transformations with Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning To See Topological Properties In 4D Using Convolutional Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Expressive Sign Equivariant Networks for Spectral Geometric Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Ability of Graph Neural Networks to Model Interactions Between Vertices ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "An ML approach to resolution of singularities ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DeepEMD: A Transformer-based Fast Estimation of the Earth Mover's Distance ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Polyhedral Complex Extraction from ReLU Networks using Edge Subdivision ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Geometric Algebra Transformers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Conditional Bisimulation for Generalization in Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "FAM: Relative Flatness Aware Minimization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "One-Shot Neural Network Pruning via Spectral Graph Sparsification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Differentially Private Clustering in Data Streams ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Episodic Memory Theory of Recurrent Neural Networks: Insights into Long-Term Information Storage and Manipulation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "MASIL: Towards Maximum Separable Class Representation for Few Shot Class Incremental Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Topological Feature Selection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On Explicit Curvature Regularization in Deep Generative Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Large Graph Property Prediction via Graph Segment Training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ReLU Neural Networks, Polyhedral Decompositions, and Persistent Homology ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Geometric Insight into Equivariant Message Passing Neural Networks on Riemannian Manifolds ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Weisfeiler-Lehman Distance: Reinterpretation and Connection with GNNs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Geometrically Regularized Wasserstein Dictionary Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "k-Means Clustering with Distance-Based Privacy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data, Geometry and Homology ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Breaking the Structure of Multilayer Perceptrons with Complex Topologies ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Can strong structural encoding reduce the importance of Message Passing? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Product Manifold Learning with Independent Coordinate Selection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Metric Space Magnitude and Generalisation in Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Homological Neural Networks: A Sparse Architecture for Multivariate Complexity ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning to Explain Hypergraph Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On genuine invariance learning without weight-tying ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "An Exact Kernel Equivalence for Finite Classification Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A margin-based multiclass generalization bound via geometric complexity ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bridging Equational Properties and Patterns on Graphs: an AI-Based Approach ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Explaining Graph Neural Networks Using Interpretable Local Surrogates ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Visualizing and Analyzing the Topology of Neuron Activations in Deep Adversarial Training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Deep Networks as Paths on the Manifold of Neural Representations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sumformer: Universal Approximation for Efficient Transformers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Equivariant Self-supervised Deep Pose Estimation for Cryo EM ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Lie Point Symmetry and Physics Informed Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Assessing Neural Network Representations During Training Using Data Diffusion Spectra ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Expressive Power of Ollivier-Ricci Curvature on Graphs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Gromov-Hausdorff Distances for Comparing Product Manifolds of Model Spaces ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Non-isotropic Persistent Homology ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Enriching Disentanglement: Definitions to Metrics ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Polynomial Problems with SL(2)-Equivariance ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Exact Sample Complexity Gain from Invariances for Kernel Regression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Regression on Latent Spaces for the Analysis of Multi-Condition Single-Cell RNA-Seq Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Caveats of neural persistence in deep neural networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Asynchronous Algorithmic Alignment with Cocycles ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Relationship Between Data Manifolds and Adversarial Examples ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Equivariant Representation Learning with Equivariant Convolutional Kernel Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Evolving Computation Graphs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Which Features are Learned by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sample Complexity Bounds for Estimating the Wasserstein Distance under Invariances ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Hyperbolic VAE via Latent Gaussian Distributions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neural Networks Are Graphs! Graph Neural Networks for Equivariant Processing of Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Desiderata for Representation Learning from Identifiability, Disentanglement, and Group-Structuredness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Edge Importance Scores for Editing Graph Topology to Preserve Fairness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learned Gridification for Efficient Point Cloud Processing ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Linear Regression on Manifold Structured Data: the Impact of Extrinsic Geometry on Solutions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fast computation of permutation equivariant layers with the partition algebra ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unsupervised Learning of 3-colorings using Simplicial Higher-Order Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Can Euclidean Symmetry Help in Reinforcement Learning and Planning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Infusing invariances in neural representations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Heat Diffusion Perspective on Geodesic Preserving Dimensionality Reduction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Topologically Attributed Graphs for Shape Discrimination ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Hyperbolic Sliced-Wasserstein via Geodesic and Horospherical Projections ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Breaking the Curse of Depth in Graph Convolutional Networks via Refined Initialization Strategy ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Mixed-Curvature Transformers for Graph Representation Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "UGSL: A Unified Framework for Benchmarking Graph Structure Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unsupervised Embedding Quality Evaluation ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Latent Space Symmetry Discovery ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "GRIL: A 2-parameter Persistence Based Vectorization for Machine Learning ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Learning Structured Representations with Equivariant Contrastive Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Positional Encodings as Group Representations: A Unified Framework ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fisher-Rao and pullback Hilbert cone distances on the multivariate Gaussian manifold with applications to simplification and quantization of mixtures ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Non-linear Embeddings in Hilbert Simplex Geometry ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 320 None",
                            "workshop": "The Synergy of Scientific and Machine Learning Modelling (SynS & ML) Workshop",
                            "author": [
                                "Antoine Wehenkel",
                                "J\u00f6rn Jacobsen",
                                "Emily Fox",
                                "Anuj Karpatne",
                                "Victoriya Kashtanova",
                                "Xuan Di",
                                "Emmanuel de Bézenac",
                                "Naoya Takeishi",
                                "Gilles Louppe"
                            ],
                            "content": [
                                "The Synergy of Scientific and Machine Learning Modeling Workshop (“SynS & ML”) is an interdisciplinary forum for researchers and practitioners interested in the challenges of combining scientific and machine-learning models. The goal of the workshop is to gather together machine learning researchers eager to include scientific models into their pipelines, domain experts working on augmenting their scientific models with machine learning, and researchers looking for opportunities to incorporate ML in widely-used scientific models.",
                                "The power of machine learning (ML), its ability to build models by leveraging real-world data is also a big limitation; the quality and quantity of training data bound the validity domain of ML models. On the other hand, expert models are designed from first principles or experiences and labelled scientific if validated on curated real-world data, often even harvested for this specific purpose, as advised by the scientific method since Galileo. Expert models only describe idealized versions of the world which may hinder their deployment for important tasks such as accurate forecasting or parameter inference. This workshop focuses on the combination of two modelling paradigms: scientific and ML modelling. Sometimes called hybrid learning or grey-box modelling, this combination should 1) unlock new applications for expert models, and 2) leverage the data compressed within scientific models to improve the quality of modern ML models. In this spirit, the workshop focuses on the symbiosis between these two complementary modelling approaches; it aims to be a “rendezvous” between the involved communities, spanning sub-fields of science, engineering and health, and encompassing ML, to allow them to present their respective problems and solutions and foster new collaborations. The workshop invites researchers to contribute to such topics; see Call for Papers and Call for Scientific Models for more details."
                            ]
                        },
                        {
                            "time": "Sat Jul 29 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 312 None",
                            "workshop": "2nd Workshop on Formal Verification of Machine Learning",
                            "author": [
                                "Mark M\u00fcller",
                                "Brendon G. Anderson",
                                "Leslie Rice",
                                "Zhouxing Shi",
                                "Shubham Ugare",
                                "Huan Zhang",
                                "Martin Vechev",
                                "Zico Kolter",
                                "Somayeh Sojoudi",
                                "Cho-Jui Hsieh"
                            ],
                            "content": "As machine learning-based systems are increasingly deployed in safety-critical applications, providing formal guarantees on their trustworthiness becomes ever more important. To facilitate the investigation of this challenging problem, we propose the 2nd Workshop on Formal Verification of Machine Learning (WFVML). WFVML will raise awareness for the importance of the formal verification of machine learning systems, bring together researchers from diverse backgrounds with interest in the topic, and enable the discussion of open problems as well as promising avenues in this emerging research area. Building on the success of last year, WFVML features a diverse panel of 8 confirmed invited speakers who made foundational contributions to the young field and an experienced and diverse multi-institutional organizing team of 10, including pioneering proponents of machine learning verification. A schedule combining invited talks, contributed talks, poster sessions, and a panel will provide opportunities and input for open discussions, with remote participation enabled via Zoom. Please see our website ml-verification.com for more details.",
                            "events": [
                                {
                                    "event": "Opening Remarks"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "Morning Break ",
                                    "form": "Break"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Contributed Talk"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Contributed Talk"
                                },
                                {
                                    "event": "Morning Poster Session ",
                                    "form": "Poster Session"
                                },
                                {
                                    "event": "Lunch Break ",
                                    "form": "Break"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Contributed Talk"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Contributed Talk"
                                },
                                {
                                    "event": "Afternoon Break ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Afternoon Poster Session ",
                                    "form": "Poster Session"
                                },
                                {
                                    "event": "TBD ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "Panel"
                                },
                                {
                                    "event": "Closing Remark"
                                }
                            ],
                            "essays": [
                                {
                                    "essay": "A Toolbox for Fast Interval Arithmetic in numpy with an Application to Formal Verification of Neural Network Controlled Systems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Probabilistic Global Robustness Verification of Arbitrary Supervised Machine Learning Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "(Almost) Provable Error Bounds Under Distribution Shift via Disagreement Discrepancy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Toward Continuous Verification of DNNs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Verifying Monotonicity and Robustness Properties for Domain-Specific DRL Algorithms ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Meaning in Language Models: A Formal Semantics Approach ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Interpreting Robustness Proofs of Deep Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Stability Guarantees for Feature Attributions with Multiplicative Smoothing ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robustness Verification for Perception Models against Camera Motion Perturbations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Efficient Estimation of Local Robustness of Machine Learning Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Constraint Satisfied Sampling for Formal Verification in Geometric Deep Learning and Molecular Modelling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Your Value Function is a Control Barrier Function ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "One Pixel Adversarial Attacks via Sketched Programs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DeepBern-Nets: Taming the Complexity of Certifying Neural Networks using Bernstein Polynomial Activations and Precise Bound Propagation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Benchmarking Formal Verification for Autonomous Driving in the Wild ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Formal Control Synthesis for Stochastic Neural Network Dynamic Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Provably Correct Physics-Informed Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Formal Verification for Counting Unsafe Inputs in Deep Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Understanding Certified Training with Interval Bound Propagation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Connecting Certified and Adversarial Training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Counterfactually Invariant Predictors ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Formal Verification for Neural Networks with General Nonlinearities via Branch-and-Bound ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fast Feature Selection with Fairness Constraints ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 316 AB None",
                            "workshop": "The Second Workshop on Spurious Correlations, Invariance and Stability",
                            "author": [
                                "Yoav Wald",
                                "Claudia Shi",
                                "Aahlad Puli",
                                "Amir Feder",
                                "Limor Gultchin",
                                "Mark Goldstein",
                                "Maggie Makar",
                                "Victor Veitch",
                                "Uri Shalit"
                            ],
                            "content": [
                                "As machine learning models are introduced into every aspect of our lives, and potential benefits become abundant, so do possible catastrophic failures. One of the most common failure scenarios when deploying machine learning models in the wild, which could possibly lead to dire consequences in extreme cases, is the reliance of models on apparently unnatural or irrelevant features.",
                                "The issue comes up in a variety of applications: from the reliance of detection models for X-rays on scanner types and marks made by technicians in the hospital, through visual question answering models being sensitive to linguistic variations in the questions, the list of examples for such undesirable behaviors keeps growing.In examples like these, the undesirable behavior stems from the model exploiting a spurious correlation.",
                                "Following last year's workshop on Spurious Correlations, Invariance and Stability (SCIS), it is apparent that work on spurious correlations is a long-term effort that spans communities such as fairness, causality-inspired ML, and domains such as NLP, healthcare and many others. Hence we hope that this year's workshop, the second edition of SCIS, will help facilitate this long term effort across communities. The workshop will feature talks by top experts doing methodological work on dealing with spurious correlations, and an extended poster session to allow extensive discussion on work submitted to the workshop."
                            ],
                            "essays": [
                                {
                                    "essay": "Complementary Benefits of Contrastive Learning and Self-Training Under Distribution Shift ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "(Almost) Provable Error Bounds Under Distribution Shift via Disagreement Discrepancy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Leveraging Task Structures for Improved Identifiability in Neural Network Representations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Regularizing Adversarial Imitation Learning Using Causal Invariance ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Uncertainty-Guided Online Test-Time Adaptation via Meta-Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Reviving Shift Equivariance in Vision Transformers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ModelDiff: A Framework for Comparing Learning Algorithms ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Improve Identity-Robustness for Face Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SAFE: Stable Feature Extraction without Environment Labels ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robust Learning with Progressive Data Expansion Against Spurious Correlation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifiability Guarantees for Causal Disentanglement from Soft Interventions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Fair Knowledge Distillation using Student Feedback ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ERM++: An Improved Baseline for Domain Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Front-door Adjustment Beyond Markov Equivalence with Limited Graph Knowledge ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Implications of Gaussian process kernel mismatch for out-of-distribution data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Leveraging sparse and shared feature activations for disentangled representation learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Complementing a Policy with a Different Observation Space ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Calibrated Propensities for Causal Effect Estimation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bridging the Domain Gap by Clustering-based Image-Text Graph Matching ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Temporal Consistency based Test Time Adaptation: Towards Fair and Personalized AI ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Provable domain adaptation using privileged information ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Towards Modular Learning of Deep Causal Generative Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Feature Selection in the Presence of Monotone Batch Effects ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fairness-Preserving Regularizer: Balancing Core and Spurious Features ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Shortcut Learning Through the Lens of Training Dynamics ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exploring new ways: Enforcing representational dissimilarity to learn new features and reduce error consistency ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Causal Dynamics Learning with Quantized Local Independence Discovery ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adversarial Data Augmentations for Out-of-Distribution Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Studying Generalization on Memory-Based Methods in Continual Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Weighted Risk Invariance for Density-Aware Domain Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Cosine Similarity-based Method for Out-of-Distribution Detection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards A Scalable Solution for Compositional Multi-Group Fair Classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neuro-Causal Factor Analysis ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Contextual Vision Transformers for Robust Representation Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Shortcut Detection with Variational Autoencoders ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Impact of Noise on Calibration and Generalisation of Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Results on Counterfactual Invariance ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Spuriosity Rankings for Free: A Simple Framework for Last Layer Retraining Based on Object Detection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Cross-Risk Minimization: Inferring Groups Information for Improved Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Understanding the Detrimental Class-level Effects of Data Augmentation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Mitigating Simplicity Bias in Deep Learning for Improved OOD Generalization and Robustness ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Do as your neighbors: Invariant learning through non-parametric neighbourhood matching ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Spuriosity Didn\u2019t Kill the Classifier: Using Invariant Predictions to Harness Spurious Features ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Last-Layer Fairness Fine-tuning is Simple and Effective for Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Stabilizing GNN for Fairness via Lipschitz Bounds ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Large Dimensional Change Point Detection with FWER Control as Automatic Stopping ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Antibody DomainBed: Towards robust predictions using invariant representations of biological sequences carrying complex distribution shifts ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data Models for Dataset Drift Controls in Machine Learning With Optical Images ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bias-to-Text: Debiasing Unknown Visual Biases by Language Interpretation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Role of Linguistic Priors in Measuring Compositional Generalization of Vision-language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Counterfactually Invariant Predictors ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Independent Causal Mechanisms ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Invariant Causal Set Covering Machines ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Transportable Representations for Out-of-distribution Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sharpness-Aware Minimization Enhances Feature Diversity ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Arbitrary Decisions are a Hidden Cost of Differentially Private Training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Removing Multiple Biases through the Lens of Multi-task Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Understanding Feature Learning in Out-of-Distribution Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Prediction without Preclusion: Recourse Verification with Reachable Sets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Seeing is not Believing: Robust Reinforcement Learning against Spurious Correlation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Group Robustness via Adaptive Class-Specific Scaling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Where Does My Model Underperform?: A Human Evaluation of Slice Discovery Algorithms ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Replicable Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Concept Algebra for Score-based Conditional Model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Deep Neural Networks Extrapolate Cautiously (Most of the Time) ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Mitigating Spurious Correlations in Multi-modal Models during Fine-tuning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Group Fairness with Uncertainty in Sensitive Attributes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robustness through Loss Consistency Regularization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Which Features are Learned by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Separating multimodal modeling from multidimensional modeling for multimodal learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Why is SAM Robust to Label Noise? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Spurious Correlations and Where to Find Them ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Pruning for Better Domain Generalizability ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Regularizing Model Gradients with Concepts to Improve Robustness to Spurious Correlations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Causal-structure Driven Augmentations for Text OOD Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Saving a Split for Last-layer Retraining can Improve Group Robustness without Group Annotations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifiability of Discretized Latent Coordinate Systems via Density Landmarks Detection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Tackling Shortcut Learning in Deep Neural Networks: An Iterative Approach with Interpretable Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Confident feature ranking ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Diverse Features in Vision Transformers for Improved Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifying and Disentangling Spurious Features in Pretrained Image Representations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Approximate Causal Effect Identification under Weak Confounding ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Optimization or Architecture: What Matters in Non-Linear Filtering? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "C-Disentanglement: Discovering Causally-Independent Generative Factors under an Inductive Bias of Confounder ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Out of the Ordinary: Spectrally Adapting Regression for Covariate Shift ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Linear Causal Representations from Interventions under General Nonlinear Mixing ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 301 None",
                            "workshop": "\"Could it have been different?\" Counterfactuals in Minds and Machines",
                            "author": [
                                "Nina Corvelo Benz",
                                "Ricardo Dominguez Olmedo",
                                "Manuel Gomez-Rodriguez",
                                "Thorsten Joachims",
                                "Amir-Hossein Karimi",
                                "Stratis Tsirtsis",
                                "Isabel Valera",
                                "Sarah A Wu"
                            ],
                            "content": "Had I left 5 minutes earlier, I would have caught the bus. Had I been driving slower, I would have avoided the accident. Counterfactual thoughts—“what if?” scenarios about outcomes contradicting what actually happened—play a key role in everyday human reasoning and decision-making. In conjunction with rapid advancements in the mathematical study of causality, there has been an increasing interest in the development of machine learning methods that support elements of counterfactual reasoning, i.e., they make predictions about outcomes that \"could have been different\". Such methods find applications in a wide variety of domains ranging from personalized healthcare and explainability to AI safety and offline reinforcement learning. Although the research at the intersection of causal inference and machine learning is blooming, there has been no venue so far explicitly focusing on methods involving counterfactuals. In this workshop, we aim to fill that space by facilitating interdisciplinary interactions that will shed light onto the three following questions: (i) What insights can causal machine learning take from the latest advances in cognitive science? (ii) In what use cases is each causal modeling framework most appropriate for modeling counterfactuals? (iii) What barriers need to be lifted for the wider adoption of counterfactual-based machine learning applications, like personalized healthcare?",
                            "essays": [
                                {
                                    "essay": "Navigating Explanatory Multiverse Through Counterfactual Path Geometry ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neuro-Symbolic Models of Human Moral Judgment: LLMs as Automatic Feature Extractors ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactual Learning to Rank via Knowledge Distillation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Advancing Counterfactual Inference through Quantile Regression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactual Memorization in Neural Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Interventional and Counterfactual Inference with Diffusion Models ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Counterfactuals for Subjective Wellbeing Panel Data: Integrated Application of Statistical Ensemble and Machine Learning Methods ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Budgeting Counterfactual for Offline RL ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Rethinking Counterfactual Explanations as Local and Regional Counterfactual Policies ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Interventional and Counterfactual Inference with Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Finding Counterfactually Optimal Action Sequences in Continuous State Spaces ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Natural Counterfactuals With Necessary Backtracking ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Natural Counterfactuals With Necessary Backtracking ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Causal Proxy Models for Concept-Based Model Explanations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Semantic Meaningfulness: Evaluating Counterfactual Approaches for Real-World Plausibility and Feasibility ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Time-uniform confidence bands for the CDF under nonstationarity ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bayesian Predictive Synthetic Control Methods ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Causal Inference with Synthetic Control Methods by Density Matching under Implicit Endogeneitiy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Why Don\u2019t We Focus on Episodic Future Reasoning, Not Only Counterfactual? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identification of Nonlinear Latent Hierarchical Causal Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactuals for the Future ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Causal Dependence Plots ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Empowering Counterfactual Reasoning for Graph Neural Networks via Inductivity ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactual Fairness Without Modularity ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactual Explanations for Misclassified Images: How Human and Machine Explanations Differ ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Delphic Offline Reinforcement Learning under Nonidentifiable Hidden Confounding ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adaptive Principal Component Regression with Applications to Panel Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Strategyproof Decision-Making in Panel Data Settings and Beyond ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactual Explanation Policies in RL ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Extending counterfactual reasoning models to capture unconstrained social explanations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactually Comparing Abstaining Classifiers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Forward-INF : Efficient Data Influence Estimation with Duality-based Counterfactual Analysis ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Inverse Transition Learning for Characterizing Near-Optimal Dynamics in Offline Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactually Comparing Abstaining Classifiers ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Counterfactual Explanations for Misclassified Images: How Human and Machine Explanations Differ ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Causal Proxy Models for Concept-Based Model Explanations ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Closed-loop Reasoning about Counterfactuals to Improve Policy Transparency ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Leveraging Contextual Counterfactuals Toward Belief Calibration ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "In the Eye of the Beholder: Robust Prediction with Causal User Modeling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Linear Causal Representations from Interventions under General Nonlinear Mixing ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Leveraging Factored Action Spaces for Off-Policy Evaluation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Observational Counterfactual Explanations in Sequential Decision Making ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Counterfactual Generation with Identifiability Guarantees ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unveiling the Betrayal of Counterfactual Explanations within Recommender Systems ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 315 None",
                            "workshop": "Interactive Learning with Implicit Human Feedback",
                            "author": [
                                "Andi Peng",
                                "Akanksha Saran",
                                "Andreea Bobu",
                                "Tengyang Xie",
                                "Pierre-Yves Oudeyer",
                                "Anca Dragan",
                                "John Langford"
                            ],
                            "content": "Systems that can learn interactively from their end-users are quickly becoming widespread in real-world applications. Typically humans provide tagged rewards or scalar feedback for such interactive learning systems. However, humans offer a wealth of implicit information (such as multimodal cues in the form of natural language, speech, eye movements, facial expressions, gestures etc.) which interactive learning algorithms can leverage during the process of human-machine interaction to create a grounding for human intent, and thereby better assist end-users. A closed-loop sequential decision-making domain offers unique challenges when learning from humans -– (1) the data distribution may be influenced by the choices of the algorithm itself, and thus interactive ML algorithms need to adaptively learn from human feedback, (2) the nature of the environment itself changes rapidly, (3) humans may express their intent in various forms of feedback amenable to naturalistic real-world settings, going beyond tagged rewards or demonstrations. By organizing this workshop, we attempt to bring together interdisciplinary experts in interactive machine learning, reinforcement learning, human-computer interaction, cognitive science, and robotics to explore and foster discussions on such challenges. We envision that this exchange of ideas within and across disciplines can build new bridges, address some of the most valuable challenges in interactive learning with implicit human feedback, and also provide guidance to young researchers interested in growing their careers in this space."
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 311 None",
                            "workshop": "Artificial Intelligence & Human Computer Interaction",
                            "author": [
                                "Yang Li",
                                "Ranjay Krishna",
                                "Helena Vasconcelos",
                                "Bryan Wang",
                                "Forrest Huang"
                            ],
                            "content": "Artificial intelligence (AI) and Human Computer Interaction (HCI) share common roots: early work on conversational agents has laid the foundation for both fields. However, economic and political influences have driven these fields to remain separate in subsequent decades. The recent rise of data-centric methods in machine learning has propelled few-shot emergent AI capabilities, resulting in a raft of practical tools. In particular, modern AI techniques now power new ways for machines and humans to interact. Recently, a wave of HCI tasks have been proposed to the machine learning community, which direct AI research by contributing new datasets and benchmarks, and challenging existing modeling techniques, learning methodologies, and evaluation protocols. This workshop offers a forum for researchers to discuss these new research directions, identifying important challenges, showcasing new computational and scientific ideas that can be applied, sharing datasets/tools that are already available, or proposing those that should be further developed.",
                            "essays": [
                                {
                                    "essay": "Large Language Models as a Proxy For Human Evaluation in Assessing the Comprehensibility of Disordered Speech Transcription ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PromptCrafter: Crafting Text-to-Image Prompt through Mixed-Initiative Dialogue with LLM ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Discovering User Types: Characterization of User Traits by Task-Specific Behaviors in Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Designing Decision Support Systems Using Counterfactual Prediction Sets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "An Interactive Human-Machine Learning Interface for Collecting and Learning from Complex Annotations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Crowdsourced Clustering via Active Querying: Practical Algorithm with Theoretical Guarantees ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "feather - a Python SDK to share and deploy models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Designing interactions with AI to support the scientific peer review process ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adaptive interventions for both accuracy and time in AI-assisted human decision making ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Iterative Disambiguation: Towards LLM-Supported Programming and System Design ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Active Reinforcement Learning from Demonstration in Continuous Action Spaces ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Spotlight: Mobile UI Understanding using Vision-Language Models with a Focus ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Demystifying the Role of Feedback in GPT Self-Repair for Code Generation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Semi-supervised Concept Bottleneck Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Mitigating Spurious Correlations in Image Classifiers with Simple Yes-no Feedback ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Interactively Optimizing Layout Transfer for Vector Graphics ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Human-in-the-Loop Out-of-Distribution Detection with False Positive Rate Control ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A More Robust Baseline for Active Learning by Injecting Randomness to Uncertainty Sampling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Co-creating a globally interpretable model with human input ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The corrupting influence of AI as a boss or Counterparty ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Black-Box Batch Active Learning for Regression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Rethinking Model Evaluation as Narrowing the Socio-Technical Gap ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Human-Aligned Calibration for AI-Assisted Decision Making ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "LeetPrompt: Leveraging Collective Human Intelligence to Study LLMs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Workflow Discovery from Dialogues in the Low Data Regime ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exploring Mobile UI Layout Generation using Large Language Models Guided by UI Grammar ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Semantically-Aware UI Design Tools: Design, Implementation and Evaluation of Semantic Grouping Guidelines ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Language Models can Solve Computer Tasks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Uncertainty Fingerprints: Interpreting Model Decisions with Human Conceptual Hierarchies ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "How vulnerable are doctors to unsafe hallucinatory AI suggestions? A framework for evaluation of safety in clinical human-AI cooperation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Informed Novelty Detection in Sequential Data by Per-Cluster Modeling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Ada-TTA: Towards Adaptive High-Quality Text-to-Talking Avatar Synthesis ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Participatory Personalization in Classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Partial Label Learning meets Active Learning: Enhancing Annotation Efficiency through Binary Questioning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Give Weight to Human Reactions: Optimizing Complementary AI in Practical Human-AI Teams ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Prediction without Preclusion Recourse Verification with Reachable Sets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Do Users Write More Insecure Code with AI Assistants? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Designing Data: Proactive Data Collection and Iteration for Machine Learning Using Reflexive Planning, Monitoring, and Density Estimation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ConvGenVisMo: Evaluation of conversational generative vision models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "State trajectory abstraction and visualization method for explainability in reinforcement learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SAP-sLDA: An Interpretable Interface for Exploring Unstructured Text ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adaptive User-centered Neuro-symbolic Learning for Multimodal Interaction with Autonomous Systems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Computational Approaches for App-to-App Retrieval and Design Consistency Check ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Mitigating Label Bias via Decoupled Confident Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Never-ending Learning of User Interfaces ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "How Can AI Reason Your Character? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ConceptEvo: Interpreting Concept Evolution in Deep Learning Training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "HateXplain2.0: An Explainable Hate Speech Detection Framework Utilizing Subjective Projection from Contextual Knowledge Space to Disjoint Concept Space ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "LayerDiffusion: Layered Controlled Image Editing with Diffusion Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Exploring Open Domain Image Super-Resolution through Text ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Creating a Bias-Free Dataset of Food Delivery App Reviews with Data Poisoning Attacks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Symbiotic Co-Creation with AI ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Toward Model Selection Through Measuring Dataset Similarity on TensorFlow Hub ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Personalized Prediction of Recurrent Stress Events Using Self-Supervised Learning on Multimodal Time-Series Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unsupervised Learning of Distributional Properties can Supplement Human Labeling and Increase Active Learning Efficiency in Anomaly Detection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Breadcrumbs to the Goal: Goal-Conditioned Exploration from Human-in-the-loop feedback ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Are Good Explainers Secretly Human-in-the-Loop Active Learners? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "CHILLI: A data context-aware perturbation method for XAI ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neuro-Symbolic Models of Human Moral Judgment: LLMs as Automatic Feature Extractors ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 323 None",
                            "workshop": "Machine Learning for Multimodal Healthcare Data",
                            "author": [
                                "Julia Schnabel",
                                "Andreas Maier",
                                "Pallavi Tiwari",
                                "Oliver Stegle"
                            ],
                            "content": "This new workshop will bring together interdisciplinary scientists and practitioners working at the intersections of machine learning (ML) to medicine, pathology and biology, for presenting new methods and solutions for healthcare challenges across the full range of multimodal, and often highly heterogeneous and complex patient data, to the wider ICML community. Topics of interest include, but are not limited to: Multimodal fusion and learning in medical imaging, digital pathology, computational biology, genetics, electronic healthcare records; Multimodal biomarkers for early prediction of disease onset, therapeutic response or disease recurrence; Benchmarking, domain shifts, and generalization of ML in multimodal healthcare data; ML for dealing with inherent sparsity, incompleteness and complexity of multimodal healthcare data; ML for ensuring fairness and reducing bias in healthcare applications; ML for privacy preservation in healthcare data; Co-creation and human-in-the-loop for ML in healthcare.",
                            "essays": [
                                {
                                    "essay": "Death Prediction by Race in Colorectal Cancer Patients Using Machine Learning Approaches ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Speed-of-Sound Mapping for Pulse-Echo Ultrasound Raw Data using Linked-Autoencoders ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "GastroVision: A Multi-class Endoscopy Image Dataset for Computer Aided Gastrointestinal Disease Detection ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Multimodal Representation Learning of Cardiovascular Magnetic Resonance Imaging ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Multimodal LLMs for health grounded in individual-specific data ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Prompt-based Generative Replay: A Text-to-Image Approach for Continual Learning in Medical Settings ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Can Brain Signals Reveal Inner Alignment with Human Languages? ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "SsFnL: The Most Robust Model by Scenario-specific and Self-supervised Learning in Missing Modality Brain Tumor Segmentation ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Latent Masking for Multimodal Self-supervised Learning in Health Timeseries ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Multi-Modal Biomarker Extraction Framework for Therapy Monitoring of Social Anxiety and Depression Using Audio and Video ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "HOOREX: Higher Order Optimizers for 3D Recovery from X-Ray Images ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "MaxCorrMGNN: A Multi-Graph Neural Framework for Generalized Multimodal Fusion of Medical Data for Outcome Prediction ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Interpretable and Intervenable Ultrasonography-based Machine Learning Models for Pediatric Appendicitis ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Semi-supervised Cooperative Learning for Multiomics Data Fusion ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Exploiting Partial Common Information Microstructure for Multi-Modal Brain Tumor Segmentation ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "SIM-CNN: Self-Supervised Individualized Multimodal Learning for Stress Prediction on Nurses Using Biosignals ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Neural Graph Revealers ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Molecule-Morphology Contrastive Pretraining for Transferable Molecular Representation ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "InterSynth: a semi-synthetic framework for benchmarking prescriptive inference from observational data ",
                                    "form": "Oral"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 313 None",
                            "workshop": "Neural Conversational AI Workshop - What\u2019s left to TEACH (Trustworthy, Enhanced, Adaptable, Capable and Human-centric) chatbots?",
                            "author": [
                                "Hyundong Cho",
                                "Nayeon Lee",
                                "Ninareh Mehrabi",
                                "Hsuan Su",
                                "Ahmad Beirami",
                                "Hung-yi Lee",
                                "Jonathan May"
                            ],
                            "content": "The recent breathtaking progress made in generative natural language processing (NLP) has been propelled by large language models and innovative learning methods that intersects machine learning (ML) and NLP such as Reinforcement Learning with Human Feedback (RLHF), leading to the creation of impressive chatbots like ChatGPT. However their lack of groundedness, factuality, and interoperability with tools and custom APIs limits them to mostly creative endeavors due to low fidelity and reliability. On the contrary, digital assistants in the real world such as Siri, Alexa, and Google Assistant can interface with proprietary APIs, but they still cover a relatively narrow set of use cases that are mostly simple single-turn interactions. Through the combination of each of their strengths, the goal of deploying truly conversational and capable digital assistants that are also trustworthy seems tantalizingly close. What are the remaining challenges for this goal, and how can the ML and NLP communities come together to overcome them? The goal of this workshop is to bring together machine learning researchers and dialogue researchers from academia and industry to encourage knowledge transfer and collaboration on these central questions to discover ideas that can further expand the use cases of conversational AI. The ideal outcome of the workshop is to identify a set of concrete research directions to enable the next generation of digital assistants.",
                            "essays": [
                                {
                                    "essay": " \tLMQL Chat: Scripted Chatbot Development ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Situated Interaction with Real-Time State Conditioning of Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Trust and ethical considerations in a multi-modal, explainable AI-driven chatbot tutoring system: The case of collaboratively solving Rubik\u2019s Cube ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "In-Context Exemplars as Clues to Retrieving \\ from Large Associative Memory ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Robustness through Loss Consistency Regularization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Idiolect: A Reconfigurable Voice Coding Assistant ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "AutoML-GPT: Large Language Model for AutoML ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Teaching Arithmetic to Small Transformers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DiversiGATE: A Comprehensive Framework for Reliable Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "TRAC: Trustworthy Retrieval Augmented Chatbot ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "LLM2Loss: Leveraging Language Models for Explainable Model Diagnostics ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Large Language Models can Share Images, Too! ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Conformal Prediction with Large Language Models for Multi-Choice Question Answering ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Describe, Explain, Plan and Select: Interactive Planning with LLMs Enables Open-World Multi-Task Agents ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Scalable Conversational Moderation: Promoting Constructive Dialogue to Reduce Online Polarization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Can Chatbots \u201cUnderstand\u201d? Evidence of Meaning in Language Models Trained on Programs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Let\u2019s Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Assessing Spoken Language Understanding Pipeline of a Multimodal Dialogue System for Kids Learning Math at Home ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Disclosing the Biases in Large Language Models via Reward Based Questioning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Can Large Language Models Reason Algorithmically in an Interactive Environment? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Not what you've signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "LLM Guided Inductive Inference for Solving Compositional Problems ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 320 None",
                            "workshop": "Duality Principles for Modern Machine Learning",
                            "author": [
                                "Thomas Moellenhoff",
                                "Zelda Mariet",
                                "Mathieu Blondel",
                                "Khan Emtiyaz"
                            ],
                            "content": "Duality is a pervasive and important principle in mathematics. Not only has it fascinated researchers in many different fields but it has also been used extensively in optimization, statistics, and machine-learning (ML), giving rise to powerful tools such as Fenchel duality in convex optimization, representer theorems in kernel methods and Bayesian nonparametrics, and dually-flat spaces in information geometry. Such applications have played an important role in the past, but lately we do not see much work on duality principles, especially in deep learning. For example, Lagrange duality can be useful for model explanation because it allows us to measure sensitivity of certain perturbations, but this is not yet fully exploited. This slowdown is perhaps due to a growing focus on nonconvex and nonlinear problems where duality does not seem to be directly applicable. There have not been any workshops on duality in recent years. With this workshop, we aim to revive the interest of the ML community in duality principles.The goal of the workshop is to bring together researchers working on various duality concepts from many different fields, and discuss new applications for modern machine learning, especially focusing on topics such as model understanding, explanation, and adaptation in deep learning and reinforcement learning. Our organizers, speakers, and panelists have expertise working on such topics and form a diverse group in terms of backgrounds, fields, race, gender, and country. We also have an advisory committee who have been helping us in organization and communication. Overall, we aim to cover a wide-range of topics from both theory and application of duality."
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Ballroom A None",
                            "workshop": "ES-FoMo: Efficient Systems for Foundation Models",
                            "author": [
                                "Julien Launay",
                                "Daniel Y Fu",
                                "Tri Dao",
                                "Daniel Hesslow",
                                "Beidi Chen",
                                "Azalia Mirhoseini",
                                "Percy Liang"
                            ],
                            "content": [
                                "As models increase in size and training budget, they not only systematically improve in upstream quality, but also exhibit novel emergent capabilities. This increase in scale raises proportionate difficulties for practitioners: foundation model training and inference lie at a unique interdisciplinary crossroad, combining open problems in algorithms, system design, and software engineering.",
                                "Machine learning practitioners are key stakeholders here: on the one hand, researchers may contribute algorithmic insights and novel methods to improving training and inference of large models; on the other hand, novel research findings may be best demonstrated at scale—which may require training models as efficiently as possible to make the best use of available resources.",
                                "The goal of this workshop is to bring together interdisciplinary experts working on the emerging research questions and challenges associated with foundation model training and inference. We welcome submissions around training and inference systems/algorithms for foundation models, focusing on scaling-up or on reducing compute, time, memory, bandwidth, and energy requirements. Notably, we encourage submissions concerning the entire spectrum of foundation models: from BERT-sized Transformers, to large models with 100B+ parameters. Topics include but are not limited to:",
                                "* Training and inference systems, either distributed at large scale or in resource-constrained scenarios;",
                                "* Algorithms for improved training and inference efficiency;",
                                "* Systems for foundation models, such as novel programming languages or compilers."
                            ],
                            "essays": [
                                {
                                    "essay": "Cramming: Training a Language Model on a single GPU in one day ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "RapidBERT: How to Train BERT with a Lunch Money Budget ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Constant Memory Attention Block ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On IO-Efficient Attention Mechanisms: Context-Aware Bifurcated Attention and the Generalized Multi-Group Attention ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "GPT-Zip: Deep Compression of Finetuned Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Comprehensive Analysis of Adapter Efficiency ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Can Public Large Language Models Help Private Cross-device Federated Learning? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM Decoding ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Semi-supervised Tabular Classification via In-context Learning of Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "BK-SDM: Architecturally Compressed Stable Diffusion for Efficient Text-to-Image Generation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Generating Efficient Kernels for Quantized Inference on Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Blockwise Parallel Transformer for Long Context Large Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Continual Pre-Training of Large Language Models: How to re-warm your model? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ZipLM: Inference-Aware Structured Pruning of Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "UOTA: Unsupervised Open-Set Task Adaptation Using a Vision-Language Foundation Model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Simple and Effective Pruning Approach for Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fast Causal Attention with Dynamic Sparsity ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Scaling In-Context Demonstrations with Structured Attention ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Sequence Parallelism: Long Sequence Training from System Perspective ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Closer Look at In-Context Learning under Distribution Shifts ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ViT Graph Head Attention for Small Sized Datasets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Three Towers: Flexible Contrastive Learning with Pretrained Image Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Reasoning Ability Emerges in Large Language Models as Aggregation of Reasoning Paths ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Fair Knowledge Distillation using Student Feedback ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ROSA: Random Orthogonal Subspace Adaptation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Deep Fusion: Efficient Network Training via Pre-trained Initializations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Incremental Low-Rank Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Reverse Distillation: Training Billion Parameter Models For CTR Prediction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Training Diffusion Models with Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On Robustness-Accuracy Characterization of Large Language Models using Synthetic Datasets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Language Models are Weak Learners ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Progressive Knowledge Distillation: Balancing Inference Latency and Accuracy at Runtime ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "MRMP: Multi-Rate Magnitude Pruning of Graph Convolutional Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Dissecting Efficient Architectures for Wake-Word Detection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Landmark Attention: Random-Access Infinite Context Length for Transformers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SpecTr: Fast Speculative Decoding via Optimal Transport ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Compositional Interfaces for Compositional Generalization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Incrementally-Computable Neural Networks: Efficient Inference for Dynamic Inputs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "H2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Structured Sparsity in Transformers for Efficient Inference ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Efficient World Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Test-Time Training for Speech ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Accelerating LLM Inference with Staged Speculative Decoding ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Looped Transformers are Better at Learning Learning Algorithms ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Implementing block-sparse matrix multiplication kernels using Triton ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SuperShaper: A Pre-Training Approach for Discovering Efficient Transformer Shapes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Less is More: Using Multiple LLMs for Applications with Lower Costs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SpeedLimit: Neural Architecture Search for Quantized Transformer Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Memory-Efficient Selective Fine-Tuning ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Fine-Tuning Language Models with Just Forward Passes ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Learned Thresholds Token Merging and Pruning for Vision Transformers ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Audio-Journey: Efficient Visual+LLM-aided Audio Encodec Diffusion ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Mental Calibration: Discovering and Adjusting for Latent Factors Improves Zero-Shot Inference of CLIP ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 314 None",
                            "workshop": "ICML 2023 Workshop on Computational Biology",
                            "author": [
                                "Yubin Xie",
                                "Cassandra Burdziak",
                                "Dana Pe'er",
                                "Debora Marks",
                                "Alexander Anderson",
                                "Elham Azizi",
                                "Abdoulaye Baniré Diallo",
                                "Wesley Tansey",
                                "Bianca Dumitrascu",
                                "Sandhya Prabhakaran",
                                "Maria Brbic",
                                "Mafalda Dias",
                                "Cameron Park",
                                "Pascal Notin",
                                "Joy Fan",
                                "Ruben Weizman",
                                "Lingting Shi",
                                "Siyu He",
                                "Yinuo Jin"
                            ],
                            "content": "Each year, machine learning (ML) advances are successfully translated to develop systems we now use regularly, such as speech recognition platforms or translation software. The COVID-19 pandemic has highlighted the urgency for translating these advances to the domain of biomedicine. Biological data has unique properties (high dimensionality, degree of noise and variability), and therefore poses new challenges and opportunities for methods development. To facilitate progress toward long-term therapeutic strategies or basic biological discovery, it is critical to bring together practitioners at the intersection of computation, ML, and biology.The ICML Workshop on Computational Biology (WCB) will highlight how ML approaches can be tailored to making both translational and basic scientific discoveries with biological data, such as genetic sequences, cellular features or protein structures and imaging datasets, among others. This workshop thus aims to bring together interdisciplinary ML researchers working in areas such as computational genomics; neuroscience; metabolomics; proteomics; bioinformatics; cheminformatics; pathology; radiology; evolutionary biology; population genomics; phenomics; ecology, cancer biology; causality; representation learning and disentanglement to present recent advances and open questions to the machine learning community. We especially encourage interdisciplinary submissions that might not neatly fit into one of these categories."
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Ballroom B None",
                            "workshop": "Generative AI and Law (GenLaw)",
                            "author": [
                                "Katherine Lee",
                                "A. Feder Cooper",
                                "FatemehSadat Mireshghallah",
                                "Madiha Zahrah",
                                "James Grimmelmann",
                                "David Mimno",
                                "Deep Ganguli",
                                "Ludwig Schubert"
                            ],
                            "content": [
                                "Progress in generative AI depends not only on better model architectures, but on terabytes of scraped Flickr images, Wikipedia pages, Stack Overflow answers, and websites. But generative models ingest vast quantities of intellectual property (IP), which they can memorize and regurgitate verbatim. Several recently-filed lawsuits relate such memorization to copyright infringement. These lawsuits will lead to policies and legal rulings that define our ability, as ML researchers and practitioners, to acquire training data, and our responsibilities towards data owners and curators. AI researchers will increasingly operate in a legal environment that is keenly interested in their work — an environment that may require future research into model architectures that conform to legal requirements. Understanding the law and contributing to its development will enable us to create safer, better, and practically useful models.",
                                "Our workshop will begin to build a comprehensive and precise synthesis of the legal issues at play. Beyond IP, the workshop will also address privacy and liability for dangerous, discriminatory, or misleading and manipulative outputs. Addressing these challenges requires collaboration between ML researchers and practitioners, data curators, HCI researchers, and legal experts. We will mix tutorial-style presentations from renowned experts in both ML and law with panel discussions where researchers in both disciplines can engage in semi-moderated conversation."
                            ],
                            "essays": [
                                {
                                    "essay": " Ignore the Law: The Legal Risks of Prompt Injection Attacks on Large Language Models; Author(s): Ram Shankar Siva Kumar, Jonathon Penney ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Machine Learning Has A Fixation Problem; Author(s): Katrina Geddes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " From Algorithmic Destruction to Algorithmic Imprint: Generative AI and Privacy Risks Linked to Potential Traces of Personal Data in Trained Models; Author(s): Lydia Belkadi, Catherine Jasserand ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Developing Methods for Identifying and Removing Copyrighted Content from Generative AI Models; Author(s): Krishna Sri Ipsit Mantri, Nevasini NA Sasikumar ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Takeaways from Data Extraction and Unlearning for Law; Author(s): Jaydeep Borkar ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " AI and the EU Digital Markets Act: Addressing the Risks of Bigness and Dominance in Generative AI; Author(s): Andrew Chong, et al. ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " How can we manage the risks and liabilities associated with legal translation in the age of machine translation and generative AI?; Author(s): Argyri Panezi, John O Shea ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Generative AI and the Future of Financial Advice Regulation; Author(s): Talia Gillis, Sarith Felber, Itamar Caspi ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Exploring Antitrust and Platform Power in Generative AI; Author(s): Konrad Kollnig, Qian Li ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " PoT: Securely Proving Legitimacy of Training Data and Logic for AI Regulation; Author(s): Hongyang Zhang, Haochen Sun ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " When Synthetic Data Met Regulation; Author(s): Georgi Ganev ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Provably Confidential Language Modelling Author(s): Xuandong Zhao, Lei Li, Yu-Xiang Wang ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " The Extractive-Abstractive Axis: Measuring Content \u2019Borrowing\u2019 in Generative Language Models; Author(s): Nedelina Teneva ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Anticipating and Mitigating Unsafe and Harmful Outcomes with Generative Language Models: The Role and Limits of Laws; Author(s): Inyoung Cheong, Aylin Caliskan, Tadayoshi Kohno ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Reclaiming the Digital Commons: A Public Data Trust for Training Data; Author(s): Alan Chan, Herbie Bradley, Nitarshan Rajkumar ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Chain Of Reference prompting helps LLM to think like a lawyer Author(s): Nikon Rasumov-Rahe, Aditya Kuppa, Marc Voses ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Compute and Antitrust: Regulatory implications of the AI hardware supply chain, from chip design to foundation model APIs; Author(s): Haydn Belfield, Shin-Shin Hua ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Consent-to-train Metadata for a Machine Learning World; Author(s): Daphne E Ippolito, Yun William Yu ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " When is Copying Fair? Exploring the Copyright Implications of Andy Warhol Foundation v. Goldsmith for Generative AI; Author(s): Tiffany Georgievski ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Licensing Training Data and Attributing Copyright of Derivative Content From Large Language Models Can Resolve Up- and Downstream Copyright Issues; Author(s): Brian L Zhou, Lakshmi Sritan R Motati ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " The Limited Relevance of Fair Use: Legal Implications of Training LLMs on Copyrighted Text; Author(s): Noorjahan Rahman ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Applying Torts to Juridical Persons: Corporate and AI Governance; Author(s): Aaron Tucker ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Differential Privacy vs Detecting Copyright Infringement: A Case Study Using Normalizing Flows; Author(s): Saba Amiri, Eric Nalisnick, Adam Belloum, Sander Klous, Leon Gommans ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Gradient Surgery for One-shot Unlearning on Generative Model; Author(s): Seohui Bae, Seoyoon Kim, Hyemin Jung, Woohyung Lim ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " Protecting Visual Artists from Generative AI: A Multidisciplinary Perspective; Author(s): Eunseo Choi ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": " The Restatement (Artificial) of Torts; Author(s): Colin Doyle ",
                                    "form": "Poster:Spotlight"
                                },
                                {
                                    "essay": " The Data Provenance Initiative; Author(s): Shayne Longpre, et al.",
                                    "form": "Poster:Spotlight"
                                },
                                {
                                    "essay": " Break It Till You Make It: Limitations of Copyright Liability Under a Pre-training Paradigm of AI Development; Author(s): Rui-Jie Yew, Dylan Hadfield-Menell",
                                    "form": "Poster:Spotlight"
                                },
                                {
                                    "essay": " Diffusion Art or Digital Forgery? Investigating Data Replication in Stable Diffusion; Author(s): Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas A. Geiping, Tom Goldstein",
                                    "form": "Poster:Spotlight"
                                },
                                {
                                    "essay": " Measuring the Success of Diffusion Models at Imitating Human Artists; Author(s): Stephen Casper, et al.",
                                    "form": "Poster:Spotlight"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 310 None",
                            "workshop": "Localized Learning: Decentralized Model Updates via Non-Global Objectives",
                            "author": [
                                "David I. Inouye",
                                "Mengye Ren",
                                "Mateusz Malinowski",
                                "Michael Eickenberg",
                                "Gao Huang",
                                "Eugene Belilovsky"
                            ],
                            "content": "Despite being widely used, global end-to-end learning has several key limitations. It requires centralized computation, making it feasible only on a single device or a carefully synchronized cluster. This restricts its use on unreliable or resource-constrained devices, such as commodity hardware clusters or edge computing networks. As the model size increases, synchronized training across devices will impact all types of parallelism. Global learning also requires a large memory footprint, which is costly and limits the learning capability of single devices. Moreover, end-to-end learning updates have high latency, which may prevent their use in real-time applications such as learning on streaming video. Finally, global backpropagation is thought to be biologically implausible, as biological synapses update in a local and asynchronous manner. To overcome these limitations, this workshop will delve into the fundamentals of localized learning, which is broadly defined as any training method that updates model parts through non-global objectives.",
                            "events": [
                                {
                                    "event": "Opening Remarks"
                                },
                                {
                                    "event": "Geoffrey Hinton ",
                                    "form": "Keynote"
                                },
                                {
                                    "event": "Timoleon Moraitis ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "Morning Poster Session ",
                                    "form": "Poster Session"
                                },
                                {
                                    "event": "Claudia Clopath ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "Edouard Oyallon ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "Dual Propagation: Accelerating Contrastive Hebbian Learning with Dyadic Neurons ",
                                    "form": "Best Contributed Paper"
                                },
                                {
                                    "event": "Lunch Break and Informal Poster Session ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Irina Rish ",
                                    "form": "Keynote"
                                },
                                {
                                    "event": "Qu Yang ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "Stephen Guo: Lessons of Local Learning in Training LLMs ",
                                    "form": "Invited Talk"
                                },
                                {
                                    "event": "Understanding Predictive Coding as an Adaptive Trust-Region Method ",
                                    "form": "Best Contributed Paper"
                                },
                                {
                                    "event": "Short Break and Informal Poster Session ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Panel - Localized Learning: Past, Present and Future ",
                                    "form": "Discussion Panel"
                                },
                                {
                                    "event": "Afternoon Poster Session ",
                                    "form": "Poster Session"
                                }
                            ],
                            "essays": [
                                {
                                    "essay": "Internet Learning: Preliminary Steps Towards Highly Fault-Tolerant Learning on Device Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Simplifying Distributed Neural Network Training on Massive Graphs: Randomized Partitions Improve Model Aggregation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Dual Propagation: Accelerating Contrastive Hebbian Learning with Dyadic Neurons ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Recurrent Models with Temporally Local Rules ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Co-Dream: Collaborative data synthesis with decentralized models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Lightweight Learner for Shared Knowledge Lifelong Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Dataset Pruning Using Early Exit Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Understanding Predictive Coding as an Adaptive Trust-Region Method ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Decentralized Plasticity in Reservoir Dynamical Networks for Pervasive Environments ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Localizing Partial Model for Personalized Federated Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Auto-Aligning Multiagent Incentives with Global Objectives ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Breaking the Curse of Multiagents in a Large State Space: RL in Markov Games with Independent Linear Function Approximation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Local Inconsistency Resolution Algorithm ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "MOLE: MOdular Learning FramEwork via Mutual Information Maximization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Modular Machine Learning Pipelines ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Metric Compatible Training for Online Backfilling in Large-Scale Retrieval ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Preventing Dimensional Collapse in Contrastive Local Learning with Subsampling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Beyond weight plasticity: Local learning with propagation delays in spiking neural networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Energy-Based Learning Algorithms: A Comparative Study ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Associative memory and deep learning with Hebbian synaptic and structural plasticity ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Gradient Scaling on Deep Spiking Neural Networks with Spike-Dependent Local Information ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 317 B None",
                            "workshop": "2nd ICML Workshop on Machine Learning for Astrophysics",
                            "author": [
                                "Francois Lanusse",
                                "Marc Huertas-Company",
                                "Brice Menard",
                                "Laurence Perreault-Levasseur",
                                "J. Xavier Prochaska",
                                "Uros Seljak",
                                "Francisco Villaescusa-Navarro",
                                "Ashley Villar"
                            ],
                            "content": "As modern astrophysical surveys deliver an unprecedented amount of data, from the imaging of hundreds of millions of distant galaxies to the mapping of cosmic radiation fields at ultra-high resolution, conventional data analysis methods are reaching their limits in both computational complexity and optimality. Deep Learning has rapidly been adopted by the astronomical community as a promising way of exploiting these forthcoming big-data datasets and of extracting the physical principles that underlie these complex observations. This has led to an unprecedented exponential growth of publications combining Machine Learning and astrophysics. Yet, many of these works remain at an exploratory level and have not been translated into real scientific breakthroughs.Following a successful initial iteration of this workshop at ICML 2022, our continued goal for this workshop series is to bring together Machine Learning researchers and domain experts in the field of Astrophysics to discuss the key open issues which hamper the use of Deep Learning for scientific discovery.",
                            "essays": [
                                {
                                    "essay": "PPDONet: Deep Operator Networks for Fast Prediction of Steady-State Solutions in Disk-Planet Systems ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A cross-modal contrastive learning method for estimating photometric redshift of quasars ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Comparative Study on Generative Models for High Resolution Solar Observation Imaging ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Shared Stochastic Gaussian process Decoders: A Probabilistic Generative model for Quasar Spectra ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Flow Matching for Scalable Simulation-Based Inference ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Field-Level Inference with Microcanonical Langevin Monte Carlo ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Diffusion generative modeling for galaxy surveys: emulating clustering for inference at the field level ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Disentangling gamma-ray observations of the Galactic Center using differentiable probabilistic programming ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Spotting Hallucinations in Inverse Problems with Data-Driven Priors ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Learning the galaxy-environment connection with graph neural networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Multi-fidelity Emulator for Cosmological Large Scale 21 cm Lightcone Images: a Few-shot Transfer Learning Approach with GAN ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Cosmology with Galaxy Photometry Alone ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neural Astrophysical Wind Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Assessing Summary Statistics with Mutual Information for Cosmological Inference ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bayesian Uncertainty Quantification in High-dimensional Stellar Magnetic Field Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "3D ScatterNet: Inference from 21~cm Light-cones ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Weisfeiler-Lehman Graph Kernel Method: A New Approach to Weak Chemical Tagging ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Population-Level Inference for Galaxy Properties from Broadband Photometry ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Diffusion Models for Probabilistic Deconvolution of Galaxy Images ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Closing the stellar labels gap: An unsupervised, generative model for Gaia BP/RP spectra ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SimBIG: Field-level Simulation-based Inference of Large-scale Structure ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Domain Adaptation via Minimax Entropy for Real/Bogus Classification of Astronomical Alerts ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SimBIG: Galaxy Clustering beyond the Power Spectrum ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Multi-input Convolutional Neural Network to Automate and Expedite Bright Transient Identification for the Zwicky Transient Facility ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Novel Application of Conditional Normalizing Flows: Stellar Age Inference with Gyrochronology ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Toward a Spectral Foundation Model: An Attention-Based Approach with Domain-Inspired Fine-Tuning and Wavelength Parameterization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Multiscale Flow for Robust and Optimal Cosmological Analysis ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Unbiased Gravitational-Wave Parameter Estimation using Score-Based Likelihood Characterization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "nbi: the Astronomer's Package for Neural Posterior Estimation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Real-Time Stellar Spectra Fitting with Amortized Neural Posterior Estimation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Time Delay Cosmography with a Neural Ratio Estimator ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "FLORAH: A generative model for halo assembly histories ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Hierarchy of Normalizing Flows for Modelling the Galaxy-Halo Relationship ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Using Multiple Vector Channels Improves E(n)-Equivariant Graph Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Positional Encodings for Light Curve Transformers: Playing with Positions and Attention ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Cosmological Data Compression and Inference with Self-Supervised Machine Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Detecting Tidal Features using Self-Supervised Learning ",
                                    "form": "Oral"
                                },
                                {
                                    "essay": "Graph Representation of the Magnetic Field Topology in High-Fidelity Plasma Simulations for Machine Learning Applications ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 317 A None",
                            "workshop": "Neural Compression: From Information Theory to Applications",
                            "author": [
                                "Berivan Isik",
                                "Yibo Yang",
                                "Daniel Severo",
                                "Karen Ullrich",
                                "Robert Bamler",
                                "Stephan Mandt"
                            ],
                            "content": "This workshop aims to address fundamental problems in the young but potentially highly impactful field of machine-learning-based data compression. In contrast to other workshops, which focus on practical compression performance on a rate/distortion trade-off, our goal is to encourage idea exchange on more fundamental issues in neural compression such as the role of quantization and stochasticity in compression algorithms, guaranteed distortion bounds, and more compute-efficient models. We aim to address these fundamental issues by bringing together researchers from diverse fields including deep generative modeling, information theory, and inference. We have confirmed expert speakers and panelists from each of these backgrounds.",
                            "essays": [
                                {
                                    "essay": "Less-Energy-Usage Network with Batch Power Iteration ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "MLIC++: Linear Complexity Multi-Reference Entropy Modeling for Learned Image Compression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Making Text-Image Connection Formal and Practical ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ICE-Pick: Iterative Cost-Efficient Pruning for DNNs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neural Image Compression with Quantization Rectifier ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learn From One Specialized Sub-Teacher: One-to-One Mapping for Feature-Based Knowledge Distillation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Diagnostically Lossless Compression of Medical Images ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Revisiting Associative Compression: I Can't Believe It's Not Better ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Are Visual Recognition Models Robust to Image Compression? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neural Distributed Compressor Does Binning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Maximum Mutual Information Capacity of Neural Architectures ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Lightweighted Sparse Autoencoder based on Explanable Contribution ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fast Autoregressive Bit Sequence Modeling for Lossless Compression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neural Network Optimization with Weight Evolution ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Autoencoding Implicit Neural Representations for Image Compression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Entropy Coding of Unordered Data Structures ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Neural Image Compression: Generalization, Robustness, and Spectral Biases ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Designing Discontinuities ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Choice of Perception Loss Function for Learned Video Compression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Text + Sketch: Image Compression at Ultra Low Rates ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Task-aware Distributed Source Coding under Dynamic Bandwidth ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Slicing Mutual Information Generalization Bounds for Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Minimal Random Code Learning with Mean-KL Parameterization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Practical Random Tree Generation using Spanning Trees: Entropy and Compression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "NNCodec: An Open Source Software Implementation of the Neural Network Coding ISO/IEC Standard ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Estimating the Rate-Distortion Function by Wasserstein Gradient Descent ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "FusionToken: Enhancing Compression and Efficiency in Language Model Tokenization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Lossy Image Compression with Conditional Diffusion Model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Low Complexity Neural Network-Based In-loop Filtering with Decomposed Split Luma-Chroma Model for Video Compression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Transformers are Universal Predictors ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Why Quantization Improves Generalization: NTK of Binary Weight Neural Network ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "EntropyRank: Unsupervised Keyphrase Extraction via Side-Information Optimization for Language Model-based Text Compression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Reconstruction Distortion of Learned Image Compression with Imperceptible Perturbations ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Siamese SIREN: Audio Compression with Implicit Neural Representations ",
                                    "form": "Poster"
                                }
                            ]
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Meeting Room 312 None",
                            "workshop": "Sampling and Optimization in Discrete Space",
                            "author": [
                                "Haoran Sun",
                                "Hanjun Dai",
                                "Priyank Jaini",
                                "Ruqi Zhang",
                                "Ellen Vitercik"
                            ],
                            "content": "There have recently been new research trends in efficient discrete sampling and optimization. We are organizing this workshop with the goals of 1) syncing up on the latest research progress in discrete sampling and optimization, 2) discussing the limitations of current methods and brainstorming new algorithm paradigms, and 3) connecting to applications in domains such as language/protein modeling, physics simulation, and bio/chemical engineering---where improved techniques for sampling/optimization in discrete space could help---and exploring the gaps between the application's needs and the capabilities of existing methods. We hope this workshop will be an excellent opportunity for presenting and discussing new algorithms and applications with researchers and practitioners within or outside the domain of discrete sampling/optimization."
                        },
                        {
                            "time": "Sun Jul 30 03:00 AM -- 11:00 AM (CST)",
                            "location": " Ballroom C None",
                            "workshop": "DMLR Workshop: Data-centric Machine Learning Research",
                            "author": [
                                "Ce Zhang",
                                "Praveen Paritosh",
                                "Newsha Ardalani",
                                "Nezihe Merve G\u00fcrel",
                                "William Gaviria Rojas",
                                "Yang Liu",
                                "Rotem Dror",
                                "Manil Maskey",
                                "Lilith Bat-Leah",
                                "Tzu-Sheng Kuo",
                                "Luis Oala",
                                "Max Bartolo",
                                "Ludwig Schmidt",
                                "Alicia Parrish",
                                "Daniel Kondermann",
                                "Najoung Kim"
                            ],
                            "content": "This is the third edition of highly successful workshops focused on data-centric AI, following the success of the Data-Centric AI workshop at NeurIPS 2021 and DataPerf workshop at ICML 2022. Data, and operations over data (e.g., cleaning, debugging, curation) have been continually fueling the success of machine learning for decades. While historically the ML community has focused primarily on model development, recently the importance of data quality has attracted intensive interest from the community, including the creation of the NeurIPS dataset and benchmark track, several data-centric AI benchmarks (e.g., DataPerf), and the flourishing of data consortiums such as LAION, the community’s attention has been directed to the quality of data used for ML training and evaluation. The goal of this workshop is to facilitate these important topics in what we call Data-centric Machine Learning Research, which includes not only datasets and benchmarks, but tooling and governance, as well as fundamental research on topics such as data quality and data acquisition for dataset creation and optimization.",
                            "events": [
                                {
                                    "event": "Introduction and Opening ",
                                    "form": "Opening Remarks"
                                },
                                {
                                    "event": "Keynote 1: Andrew Ng (Landing AI) ",
                                    "form": "Keynote"
                                },
                                {
                                    "event": "DataPerf Challenge - Peter Mattson (Google & MLCommons) ",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Coffee break / networking break ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Keynote 2: Mihaela van der Schaar (University of Cambridge) - Data quality ",
                                    "form": "Keynote"
                                },
                                {
                                    "event": "Invited Talk 2: Olga Russakovsky (Princeton University) ",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Invited Talk 3: Masashi Sugiyama (RIKEN & UTokyo) - Data distribution shift ",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Lunch Break / networking break ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Keynote 3: Isabelle Guyon (Google Brain) - Data creation ",
                                    "form": "Keynote"
                                },
                                {
                                    "event": "Invited Talk 1: Dina Machuve (DevData Analytics) - Data for Agriculture ",
                                    "form": "Talk"
                                },
                                {
                                    "event": "Announcement and open discussion on DMLR (Selected members of DMLR Advisory Board) ",
                                    "form": "Discussion Panel"
                                },
                                {
                                    "event": "Panel Discussion ",
                                    "form": "Discussion Panel"
                                },
                                {
                                    "event": "Coffee break / networking break ",
                                    "form": "Break"
                                },
                                {
                                    "event": "Poster Session 1 ",
                                    "form": "Poster Session - In Person"
                                },
                                {
                                    "event": "Poster Session 2 (Virtual) ",
                                    "form": "Poster Session - Virtual"
                                }
                            ],
                            "essays": [
                                {
                                    "essay": "Algorithm Selection for Deep Active Learning with Imbalanced Datasets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Inter-Annotator Agreement in the Wild: Uncovering Its Emerging Roles and Considerations in Real-World Scenarios ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Accelerating Batch Active Learning Using Continual Learning Techniques ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Adaptive Aggregated Drift Detector ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Decoupled Graph Label Denoising for Robust Semi-Supervised Node Classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On Estimating the Epistemic Uncertainty of Graph Neural Networks using Stochastic Centering ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Toward Practical Automatic Speech Recognition and Post-Processing: a Call for Explainable Error Benchmark Guideline ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Synthetic Alone: Exploring the Dark Side of Synthetic Data for Grammatical Error Correction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "How to Cope with Gradual Data Drift? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DMOps: Data Management Operations and Recipes ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Knowledge Graph-Augmented Korean Generative Commonsense Reasoning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Transcending Traditional Boundaries: Leveraging Inter-Annotator Agreement (IAA) for Enhancing Data Management Operations (DMOps) ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Do Machine Learning Models Learn Statistical Rules Inferred from Data? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Can Expert Demonstration Guarantee Offline Performance in Sparse Reward Environment? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Fair Machine Unlearning: Data Removal while Mitigating Disparities ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data Integration for Driver Telematics with Selection Biases ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Making Scalable Meta Learning Practical ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Regularizing Neural Networks with Meta-Learning Generative Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning pipeline-invariant representation for robust brain phenotype prediction ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Does Progress On Object Recognition Benchmarks Improve Real-World Generalization? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit for Purpose? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Training with Low-Label-Quality Data: Rank Pruning and Multi-Review ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "THOS: A Benchmark Dataset for Targeted Hate and Offensive Speech ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Skew-Sensitive Evaluation Framework for Imbalanced Data Classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Prediction without Preclusion Recourse Verification with Reachable Sets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Participatory Personalization in Classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "To Aggregate or Not? Learning with Separate Noisy Labels ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Unitail: A Benchmark for Detecting, Reading, and Matching in Retail Scene ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Enhancing Time Series Forecasting Models under Concept Drift by Data-centric Online Ensembling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards an Efficient Algorithm for Time Series Forecasting with Anomalies ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Performance Scaling via Optimal Transport: Enabling Data Selection from Partially Revealed Sources ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data Banzhaf: A Robust Data Valuation Framework for Machine Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data-Driven Approach for Formality-Sensitive Machine Translation: Language-Specific Handling and Synthetic Data Generation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Repeated Random Sampling for Minimizing the Time-to-Accuracy of Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Improving multimodal datasets with image captioning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Learning Better with Less: Effective Augmentation for Sample-Efficient Visual Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Training on Thin Air: Improve Image Classification with Generated Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Early Experiments in Scalable Dataset Selection for Self-Supervised Learning in Geospatial Imagery Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data Similarity is Not Enough to Explain Language Model Performance ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Programmable Synthetic Tabular Data Generation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Detecting Errors in Numerical Data via any Regression Model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Understanding Unfairness via Training Concept Influence ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Promises and Pitfalls of Threshold-based Auto-labeling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Prioritized Trajectory Replay: A Replay Memory for Data-driven Reinforcement Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Probing Heterogeneous Pretraining Datasets with Small Curated Datasets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Evaluating the Capabilities of Multi-modal Reasoning Models with Synthetic Task Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Addressing Discrepancies in Semantic and Visual Alignment in Neural Networks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Predicting Article Time Periods with Text2Time: A Transformer-based Approach ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Partial Label Learning meets Active Learning: Enhancing Annotation Efficiency through Binary Questioning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "No Imputation without Representation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Point Cloud Classification with ModelNet40: What is left? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Why Do Self-Supervised Models Transfer? On Data Augmentation and Feature Properties ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Mobile Internet Quality Estimation using Self-Tuning Kernel Regression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Estimating label quality and errors in semantic segmentation data via any model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "ObjectLab: Automated Diagnosis of Mislabeled Images in Object Detection Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "SemDeDup: Data-efficient learning at web-scale through semantic deduplication ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Self-supervised Autoencoder for Correlation-Preserving in Tabular GANs ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Put on your detective hat: What's wrong in this video? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Usefulness of Synthetic Tabular Data Generation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Taming Small-sample Bias in Low-budget Active Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "CD-GraB: Coordinating Distributed Example Orders for Provably Accelerated Training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "How to Improve Imitation Learning Performance with Sub-optimal Supplementary Data? ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "EPIC: Graph Augmentation with Edit Path Interpolation via Learnable Cost ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset and Transformer Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Bayesian Optimisation Against Climate Change: Applications and Benchmarks ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Trade-off of Intra-/Inter-class Diversity for Supervised Pre-training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "PhysicsCAP: Natural Scene Understanding By Semantic Segmentation, CLIP And Physical Models Through Refined and Enriched Captions ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "MultiLegalPile: A 689GB Multilingual Legal Corpus ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On Robustness-Accuracy Characterization of Large Language Models using Synthetic Datasets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "DataCI: A Platform for Data-Centric AI on Streaming Data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "In or Out? Fixing ImageNet Out-of-Distribution Detection Evaluation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "TMARS: Improving Visual Representations by Circumventing Text Feature Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On Memorization and Privacy risks of Sharpness Aware Minimization ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Identifying Implicit Social Biases in Vision-Language Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Detecting Dataset Drift and Non-IID Sampling via k-Nearest Neighbors ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Dataset Interfaces: Diagnosing Model Failures Using Controllable Counterfactual Generation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "A Privacy-Friendly Approach to Data Valuation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Characterizing Risk Regimes for Safe Deployment of Deep Regression Models ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Improve Model Inference Cost with Image Gridding ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Speech Wikimedia: A 77 Language Multilingual Speech Dataset ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data-Efficient Contrastive Self-supervised Learning: Most Beneficial Examples for Supervised Learning Contribute the Least ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Characterizing the Impacts of Semi-supervised Learning for Weak Supervision ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Birds of an Odd Feather: Guaranteed Out-of-Distribution (OOD) Novel Category Detection ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Internet Explorer: Targeted Representation Learning on the Open Web ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Uncovering Neural Scaling Law in Molecular Representation Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "D4: Document Deduplication and Diversification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Offline Reinforcement Learning with Imbalanced Datasets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Ensemble Fractional Imputation for Incomplete Categorical Data with a Graphical Model ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Investigating minimizing the training set fill distance in machine learning regression ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Localized Data Work as a Precondition for Data-Centric ML: A Case Study of Full Lifecycle Crop Disease Identification in Ghana ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Suboptimal Data Can Bottleneck Scaling ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "The Matrix Reloaded: A Counterfactual Perspective on Bias in Machine Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On Data Quality and Speed of Training: Bad Data Slows Training ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Towards Declarative Systems for Data-Centric Machine Learning ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Data-Centric Defense: Shaping Loss Landscape with Augmentations to Counter Model Inversion ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Contrastive clustering of tabular data ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "STG-MTL: Scalable Task Grouping for Multi-Task Learning Using Data Maps ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Active learning for time instant classification ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Graphtester: Exploring Theoretical Boundaries of GNNs on Graph Datasets ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "On the Reproducibility of Data Valuation under Learning Stochasticity ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Principlism Guided Responsible Data Curation ",
                                    "form": "Poster"
                                },
                                {
                                    "essay": "Is Pre-training Truly Better Than Meta-Learning? ",
                                    "form": "Poster"
                                }
                            ]
                        }

                    ]
                },
                "title": "ICML 2023 Call for Post-Conference Workshops",
                "date": "Friday, July 28, and Saturday, July 29",
                "location": "Hawaii, USA",
                "introduction": [
                    "ICML workshops will be held on Friday, July 28th, and Saturday, July 29th, following the ICML main conference. Similar to the main conference, workshops will take place in-person with virtual elements. We invite researchers interested in chairing one of these workshops to submit proposals. Workshop organizers have several responsibilities, including coordinating workshop participation and content, publicizing and providing the program in a timely manner, and moderating the program throughout the workshop.",
                    "ICML also solicits proposals for affinity workshops. The format and aims of these workshops should be described by the workshop organizers, following, for instance, the template set out by similar workshops that took place at ICML and NeurIPS in recent years (Black in AI, Indigenous in AI, LatinX in AI, Muslims in ML, New in ML, Queer in AI, WiML, etc.). Affinity workshops will primarily be held on Monday, July 24th, although there will be limited availability for affinity workshops on Friday, July 28th, and Saturday, July 29th, and may last for a full or a half day. Proposals should follow a similar format as regular workshop proposals and be submitted, together with regular workshops, through CMT following the submission instructions below. The D&I Chairs will make decisions on acceptance for affinity workshops. If you have any questions, please reach out to diversity-chairs@icml.cc."
                ],
                "Workshops": {
                    "introductions": [
                        "The goal of the workshops is to provide an informal forum for researchers to discuss emerging research questions and challenges. Workshops will last for one day, with morning and afternoon sessions and free time between the sessions for individual exchange. To encourage workshop variety, all workshops will be one-day workshops.",
                        "The workshops can be on any subject relevant to a significant fraction of the ICML community. Schedules may encourage lively debates, and topics should lean more towards exploring new ideas, open problems, and interdisciplinary areas compared to the main conference. Workshops should encourage contributed content and reserve a significant portion of time for open/panel discussions and posters. A diverse group of speakers is more likely to bring diverse and surprising viewpoints on a topic. As a result, we encourage workshop organizers to be cognizant of designing panels and speaker lists that are inclusive."
                    ]
                },
                "the criteria by which workshop submissions will be evaluated:": [
                    "Fit for ICML (how the theme of the workshop connects to ICML papers and past workshops)",
                    "Potential impact (promising topic)",
                    "Novelty and originality (emerging topic)",
                    "Quality of the abstract and clarity of purpose",
                    "Organizers' relevant expertise (please avoid excessive self-promotion)",
                    "Diversity in the organizing team and speakers",
                    "Confirmed invited speakers with sufficient coverage of the topic",
                    "Room for contributed work (e.g., posters and contributed talks)",
                    "Room for discussion: degree to which the proposed program offers opportunity for discussion",
                    "Degree to which the organizers provide means to engage in the workshop for those unable to attend in person"
                ],
                "Submission Instructions": {
                    "introduction": "Workshop submissions will be made through CMT. Please follow the URL below and check the required format for the application well before the proposal deadline. You may submit and update your application online right up until this deadline.",
                    "Important dates for workshop submissions:": {
                        "Workshop submissions open": "February 1, 2023",
                        "Workshop application deadline": "February 16, 2023, AOE.",
                        "Workshop notification": "March 16, 2023",
                        "Universal notification deadline for all ICML workshop submissions": "June 19, 2023."
                    },
                    "Proposals should be submitted electronically at the following URL": "https://cmt3.research.microsoft.com/ICMLWorkshops2023",
                    "matter need attention": "Please use the same email address that you use for ICML.cc."
                },
                "Submission format": {
                    "introduction": "Proposals should be two pages long, in single-column A4 or letter format, with font size 11 or greater, excluding organizer contact details/CVs and bibliographic references.",
                    "Proposals should clearly specify the following:": [
                        "Workshop title",
                        "Brief description of the topics to be covered, and an explanation as to why the workshop will appeal to ICML audiences",
                        "Short description and rough timetable of all planned activities (talks, posters, panels), detailing planned in-person and virtual elements",
                        "List of invited speakers, specifying who has been confirmed",
                        "Description of the history of the workshop (if it previously took place, then when/where)",
                        "Similar past and current events at ICML and NeurIPS in the last 1-2 years, even if not organized by the present workshop organizers: New workshops are welcome to build on prior workshops if a good case is made; completely original workshops are also welcome",
                        "List of organizers with email addresses, web page URLs, pointers to Google Scholar or other similar citation service pages, a one-paragraph bio for each organizer, describing research expertise, and previous experience organizing scientific meetings. Unless explicitly indicated, we will assume all organizers are intending to participate in person.",
                        "Names of two organizers designated as contacts for all communications"
                    ],
                    "matter need attention:": [
                        "To facilitate the participation of people unable to travel, workshop contents should be available online, as well. Workshop organizers are asked to manage the virtual elements (e.g., hosting and recording presentations and papers, streaming, and virtual poster sessions). The ICML organizers will assist with central support as needed.",
                        "ICML does not provide travel funding for workshop speakers; in the past, some workshops have sought and received funding from external sources to bring in outside speakers. The organizers of each accepted workshop will be given five complimentary full confernce registrations to distribute among workshop organizers and/or participants. In the event that the conference is sold out, each workshop will be given a number of guaranteed registrations for workshop contributors, so please let us know in your application how many such registrations you anticipate you will need."
                    ],
                    "FAQ": {
                        "Can we host a fully virtual workshop? ": "No, fully virtual workshops will not be supported this year; all workshops must have at least some in-person activities.",
                        "Do organizers need to attend the workshop in-person?": "At least one organizer must attend the workshop in-person.",
                        "Can workshop speakers give virtual talks?": "Workshop organizers can allow for speakers to present virtually. ICML can provide each workshop with a Zoom licenses but the organizers will need to need to coordinate with the remote speaker. Virtual speakers should also commit to engaging with other presenters and participants of the workshop throughout the day of the workshop, and organizers should provide a means for interaction between the physical and virtual components of the workshop.",
                        "Will there be technical support to help with the workshop?": "We will be providing SlidesLive support for livestreaming and recording in-person components of the workshops this year. There will be no SlidesLive support for prerecording videos. We instead suggest using zoom to prerecord and present remote talks, and will offer a limited number of zoom licenses to help support this."
                    },
                    "Workshop review committee": [
                        "Vineeth Balasubramanian",
                        "Beidi Chen",
                        "Lydia Chen",
                        "Alexandra Chouldechova",
                        "Florence d'Alche-Buc",
                        "Emily Denton",
                        "Bo Han",
                        "Daniel Hsu",
                        "Ata Kaban",
                        "Gautam Kamath",
                        "Kristian Kersting",
                        "Emtiyaz Khan",
                        "Ramya Korlakai Vinayak",
                        "Hsuan-Tien Lin",
                        "Aditya Menon",
                        "Rocio Mercado",
                        "Nina Miolane",
                        "Sara Mostafavi",
                        "Krikamol Muandet",
                        "Mijung Park",
                        "Andrej Risteski",
                        "Benjamin Rubinstein",
                        "Dino Sejdinovic",
                        "Thomas Steinke",
                        "Danica Sutherland",
                        "Taiji Suzuki",
                        "Matus Telgarsky",
                        "Eunho Yang",
                        "Fanny Yang",
                        "Lina Yao",
                        "Xinhua Zhang"
                    ],
                    "ICML 2023 Workshop Chairs": {
                        "chairs": [
                            {
                                "name": "Po-Ling Loh",
                                "affiliation": "University of Cambridge"
                            },
                            {
                                "name": "Virginia Smith",
                                "affiliation": "Carnegie Mellon University"
                            },
                            {
                                "name": "Cheng Soon Ong",
                                "affiliation": "CSIRO and Australian National University"
                            }
                        ],
                        "e-mail": "workshop-chairs@icml.cc"
                    }
                }
            },
            "Call For Socials": {
                "title": "Call for Socials and Mentoring sessions",
                "conference": "ICML 2023",
                "date": "25  July (Tue) to 27 July (Thu), 2023",
                "location": "Honolulu, Hawaii (in-person).",
                "introduction": [
                    "A strong community is central to the success of ICML. Our mission is to create an opportunity for all participants to meet new people and to share knowledge, valuable experiences, best practices, career options, and diverse less research-related interests. To enable this, we will support socials and mentoring sessions.",
                    "Similar as in 2022, ICML 2023 is going to be organized in person this year as well, with some virtual elements.  The goal of ICML socials is to help the attendees connect and communicate with each other about research. Neither socials nor mentoring sessions should be used to promote any person and/or company. Companies interested in promoting their visibility  at the conference are welcome to apply to be a sponsor and use resources available for sponsors."
                ],
                "Socials": {
                    "introduction": "A social is a participant-led meeting centered around diverse themes.",
                    "themes range(but not limited)": [
                        "Research topics and interests (e.g., generative models, reinforcement learning, social impact ML)",
                        "Skills exchange and training (e.g., giving better presentations, guidance on academic job applications)",
                        "Supporting affinity group meetings (e.g., QueerInAI, Women in Machine Learning)",
                        "Other less research-oriented, social, and intellectual gatherings (e.g., ICML book club, wine and cheese, quiz night)"
                    ]
                },
                "sponsors": "https://icml.cc/Sponsors/sponsorinfo",
                "matters need attention": [
                    "Socials are typically about 2-hour long, and must have two leads (who will organize the session, moderate the session, and ensure respectful communication). The leads need to commit to attend the conference in person.",
                    "Socials happen in person at the conference venue. Next to contributed socials, we are planning to organize a virtual meetup for remote participants. "
                ],
                "Mentoring sessions": [
                    "A mentoring session is a meeting where a senior member of the community (academic or industry) offers their time to give scientific and career advice, and answer questions from more junior members and newcomers. These mentoring sessions will help the ICML community in its goal of increasing inclusivity.",
                    "We will also support ad-hoc, last-minute mentoring sessions during the conference. We will use the Mementor system (https://mementor.net/) to register Mentor sessions."
                ],
                "Submission": {
                    "introductions": [
                        "If you are interested in hosting a social, please complete this form for socials,volunteering your time for a mentoring session, please register here and schedule a mentoring session there during ICML 2023 - 25 July to 29 July, 2023 (in the form there please choose ICML2023 in associated with which event?)",
                        "Organizers and guests should be registered participants of ICML.",
                        "Submit forms for socials and physical mentoring sessions before 11 June 2023 (anywhere on Earth). Virtual mentoring sessions can be scheduled at any time.",
                        "We will review these as quickly as we can after the deadline. We may combine activities, or suggest other modifications (such as suggesting alternative dates/times) in order to balance the program of activities.",
                        "Code of conduct: Being part of ICML 2023, social events and mentoring sessions are subject to the general code of conduct of the conference."
                    ],
                    "form for socials": [
                        "ICML 2023 Socials ",
                        "ICML 2023 In-Person Socials",
                        "The proposal will take approximately 5 minutes to complete.",
                        "A strong community is central to the success of ICML. Our mission is to create an opportunity for all participants to meet new people and to share knowledge, valuable experiences, best practices, career options, and diverse less research-related interests. To enable this, we will support many socials and mentoring sessions.",
                        "Since the in-person conference last year after COVID-19 pandemic, ICML is going to be in person this year as well. Because the goal of ICML socials is to help the attendees communicate with each other for better research, we note that neither socials nor mentoring sessions should be used to promote any person and/or company. A company that wishes to have an advertisement at the conference should apply to be a sponsor and use resources available for sponsors",
                        "A social is a participant-led meeting centered around different themes. More information about socials can be found here: https://icml.cc/Conferences/2023/CallForSocials/.",
                        "If you are interested in hosting a social (either in-person only or in-person with live stream), please complete this form. Submit this form before 11 June 2022 (anywhere on earth).",
                        "Privacy notice: We collect email addresses to contact you afterwards for feedback about your session. This data can be seen by the ICML organising committees and their support teams, and identifiable information (e.g., names and emails) will be removed within 6 months of the conference ending."
                    ]
                },
                "Important Dates": {
                    "Deadline": "June 11 2023",
                    "Notification": "June 18 2023"
                },
                "FAQ(will be extended)": {
                    "Will there be financial support for inviting speakers etc? ": "No, but the rooms are made available for free.",
                    "For which time slots will  rooms be available?": "We try to get rooms whenever there is no main program session taking place. Most likely in the late afternoon and evening hours (main conference time). ",
                    "Will you provide Visa letters for attendees of socials?": "No. Since attendees for socials will be ICML attendees, please check the conference page for visa letters  (https://icml.cc/Register2?showPanel=5) "
                },
                "Social Chairs, ICML 2023": "Hendrik Strobelt and Jung-Woo Ha"
            },
            "Call For Expo": {
                "title": "ICML 2023 Expo Call for Talks and Panels",
                "date": "Sun Jul 23, 2023",
                "location": "Hawaii Convention Center, Honolulu",
                "Submission deadline": "May 31, 2023 ",
                "introduction": [
                    "Speakers confirm that their talk will accord with the ICML code of conduct.",
                    "Submissions are solicited from ICML sponsors for ICML 2023 Expo, a new component of the International Conference on Machine Learning (ICML 2023), a multitrack, interdisciplinary conference that brings together researchers in machine learning, neural computational and their applications. ",
                    "Talks and panels will be held on Sun Jul 23, 2023, the day before the ICML 2023 main conference tutorials.",
                    "We invite sponsors to submit proposals for talks and panels on topics that are relevant to the ICML community. Submissions will be evaluated on their general interest, potential impact, and timeliness."
                ],
                "Subject areas": [
                    "1. Applications",
                    "2. Software",
                    "3. Hardware",
                    "4. Algorithms",
                    "5. Neuroscience and AI",
                    "6. Research opportunities"
                ],
                "Submission Format": [
                    "Title of the Talk/Panel",
                    "Name and contact information of the organizer",
                    "(phone number, email address, physical address) ",
                    "Name(s) and affiliation of speaker(s)",
                    "Abstract of the talk/panel."
                ]
            }
        },
        "Resources": {
            "Author Tips": {},
            "Poster Instructions": {
                "Physical Conference Poster Presenter Instructions": [
                    "Please bring your poster to your assigned poster session and place it in the location identified on your poster page.  If you are bringing a poster for a workshop check with your workshop organizer for details but usually posters are put up in the workshop on the day of the workshop.",
                    "For some conferences an author may optionally also prepare a virtual poster and thumbnail.  These posters and thumbnails may be used on the website as part of your poster page.  See the Virtual Poster Presenter Instructions  for details on uploading the poster and thumbnail.  See Poster Uploads for instructions to upload your poster and thumbnail."
                ],
                "Virtual Poster Presenter Instructions(url)": "https://wiki.eventhosts.cc/en/reference/poster-presenter-instructions",
                "Poster Uploads(url)": "https://wiki.eventhosts.cc/en/reference/posteruploads",
                "Visit your Poster Page (main conference posters only)": "Search the Paper browser in the virtual site for your paper title and open your paper's virtual page by clicking the title or by visiting the My Stuff page.  You will need to be logged onto the conference website in order to see the Paper browser.",
                "htmls": [
                    {
                        "conference": "neurips",
                        "html": "https://neurips.cc/virtual/current/papers.html"
                    },
                    {
                        "conference": "icml",
                        "html": "https://icml.cc/virtual/current/papers.html"
                    },
                    {
                        "conference": "iclr",
                        "html": "https://iclr.cc/virtual/current/papers.html"
                    },
                    {
                        "conference": "AISTATS",
                        "html": "https://virtual.aistats.org/virtual/current/papers.html"
                    },
                    {
                        "conference": "mlsys",
                        "html": "https://mlsys.org/virtual/current/papers.html"
                    }
                ],
                "notice": [
                    "Note the location and time of your poster on your paper's virtual page.",
                    "Check that your abstract is correct by  clicking the [ Abstract ] link.",
                    "Check the authors list",
                    "If you pre-recorded a video, it will appear on the page a few days before the conference.",
                    "Test the virtual world as described below.",
                    "If you are logged onto the account associated with a poster you should see a link to the Metadata Poster Page."
                ],
                "Poster Printing": {
                    "For NeurIPS visit this page": "https://neurips.cc/FAQ/PosterInformation",
                    "ICML visit this page": "https://icml.cc/FAQ/PosterInstructions"
                },
                "Main Conference": "No larger than 4'x8' landscape",
                "Workshop": [
                    "No larger than 24\" x 36\" in portrait",
                    "Printed on lightweight paper.",
                    "If poster board are not provided you will tape your poster directly to the wall using onky the tape we provid",
                    "Use only the tape we provide."
                ]
            },
            "Review Form": {
                "quote": {
                    "content": "Review the papers of others as you would wish your own to be reviewed",
                    "writer": "Mihir Bellare",
                    "url": "https://youtu.be/SPVWSG7-i_E?t=1742)"
                },
                "Background": "We share here the review form to be used with ICML 2022 with some extra explanations in order to help both authors and the PC members. More information about how to be a good reviewer can be found here. All reviewers are expected to adhere to the principles mentioned there.",
                "content": [
                    "The review is written for the Meta-Reviewer (MR) and the authors. The MR wants to see that the reviewer understood the paper (or how much they understood), and they also want to get the opinion of the reviewer about relevance, soundness, novelty, completeness and the quality of writing/presentation. The authors want to know whether there are any ways to improve the paper. Eventually, the paper needs to serve the readers: they want new, interesting, correct results, or new insights that are well supported and written up in an easy-to-read paper. The reviewing process should be a collaborative process where all participants work together towards ICML publishing papers that readers will find useful, interesting and a pleasure to read. ",
                    "Each aspect listed below should be evaluated on its own merit. However, if a paper has a major flaw, it is unnecessary to list all the issues (e.g., issues with writing). However, use this carefully: It is unfair to bring up major issues after the reviews have been released to the authors. In other words, the review needs to have complete information about the possible concerns with the paper before it is released to the authors. Also, it is essential to explain which issues are considered major and which are considered minor.",
                    "Summarize the contributions made in the paper with your own words. Aim for precision and conciseness. This part of the review serves the purpose of showing to the MR and the authors how much you understood of the paper and what you think the paper is about. This is not the point to evaluate the contributions for their strengths or correctness. Merely provide a summary of what the contributions are.",
                    "Novelty, relevance, significance. Assuming the contributions of the paper stand, are they relevant for our community? Are they new? A precise justification is needed if the answer is no (or partially no, e.g., citations of precise results in earlier papers), so that the authors know how to fix the paper if it is fixable. Are the results sufficiently interesting to make this a sufficiently “complete” (or, one may say, significant) paper? Note that significance does not necessarily mean solving a major open problem. Small, interesting results can also be significant. Science is incremental. But there has to be a detectable, positive increment of sufficient interest. Regarding relevance, keep in mind that the machine learning community has traditionally been quite open-minded to new ideas from different areas. So, think whether this result could benefit some sub-area of ML, or a part of the community, down the line.",
                    "Soundness. A paper ideally makes claims, which should be well supported, either by theoretical arguments, or by experimental results. Either say, the paper is sound, or list the problems. Only list major problems. Any problem listed needs a justification: do not just say that a result is incorrect, include an explanation of why you think it is incorrect. For example, a proof may have some gaps, an experiment may fail to support a claim because of its design or outcome (or the lack of its outcome). For experimental papers, the paper may fail to use a sound experimental design (e.g., the data collection may have problems).",
                    "Quality of writing/presentation. Is the paper well organized and clearly written? Does it do a good job at explaining the novelty and the results? Does the paper include enough information needed to support the claims it makes? There is an overlap here with soundness: Sometimes soundness cannot be decided if the claims in the paper are not well supported, sometimes it can still be decided (e.g. by the reviewer doing additional work; we do not expect though reviewers doing this work). In cases like this, note on the previous item that soundness cannot be decided for reasons explained under this heading. For experimental papers, it is a presentation issue if the paper did not include enough details to reproduce the experimental results with a reasonable effort. A superbly written experimental paper explains: (1) why were the experimental conditions selected the way they were selected; (2) the subsequent choices of what to measure and what to plot (including perhaps what is not shown); (3) how the results obtained substantiate the claims made. The paper should follow standard, best practices (e.g., includes error bars, better yet, uses box plots or something similar unless you suspect near Gaussian variables, etc.)",
                    "Literature. Is the paper appropriately placed into contemporary literature? If not, be specific about what is missing. Note that oftentimes it is a question of judgement of whether a result should be mentioned as papers are subject to page limits. The must-mention results are directly relevant to the topic of the paper. If you ask authors to include other papers, you will need to declare (privately, see below) whether you are an author of any of the recommended papers. It is OK to recommend relevant papers authored by yourself, however, it is not OK to recommend papers that are not relevant to be included. When in doubt, it is better to err on the side of not recommending your own papers (or ask the MR). It is not reasonable to expect a paper to refer to unpublished works that appeared within one month before the submission deadline. Concurrent works should be referred to, but cannot be held against the paper in terms of novelty. Often, these are delicate decisions and reviewers should consult their MR for guidance. ",
                    "Basis of review. Declare how much of the paper you read. E.g., “I read the full paper, including all the proofs.”. The goal is to ensure full coverage of all parts of the paper by the reviewers and the MR."
                ],
                "Summary": [
                    "List the strong and weak points of the paper, but also provide further input to whether (and why) you think the strengths or the weaknesses are dominating. For each point, indicate the importance of the point at hand: is this a major (important, critical) strength/weakness, or a minor one?",
                    "When evaluating these points take into account that some things are easy, while others are harder to fix. Include a justification. Remember, that the goal is to publish innovative, interesting, correct, good papers. Could this paper be one of those worthy to be published at ICML?",
                    "In general, reviewers are not expected to make accept/reject recommendations, this will be the job of the MRs based on all the information they have, including this summary."
                ],
                "exception": {
                    "Miscellaneous minor issues": "List any typos, grammar, etc. issues which you view as minor but should be addressed in the final version of the paper",
                    "Declaration [visible to MR, SMR and PC, not to other reviewers or the authors]": "In my review, I recommended a paper co-authored by myself to be cited in a revision of the paper. [Yes/No]",
                    "Phase 1 recommendation.Should progress to phase 2: Yes/No": [
                        "Only recommend no if you believe that the paper is not acceptable AND it cannot be fixed in simple ways. Easy to fix issues are: Few missing references, a few trivial improvements to the presentation, some fixes in proofs that are within reach, some extra experiments that are nice to have but not essential to publish the paper. On the latter point, if a paper would need substantially more experimental support, doing this is beyond the scope of the reviewing process. We do not expect authors to run extensive new experiments during the rebuttal process: Simply, there is no time for this, nor is there time to properly reevaluate the outcome of these experiments.",
                        "Note that this is a recommendation and the MR has the right to overwrite it. By default, papers with two negative recommendations are heading for rejection for Phase 1. MRs are asked to check the reviews and the papers that receive two negative recommendations and they can reverse this default decision. "
                    ],
                    "Do you have concerns regarding the ethics of the research presented in the paper? [Yes/No]": "This will be used to flag the papers to go through a review by the ethics board."
                }
            },
            "Reviewer Tutorial": {
                "title": "ICML 2023 Reviewer Tutorial",
                "quote": {
                    "content": "Review the papers of others as you would wish your own to be reviewed",
                    "writer": "Mihir Bellare",
                    "url": "https://youtu.be/SPVWSG7-i_E?t=1742)"
                },
                "Background": "The review is written for the Area Chair (AC), the authors and the research community. The AC wants to understand how well the reviewer understood the paper, and what the reviewer’s opinion is of the paper.  It is also a chance to give valuable feedback to the authors. Ultimately papers must serve the wider research community, providing new insights that can help advance the field. ",
                "Policy on Large Language Models (LLMs) for ICML 2023 Reviewing": [
                    "Given the above objectives, it is important that the opinion of the reviewer be expressed in the written review. It is acceptable to use large language models to copy edit or modify the language in a potential review, but the reviewer is ultimately responsible for their review submitted, its content, and its correctness. It is not acceptable for a reviewer to have a LLM generate the full review and submit it as if it is their own, just as it would not be acceptable to have someone else review a paper and submit it as one’s own review. Note, in addition, many LLM services may store and use the prompts and data submitted to them: in such cases it is not permitted to upload any part of authors’ paper submission, since these submissions are submitted assuming that their content will not be shared broadly before acceptance. [LLMs are a fast evolving technology and this policy may be revised in ICML 2024 or in future years].",
                    "For new reviewers, we encourage you to learn more about reviewing. Reviewing is an important research skill to cultivate, and, like all skills, can be learned. The following slide deck provides training and resources (please note that there is no separate Phase 1 and Phase 2 on the reviewing process for ICML 2023)",
                    "How to be a good reviewer-tutorials for ICML reviewers.pptx",
                    "Below we give some additional details and examples for a few aspects of the reviewer form: most other aspects will be largely self explanatory. Don’t hesitate to reach out to your AC or others if you have questions. "
                ],
                "Reviewer Form Details": [
                    "Briefly summarize the paper and its contributions. This is not the place to critique the paper; the authors should generally agree with a well-written summary. Aim for precision and conciseness. This part of the review serves the purpose of showing to the MR and the authors how much you understood of the paper and what you think the paper is about. A few sentences suffices.",
                    "Examples:",
                    "In this paper the authors extend the Carrot features framework, which has recently had great success in domain adaptation. The results show improvement over prior methods.",
                    "– extend in what way? What problem does the paper address? What is the research question?",
                    "This paper discusses that existing methods on including classifiers in a cGAN biases the generator in generating easy to classify images. Therefore, they propose a way to include classifiers in a cGAN to improve its performance in a principled manner. To do so, they decompose the joint probability distribution by the Bayes rule that results in linking classifiers to conditional discriminators. The proposed formulation shows that a joint generator model can be trained from two directions: a conditional discriminator and an un-conditional discriminator with a classifier. They combine the formulation of these two routes and propose a new method called Energy-based cGAN (ECGAN). ECGAN shows how to use a classifier for cGANs, and it explains other variants of cGANs such as ContraGAN, ACGAN, and ProjGAN as variations of its framework. They empirically show that ECGAN outperforms existing cGANs by achieving higher FID (and similar ones) score on two sets of datasets (CIFAR10, Tiny ImageNet).",
                    "Please provide a thorough assessment of the strengths and weaknesses of the paper, touching on each of the following dimensions: originality, quality, clarity, and significance. We encourage people to be broad in their definitions of originality and significance. For example, originality may arise from creative combinations of existing ideas, application to a new domain, or removing restrictive assumptions from prior theoretical results. You can incorporate Markdown and Latex into your review. See https://openreview.net/faq. Note that significance does not necessarily mean solving a major open problem. Small, interesting results can also be significant. Science is incremental. But there has to be a detectable, positive increment of sufficient interest. ",
                    "In addition, a paper ideally makes claims, which should be well supported, either by theoretical arguments, or by experimental results. If there is a claim that is incorrect or not well supported, please include that in your review. For example: a proof may have some gaps, an experiment may fail to support a claim because of its design or outcome (or the lack of its outcome), or the work may not use a sound experimental design (e.g., the data collection, or hyperparameter selection may have problems).",
                    "Examples:",
                    "Novelty:",
                    "“This paper proposes a new model for doing X, and it beats the state of the art.” ",
                    "– not enough detail: what exactly is novel? What has not been done before?",
                    "“Representation learning of molecules has become an important problem in computational chemistry and pharmacy. Yet, a known problem is that existing methods cannot well represent structural motifs. Existing methods do …. but they suffer from high complexity. This paper is the first to connect the theory of spectral semi-snippets with graph representation learning. This theory allows to compactly represent motifs, and the paper demonstrates how to exploit this idea in a parametrized form, which, with some more re-writing, leads to a model that runs in linear instead of cubic time in the size of the graph. This idea is to my knowledge completely novel in the graph representation literature and may inspire further such models.” ",
                    "– this has more details and specific justification",
                    "This result is well known, see reference ",
                    "– say what exactly is known, e.g., which part of the theorem and under which conditions, and where in the reference one can find it. It is very important to point out the exact references, too.",
                    "Soundness:",
                    "Review says: “Lemma 3 is wrong.” ",
                    "– where exactly is the mistake? Is it possibly fixable (the reviewer does not need to do long alternative derivations, but they may see an easy alternative route)? How does it affect the rest of the paper?",
                    "Instead try:",
                    "The proof of Lemma 3 has a mistake. Equation (25) only holds for nonnegative numbers, but it is needed for all reals. This makes Lemma 3 only valid for x in the range [..]. Theorem 2 relies on Lemma 3, and then only holds in a limited range of [...]. Since Theorem 2 is the main result of the paper, this is a major point weakening the contribution of the paper. ",
                    "Example on a to-the-point phrasing from a reviewer raising serious formulation issues (i.e., what to avoid from the authors’ perspective): ",
                    "I have to admit that I had some troubles in properly evaluating the algorithm because the problem it addresses is not formalized and thus we do not know what the paper is solving here.",
                    "Several points to clarify are :",
                    "what is the optimization problem the authors want to solve?",
                    "does the algorithm provide a solution to the exact problem or to an approximate one?",
                    "what are the hypotheses needed for convergence?",
                    "does the iterative procedures converge? why do we use an iterative procedure?",
                    "if it converges, does it converge towards a solution of the problem when T goes to infinity? ",
                    "Ultimately, all good reviews substantiate their claims: it is important that you flesh out, as clearly as possible, the reasons motivating your assessment (whether positive or negative) of the submission.",
                    "Soundness. Please assign the paper a numerical rating on the following scale to indicate the soundness of the technical claims, experimental and research methodology and on whether the central claims of the paper are adequately supported with evidence. "
                ]
            },
            "How to be a Good Reviewer": "https://docs.google.com/presentation/d/1UY6syNSjyPij849gByUjrQe78HG8MU_K/edit#slide=id.p3",
            "Area Chair Tutorial": "https://media.icml.cc/Conferences/ICML2022/ICML2022_AC_Tutorial.pdf"
        },
        "Attend": {
            "Register": {
                "Instructions": [
                    "Update your profile and optionally choose your pronouns and dietary restrictions. If you have multiple pronouns, use \"Specify your own\" to list them all.",
                    "Password must be at least 9 characters.",
                    "Email yourself a receipt in section 3.",
                    "Virtual Pass includes virtual-only access to the live stream of the entire conference (tutorials, main conference, workshops) and the ability to interact using Rocket Chat. All physical registrations include Virtual Pass.",
                    "Registration for any component tutorials, main conference or workshop includes access to the affinity events.",
                    "If you are open to being recruited by a sponsor, see section 6.",
                    "Student ID required to get student discount. See more.",
                    "Agree to the code of conduct, and privacy policy",
                    "Visa information is available here.",
                    "For accessibility support, please contact us. ",
                    "Masks are not required at this time. We will follow Government guidelines. Face shields will be available for poster presenters.",
                    "Registration Cancellation Policy",
                    "Registrations are not Transferable."
                ],
                "ICML Code of Conduct": {
                    "introduction": "The open exchange of ideas, the freedom of thought and expression, and respectful scientific debate are central to the goals of this conference on machine learning; this requires a community and an environment that recognizes and respects the inherent worth of every person.",
                    "Who": "All participants---attendees, organizers, reviewers, speakers, sponsors, and volunteers at our conference, workshops, and conference-sponsored social events---are required to agree with this code of conduct both during the event and on official communication channels, including social media. Organizers will enforce this code, and we expect cooperation from all participants to help ensure a safe and productive environment for everybody.",
                    "Scope": [
                        "The conference commits itself to providing an experience for all participants that is free from harassment, bullying, discrimination, and retaliation for all participants. This includes offensive comments related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion (or lack thereof), politics, technology choices, or any other personal characteristics. Bullying, intimidation, personal attacks, harassment, sustained disruption of talks or other events, and behavior that interferes with another's full participation will not be tolerated. This includes sexual harassment, stalking, following, harassing photography or recording, inappropriate physical contact, unwelcome sexual attention, public vulgar exchanges, and diminutive characterizations, which are all unwelcome in this community.",
                        "This Code of Conduct applies to the actual meeting sites and conference venues where ICML business is being conducted, including both physical and official virtual engagement platforms, including video, virtual streaming, and chat-based interaction. ICML is not responsible for non-sponsored activity or behavior that may occur at non-sponsored locations such as hotels, restaurants, or locations not otherwise a sanctioned space for ICML sponsored events (including virtual spaces). ICML will not actively monitor social media platforms, but will follow up on issues of harassment and violations of the code of conduct that occur on those platforms that are specifically related to the ICML program, during the course of ICML, if and when they are brought to our attention.",
                        "Sponsors are equally subject to this Code of Conduct. In particular, sponsors should not use images, activities, or other materials that are of a sexual, racial, or otherwise offensive nature. Booth staff (including volunteers) should not use sexualized clothing/uniforms/costumes, or otherwise create a sexualized environment. This code applies both to official sponsors as well as any organization that uses the conference name as branding as part of its activities at or around the conference."
                    ],
                    "Outcomes": "Participants asked by any member of the community to stop any such behavior are expected to comply immediately. If a participant engages in such behavior, the conference organizers may take any action they deem appropriate, including: a formal or informal warning to the offender, expulsion from the conference with no refund, barring from participation in future conferences or their organization, reporting the incident to the offender’s local institution or funding agencies, or reporting the incident to local law enforcement. A response of just joking will not be accepted; behavior can be harassing without an intent to offend. If action is taken, an appeals process will be made available.",
                    "Reporting": [
                        "If you have concerns related to your inclusion at that conference, or observe someone else's difficulties, or have any other concerns related to inclusion, please contact the Diversity and Inclusion co-chairs or the Conference HR Liaison.",
                        "The Diversity and Inclusion co-chairs can be reached by email at diversity-chairs@icml.cc. The HR Liaison can be reached via the ICML Hotline at either ICMLhotline@gmail.com or 858-208-3810. Conference volunteers will also have this contact information and can assist with connecting you to the co-chairs or the HR Liaison. Complaints and violations will be handled at the discretion of the Diversity & Inclusion co-chairs, general chair, HR Liaison, and the conference board. Reports made during the conference will be responded to in less than 24 hours; those at other times in less than two weeks. We are prepared and eager to help participants contact relevant help services, to escort them to a safe location, or to otherwise assist those experiencing harassment to feel safe for the duration of the conference. We gratefully accept feedback from the community on policy and actions; please contact us."
                    ]
                },
                "Privacy Policy": {
                    "Information We Collect and How We Use It": "We collect certain information from you through your use of the Website, such as the information you provide to ICML by registering for a user account. ",
                    "Information You Provide to Us": [
                        "When you use the ICML Website to register a user account, limited information is collected about you through a form. This information is for the purpose of identifying and communicating with you as supporters, conference registrants and community members.",
                        "We may need to send you announcements and account-related messages. These will be sent through the Website or by email."
                    ],
                    "We will not share the personal information we have collected from you, except as described below": [
                        "when you agree to share your information with our sponsors during registration in the Jobs and Recruitment section.",
                        "when auditing our books, your information may be shared temporarily with our partners in a very limited scope.",
                        "when we believe we are authorized or legally required to do so or that doing so is necessary or appropriate to comply with the law or legal processes or respond to lawful requests or legal authorities, including things like subpoenas, warrants or court orders.",
                        "to enforce or apply our Privacy Policy, our Terms of Use or our other policies or agreements.",
                        "if your company is one of our sponsors. Some sponsors have access to a report that shows who from their company is attending (including email addresses), what they've registered for, and what they are presenting. A sponsor can only see information for their own employees.",
                        "to facilitate and support visa applications, we may share a list of current year registrations with the immigration office of the current year host government",
                        "meeting organizers have access to user profile information to facilitate building the schedule, and communicating with speakers and presenters"

                    ],
                    "Accessing Your Information": "If you would like ICML to delete your personal information that has been collected, please contact us with your request. ",
                    "How We Protect Your Information": "We employ administrative, physical, and electronic measures designed to protect your information from unauthorized access. However, despite those efforts, no security measures are perfect or impenetrable. ",
                    "Links to Other Sites": "The ICML Website may contain links to other services, apps, and sites not operated by us (we refer to these as Other Sites). Any information you provide on those Other Sites is provided directly to the owner of that site. Our Privacy Policy does not apply to those Other Sites, and we are not responsible for the content you provide to, or the privacy and security practices and policies of, Other Sites. CMT and OpenReview are examples of Other Sites. ",
                    "Changes to Our Privacy Policy": "Any information that is collected is subject to our Privacy Policy in effect at the time such information is collected. We may, however, modify and revise our Privacy Policy from time-to-time. In the event of a modification to the Privacy Policy, ICML will send notification to you that a change has occurred via the Website or Email. It is required that you accept the revised Privacy Policy before continuing to use the Website. By accepting changes to the policy, you are agreeing to be bound by the revised policy. ",
                    "Questions or Concerns": "Please contact us if you have any questions or concerns about our Privacy Policy. "
                }
            },
            "Hotels": {
                "title": "Hotels – Hawaii 2023",
                "introduction": [
                    "The Hotel Reservations portal for the Fourth International Conference on Machine Learning is now open.",
                    "Book your Hotel Registration with the conference santioned venues  HERE",
                    "ICML has contracted guest rooms at discounted pricing. Reserve your accommodations early for the best chance of getting your first choice. We urge you to please make your reservations at only one of the sanctioned ICML Hotels and through the links above as they contribute to keeping our costs down and protect ICML to meet the projections we commit to. If ICML does not achieve a minimum number of overnight accommodations, the price of services will increase all costs for future programs. We thank you for your assistance."

                ]
            },
            "Child Care": {
                "title": "ICML 2023 Child Care",
                "introduction": [
                    "ICML 2023 is proud to provide free on site child care from Sunday, July 23rd through Saturday, July 29th to our attendees at The Hawai‘i Convention Center.  ",
                    "This year, we have partnered with Aloha Sitters, a local, fully licensed small business that is owned and operated by economically disadvantaged women. Visit Aloha Sitters’ website for a quick glance of this organization. Aloha Sitters will have custom themed activities with an overflow of fun crafts and games to keep your child(ren) occupied.",
                    "Please CLICK HERE to begin the registration process for your child(ren). The deadline to register is July 5, 2023 (EOD/AOE). There are no guarantees of availability if you show up on site without registering your child(ren). This is due to strict ratios of the number of children permitted per sitter. ",
                    "The conference provides child care in order to facilitate traveling and attendance of participants with children. This child care is for parents and not for children to attend the conference. If any child of a participant attends the conference, we consider them as a usual participant and requires them to be registered and pay the registration fee",
                    "Please contact Stephanie Willes if you have any questions."
                ],
                "IMPORTANT INFORMATION:": [
                    "Parents/guardians must have a conference registration for the same dates that they've registred their child for child care services. For example, if you've only purchased a workshop registration, then your child is only eligible for child care services on Friday and Saturday. If you'd like your child to have child care services from Sunday, July 23rd - Saturday, July 29th then you must purchase all three registrations (Tutorials, Conference Sessions, & Workshops). ",
                    "A parent/guardian MUST remain at the venue (Hawaii Convention Center) at all times while their child(ren) are in the child care center. "
                ]
            },
            "Baggage Check": {
                "introduction": [
                    "ICML 2023 is providing complimentary baggage check service for conference attendees",
                    "Baggage check will be located in the room 303B on the 3rd floor of the Hawaii Convention Center. ICML or its staff are not liable for lost, stolen, or damaged baggage or the contents wherein. You must provide ID and luggage ticket at pick-up. We suggest you take a photo of your luggage and ticket in case your ticket is lost."
                ],
                "time": [
                    "July 24th 9:00 am to 5:00 pm HT",
                    "July 25th 8:00 am to 5:00 pm HT",
                    "July 27th 8:00 am to 5:00 pm HT"
                ]
            },
            "Parking": {
                "introduction": [
                    "Our parking garage has 690 parking stalls and is located on Level 2 of our facility. The entrance to the parking garage is located on Kalakaua Avenue. The parking garage accommodates vehicles up to 8’11” in height and up to 140” wheelbase. (NOTE: Our exit ramp/helix is not wide enough to accommodate limousines. ",
                    "We have accessible parking available in Row “A” of our parking garage and two accessible unloading and loading zones in the Porte Cochère. Material handling equipment is not permitted in the Porte Cochere. All booth materials requiring material handling equipment, ei., push carts, pallet jacks, dollies are to be unloaded by the service contractor at the docks.",
                    "Parking is allowed during business/event hours only. Our parking lot opens one hour before and closes one hour after an event. Overnight parking is not allowed. Vehicles parked overnight are subject to removal. Parking is restricted to marked parking stalls. Vehicles parked in designated fire lanes, service streets, vacant Exhibit Halls, loading dock areas or locations posted “No Parking” may be cited and/or towed at the owner’s expense. "
                ],
                "Cost": [
                    "The current self-parking rate at the HCC is 15.00, per vehicle payable at exit.",
                    "Guests are more than welcomed to enter and exit the parking lot throughout the day.",
                    "The applicable parking fee of 15.00 will apply to each occurrence of the vehicle exiting the parking garage",
                    "The HCC does allow a 30-minute parking “grace period or complimentary period” to the first 30-minutes of entering its parking structure and exiting – no fee or charge.",
                    "Parking after the first 30-minutes will incur the vehicle exiting fee of 15.00."
                ]
            },
            "Visiting Hawaii": {
                "title": "Visit Hawaii - ICML 2023",
                "Building Layout - FloorPlan": {
                    "url": "https://icml.cc/static/core/HawaiiConventionCenterFloorPlan.pdf"
                },
                "Nursing Pod Information ": {
                    "url": "https://icml.cc/static/core/HCCNursingPod_ICML2023.pdf"
                },
                "Accessibility Brochure": {
                    "url": "https://icml.cc/static/core/HCCAccessibilityBrochure_ICML2023.pdf"
                },
                "Luggage check": "Luggage check will be available. Days and times will be posted later",
                "Health & Safety": "TBD",
                "Recycling": [
                    "HCC is committed to recycling and provides receptacles throughout the common areas for your event recycling needs. Additional receptacles are available for paper recycling in offices, attendee badge holders and lanyards and other items to reuse. HCC has partnered with local organizations to repurpose foam core signs, exhibitor giveaways and exhibitor build-outs. Bulk recycling areas are provided within the Exhibit Halls for all exhibitors to use. ",
                    "We encourage all contractors, exhibitors and attendees to participate in our recycling program as it has proven its effectiveness at reducing trash costs and your impact on the environment.",
                    "Please speak with Stephanie Willes stephanie@eventhosts.cc to discuss your recycling needs. "
                ]
            },
            "Invitation Letter": {
                "Instructions": [
                    "Update your profile and optionally choose your pronouns and dietary restrictions. If you have multiple pronouns, use \"Specify your own\" to list them all.",
                    "Password must be at least 9 characters.",
                    "Email yourself a receipt in section 3.",
                    "Virtual Pass includes virtual-only access to the live stream of the entire conference (tutorials, main conference, workshops) and the ability to interact using Rocket Chat. All physical registrations include Virtual Pass.",
                    "Registration for any component tutorials, main conference or workshop includes access to the affinity events.",
                    "If you are open to being recruited by a sponsor, see section 6.",
                    "Student ID required to get student discount. See more.",
                    "Agree to the code of conduct, and privacy policy",
                    "Visa information is available here.",
                    "For accessibility support, please contact us. ",
                    "Masks are not required at this time. We will follow Government guidelines. Face shields will be available for poster presenters.",
                    "Registration Cancellation Policy",
                    "Registrations are not Transferable."
                ],
                "ICML Code of Conduct": {
                    "introduction": "The open exchange of ideas, the freedom of thought and expression, and respectful scientific debate are central to the goals of this conference on machine learning; this requires a community and an environment that recognizes and respects the inherent worth of every person.",
                    "Who": "All participants---attendees, organizers, reviewers, speakers, sponsors, and volunteers at our conference, workshops, and conference-sponsored social events---are required to agree with this code of conduct both during the event and on official communication channels, including social media. Organizers will enforce this code, and we expect cooperation from all participants to help ensure a safe and productive environment for everybody.",
                    "Scope": [
                        "The conference commits itself to providing an experience for all participants that is free from harassment, bullying, discrimination, and retaliation for all participants. This includes offensive comments related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion (or lack thereof), politics, technology choices, or any other personal characteristics. Bullying, intimidation, personal attacks, harassment, sustained disruption of talks or other events, and behavior that interferes with another's full participation will not be tolerated. This includes sexual harassment, stalking, following, harassing photography or recording, inappropriate physical contact, unwelcome sexual attention, public vulgar exchanges, and diminutive characterizations, which are all unwelcome in this community.",
                        "This Code of Conduct applies to the actual meeting sites and conference venues where ICML business is being conducted, including both physical and official virtual engagement platforms, including video, virtual streaming, and chat-based interaction. ICML is not responsible for non-sponsored activity or behavior that may occur at non-sponsored locations such as hotels, restaurants, or locations not otherwise a sanctioned space for ICML sponsored events (including virtual spaces). ICML will not actively monitor social media platforms, but will follow up on issues of harassment and violations of the code of conduct that occur on those platforms that are specifically related to the ICML program, during the course of ICML, if and when they are brought to our attention.",
                        "Sponsors are equally subject to this Code of Conduct. In particular, sponsors should not use images, activities, or other materials that are of a sexual, racial, or otherwise offensive nature. Booth staff (including volunteers) should not use sexualized clothing/uniforms/costumes, or otherwise create a sexualized environment. This code applies both to official sponsors as well as any organization that uses the conference name as branding as part of its activities at or around the conference."
                    ],
                    "Outcomes": "Participants asked by any member of the community to stop any such behavior are expected to comply immediately. If a participant engages in such behavior, the conference organizers may take any action they deem appropriate, including: a formal or informal warning to the offender, expulsion from the conference with no refund, barring from participation in future conferences or their organization, reporting the incident to the offender’s local institution or funding agencies, or reporting the incident to local law enforcement. A response of just joking will not be accepted; behavior can be harassing without an intent to offend. If action is taken, an appeals process will be made available.",
                    "Reporting": [
                        "If you have concerns related to your inclusion at that conference, or observe someone else's difficulties, or have any other concerns related to inclusion, please contact the Diversity and Inclusion co-chairs or the Conference HR Liaison.",
                        "The Diversity and Inclusion co-chairs can be reached by email at diversity-chairs@icml.cc. The HR Liaison can be reached via the ICML Hotline at either ICMLhotline@gmail.com or 858-208-3810. Conference volunteers will also have this contact information and can assist with connecting you to the co-chairs or the HR Liaison. Complaints and violations will be handled at the discretion of the Diversity & Inclusion co-chairs, general chair, HR Liaison, and the conference board. Reports made during the conference will be responded to in less than 24 hours; those at other times in less than two weeks. We are prepared and eager to help participants contact relevant help services, to escort them to a safe location, or to otherwise assist those experiencing harassment to feel safe for the duration of the conference. We gratefully accept feedback from the community on policy and actions; please contact us."
                    ]
                },
                "Privacy Policy": {
                    "Information We Collect and How We Use It": "We collect certain information from you through your use of the Website, such as the information you provide to ICML by registering for a user account. ",
                    "Information You Provide to Us": [
                        "When you use the ICML Website to register a user account, limited information is collected about you through a form. This information is for the purpose of identifying and communicating with you as supporters, conference registrants and community members.",
                        "We may need to send you announcements and account-related messages. These will be sent through the Website or by email."
                    ],
                    "We will not share the personal information we have collected from you, except as described below": [
                        "when you agree to share your information with our sponsors during registration in the Jobs and Recruitment section.",
                        "when auditing our books, your information may be shared temporarily with our partners in a very limited scope.",
                        "when we believe we are authorized or legally required to do so or that doing so is necessary or appropriate to comply with the law or legal processes or respond to lawful requests or legal authorities, including things like subpoenas, warrants or court orders.",
                        "to enforce or apply our Privacy Policy, our Terms of Use or our other policies or agreements.",
                        "if your company is one of our sponsors. Some sponsors have access to a report that shows who from their company is attending (including email addresses), what they've registered for, and what they are presenting. A sponsor can only see information for their own employees.",
                        "to facilitate and support visa applications, we may share a list of current year registrations with the immigration office of the current year host government",
                        "meeting organizers have access to user profile information to facilitate building the schedule, and communicating with speakers and presenters"

                    ],
                    "Accessing Your Information": "If you would like ICML to delete your personal information that has been collected, please contact us with your request. ",
                    "How We Protect Your Information": "We employ administrative, physical, and electronic measures designed to protect your information from unauthorized access. However, despite those efforts, no security measures are perfect or impenetrable. ",
                    "Links to Other Sites": "The ICML Website may contain links to other services, apps, and sites not operated by us (we refer to these as Other Sites). Any information you provide on those Other Sites is provided directly to the owner of that site. Our Privacy Policy does not apply to those Other Sites, and we are not responsible for the content you provide to, or the privacy and security practices and policies of, Other Sites. CMT and OpenReview are examples of Other Sites. ",
                    "Changes to Our Privacy Policy": "Any information that is collected is subject to our Privacy Policy in effect at the time such information is collected. We may, however, modify and revise our Privacy Policy from time-to-time. In the event of a modification to the Privacy Policy, ICML will send notification to you that a change has occurred via the Website or Email. It is required that you accept the revised Privacy Policy before continuing to use the Website. By accepting changes to the policy, you are agreeing to be bound by the revised policy. ",
                    "Questions or Concerns": "Please contact us if you have any questions or concerns about our Privacy Policy. "
                }
            },
            "Visa Information": {
                "title": "ICML 2023 Visa Information",
                "VISA Letter of Invitation": "Letters of invitation to ICML 2023 are only available for a paid registration. The letter is available in section 5 of the registration page.",
                "Application Information": [
                    "Information on how to apply for a U.S. Visa is available here.",
                    "Find out if you qualify for a Visa Waiver",
                    "Visa FAQ",
                    "Visa Wizard",
                    "Visa Application Wait Times",
                    "List of US Embassies",
                    "iVisa.com and Travisa are services that can provide Visa application support."
                ],
                "If your visa appliction is denied": "See this page for more information on how to proceed.",
                "Submitting your application": [
                    "We recommend that you start you submit your application as soon as you can. Processing times for visa applications vary depending on the visa office and the time of the year. ",
                    "Make sure you complete all parts of you application. A common problem in previous years is submission of an incomplete application."
                ]
            }
        },
        "Organization": {
            "ICML Board": {
                "title": "2023 ICML Officers and Board Members",
                "President": {
                    "name": "Francis Bach",
                    "affiliation": "INRIA - Ecole Normale Supérieure"
                },
                "President Elect": "Kilian Weinberger",
                "Secretary": {
                    "name": "Jennifer Dy",
                    "affiliation": "Northeastern University"
                },
                "Treasurer": {
                    "name": "John Langford",
                    "affiliation": "Microsoft Research"
                },
                "Legal Advisor": "David Kirkpatrick",
                "Board Members": [
                    {
                        "name": "Aarti Singh",
                        "affiliation": "2020 Program Chair"
                    },
                    {
                        "name": "Andreas Krause ",
                        "affiliation": "Elected 2019 & 2018 Program Chair"
                    },
                    {
                        "name": "Corinna Cortes ",
                        "affiliation": "Elected 2018"
                    },
                    {
                        "name": "Csaba Szepesvari",
                        "affiliation": "2022 Program Chair"
                    },
                    {
                        "name": "David Blei ",
                        "affiliation": "2020 General chair"
                    },
                    {
                        "name": "Emma Brunskill ",
                        "affiliation": "Elected 2018"
                    },
                    {
                        "name": "Eric Xing ",
                        "affiliation": "Elected 2019 & 2019 General Chair"
                    },
                    {
                        "name": "Francis Bach ",
                        "affiliation": "Elected 2019 & 2023 President"
                    },
                    {
                        "name": "Hal Daume",
                        "affiliation": "2020 Program Chair"
                    },
                    {
                        "name": "Hanna Wallach ",
                        "affiliation": "Elected 2019"
                    },
                    {
                        "name": "Hugo Larochelle ",
                        "affiliation": "Elected 2018"
                    },
                    {
                        "name": "Jennifer Dy ",
                        "affiliation": "2018 Program Chair & 2022 Secretary"
                    },
                    {
                        "name": "Kamalika Chaudhuri ",
                        "affiliation": "2019 Program Chair"
                    },
                    {
                        "name": "John Langford ",
                        "affiliation": "2022 President & 2023 Treasurer"
                    },
                    {
                        "name": "Kilian Weinberger ",
                        "affiliation": "Elected 2018"
                    },
                    {
                        "name": "Nina Balcan ",
                        "affiliation": "Elected 2018 & 2021 General Chair"
                    },
                    {
                        "name": "Ruslan Salakhutdinov ",
                        "affiliation": "2019 Program Chair"
                    },
                    {
                        "name": "Stefanie Jegelka",
                        "affiliation": "2022 Program Chair"
                    },
                    {
                        "name": "Thorsten Joachims ",
                        "affiliation": "Elected 2018"
                    },
                    {
                        "name": "Shakir Mohamed",
                        "affiliation": "Elected 2019"
                    },
                    {
                        "name": "Le Song",
                        "affiliation": "Elected 2019"
                    },
                    {
                        "name": "Marina Meila",
                        "affiliation": "2021 Program Chair"
                    }
                ],
                "Emeritus Members": [
                    {
                        "name": "Joelle Pineau",
                        "affiliation": "Elected & Past President"
                    },
                    "William Cohen",
                    "Tom Dietterich",
                    "Andrew McCallum",
                    "Ray Mooney"
                ]
            },
            "Organizing Committee": {
                "title": "2023 ICML Organizing Committee",
                "General Chair": {
                    "name": "Andreas Krause",
                    "affiliation": "ETH Zurich"
                },
                "Expo Chairs": [
                    {
                        "name": "Adish Singla",
                        "affiliation": "Max Planck Institute (MPI-SWS)"
                    },
                    {
                        "name": "Rose Yu",
                        "affiliation": "University of California, San Diego"
                    }
                ],
                "Workshop Chairs": [
                    {
                        "name": "Cheng Soon Ong",
                        "affiliation": "Data61 and ANU"
                    },
                    {
                        "name": "Po-Ling Loh",
                        "affiliation": "University of Cambridge"
                    },
                    {
                        "name": "Virginia Smith",
                        "affiliation": "Carnegie Mellon University"
                    }
                ],
                "Tutorial Chairs": [
                    {
                        "name": "Bo Li",
                        "affiliation": "UIUC"
                    },
                    {
                        "name": "Hanie Sedghi",
                        "affiliation": "Google Brain"
                    },
                    {
                        "name": "Martin Jaggi",
                        "affiliation": "EPFL"
                    }
                ],
                "Communications Chairs": [
                    {
                        "name": "Marco Cuturi",
                        "affiliation": "Apple"
                    },
                    {
                        "name": "Yisong Yue",
                        "affiliation": "Caltech & Latitude AI"
                    }
                ],
                "Program Chairs": [
                    {
                        "name": "Barbara Engelhardt",
                        "affiliation": "Princeton University"
                    },
                    {
                        "name": "Emma Brunskill",
                        "affiliation": "Stanford University"
                    },
                    {
                        "name": "Kyunghyun Cho",
                        "affiliation": "New York University, Genentech"
                    }
                ],
                "Workflow Chair": {
                    "name": "Zhenyu (Sherry) Xue",
                    "affiliation": "ICML"
                },
                "Social Chairs": [
                    {
                        "name": "Hendrik Strobelt",
                        "affiliation": "MIT-IBM Watson AI Lab, IBM Research"
                    },
                    {
                        "name": "Jung-Woo Ha",
                        "affiliation": "NAVER AI Lab@NAVER Cloud"
                    }
                ],
                "Accessibility Chair": {
                    "name": "Maria Skoularidou",
                    "affiliation": "University of Cambridge"
                },
                "Publications Chairs": [
                    {
                        "name": "Jonathan Scarlett",
                        "affiliation": "National University of Singapore"
                    },
                    {
                        "name": "Sivan Sabato",
                        "affiliation": "Ben-Gurion University of the Negev"
                    }
                ],
                "Diversity & Inclusion Chairs": [
                    {
                        "name": "Finale Doshi-Velez",
                        "affiliation": "Harvard University"
                    },
                    {
                        "name": "Sinead A Williamson",
                        "affiliation": "University of Texas at Austin"
                    }
                ],
                "Associate Chairs": [
                    {
                        "name": "Didong Li",
                        "affiliation": "University of North Carolina Chapel Hill"
                    },
                    {
                        "name": "Natasa Tagasovska",
                        "affiliation": "Prescient Design - Genentech, Roche"
                    },
                    {
                        "name": "Yannis Flet-Berliac",
                        "affiliation": "Stanford University"
                    }
                ]
            },
            "Reviewers": {
                "introduction": "The program at ICML is made possible by the hard work of a large number of people who contribute their expertise to this process. Reviewers (7403) carefully read and assess papers, provide critical feedback to authors, and provide an appraisal of the papers' strengths. Meta-reviewers (281) work with reviewers to reach a decision through discussion and deliberation, and who write meta-reviews to authors that highlight the most salient points. Senior Meta-Reviewers (53) co-ordinate and calibrate the Meta-Reviewer recommendations, and are involved with the peer review and decision process in the more difficult and unusual situations.",
                "Senior Meta Reviewers": {},
                "Meta Reviewers": {},
                "Outstanding Reviewers (Top 10%)": [
                    {
                        "name": "Abhinav Shukla",
                        "affiliation": "FacebookFacebook"
                    },
                    {
                        "name": "Alessio Sampieri",
                        "affiliation": "University of Roma \"La Sapienza\""
                    },
                    {
                        "name": "Aliaksandr Siarohin",
                        "affiliation": "Snap Inc."
                    },
                    {
                        "name": "Ameesh Makadia",
                        "affiliation": "Google"
                    },
                    {
                        "name": "Amit Raj",
                        "affiliation": "Google "
                    },
                    {
                        "name": "Anand Mishra",
                        "affiliation": "Indian Institute of Technology, Jodhpur"
                    },
                    {
                        "name": "Andrea Burns",
                        "affiliation": "Boston University"
                    },
                    {
                        "name": "Andrei Bursuc",
                        "affiliation": "Valeo; INRIA"
                    },
                    {
                        "name": "Andrew Zisserman",
                        "affiliation": "University of Oxford; DeepMind"
                    },
                    {
                        "name": "Apoorv Khandelwal",
                        "affiliation": "Brown University"
                    },
                    {
                        "name": "Arif Mahmood",
                        "affiliation": "Information Technology University, Lahore"
                    },
                    {
                        "name": "Axel Barroso-Laguna",
                        "affiliation": "Niantic"
                    },
                    {
                        "name": "Baoyuan Wu",
                        "affiliation": "The Chinese University of Hong Kong, Shenzhen"
                    },
                    {
                        "name": "Bernhard Zeisl",
                        "affiliation": "Google"
                    },
                    {
                        "name": "Bin Xia",
                        "affiliation": "Tsinghua University, Tsinghua University"
                    },
                    {
                        "name": "Binh-Son Hua",
                        "affiliation": "VinAI Research"
                    },
                    {
                        "name": "Bruno Korbar",
                        "affiliation": "University of Oxford"
                    },
                    {
                        "name": "Carlo Masone",
                        "affiliation": "Polytechnic Institute of Turin"
                    },
                    {
                        "name": "Chaoyou Fu",
                        "affiliation": "Institute of automation, Chinese academy of science, Chinese Academy of Sciences"
                    },
                    {
                        "name": "Chen Song",
                        "affiliation": "University of Texas at Austin"
                    },
                    {
                        "name": "Chi Xu",
                        "affiliation": "Osaka University"
                    },
                    {
                        "name": "Chi Zhang",
                        "affiliation": "University of California, Los Angeles"
                    },
                    {
                        "name": "Chonghao Sima",
                        "affiliation": "Shanghai AI Lab; Purdue University"
                    },
                    {
                        "name": "Chongjian GE",
                        "affiliation": "The University of Hong Kong"
                    },
                    {
                        "name": "Chongyi Li",
                        "affiliation": "Nanyang Technological University"
                    },
                    {
                        "name": "Chris Rockwell",
                        "affiliation": "University of Michigan"
                    },
                    {
                        "name": "Christian Richardt",
                        "affiliation": "Meta"
                    },
                    {
                        "name": "Christian Unger",
                        "affiliation": "BMW Group"
                    },
                    {
                        "name": "Christopher Thomas",
                        "affiliation": "Virginia Polytechnic Institute and State University"
                    },
                    {
                        "name": "Chuanxia Zheng",
                        "affiliation": "University of Oxford"
                    },
                    {
                        "name": "Constantin Pape",
                        "affiliation": "Georg-August Universität Göttingen"
                    },
                    {
                        "name": "Dailan He",
                        "affiliation": "The Chinese University of Hong Kong; SenseTime Research"
                    },
                    {
                        "name": "Daksh Thapar",
                        "affiliation": "Indian Institute of Technology Mandi"
                    },
                    {
                        "name": "Daniel Duckworth",
                        "affiliation": "Google"
                    },
                    {
                        "name": "David Picard",
                        "affiliation": "École des Ponts"
                    },
                    {
                        "name": "David T Hoffmann",
                        "affiliation": "Bosch; University of Freiburg, Universität Freiburg"
                    },
                    {
                        "name": "Despoina Paschalidou",
                        "affiliation": "Stanford University"
                    },
                    {
                        "name": "Di Huang",
                        "affiliation": "Beihang University"
                    },
                    {
                        "name": "Dimitrios Tzionas",
                        "affiliation": "University of Amsterdam"
                    },
                    {
                        "name": "Dmitry P. Vetrov",
                        "affiliation": "National Research University Higher School of Economics"
                    },
                    {
                        "name": "Dmytro Mishkin",
                        "affiliation": "Czech Technical Univeresity in Prague, Czech Technical University of Prague; HOVER Inc."
                    },
                    {
                        "name": "Doyup Lee",
                        "affiliation": "Kakao Brain"
                    },
                    {
                        "name": "Edoardo Remelli",
                        "affiliation": "EPFL - EPF Lausanne"
                    },
                    {
                        "name": "Eduard Trulls",
                        "affiliation": "Google"
                    },
                    {
                        "name": "Eldar Insafutdinov",
                        "affiliation": "University of Oxford"
                    },
                    {
                        "name": "Evangelos Kazakos",
                        "affiliation": "Samsung"
                    },
                    {
                        "name": "Evgenia Rusak",
                        "affiliation": "FAIR; Max-Planck-Institute for Intelligent Systems, Max-Planck Institute; University of Tuebingen"
                    },
                    {
                        "name": "Fabio Tosi",
                        "affiliation": "University of Bologna"
                    },
                    {
                        "name": "Fangzhou Hong",
                        "affiliation": "Nanyang Technological University"
                    },
                    {
                        "name": "Fangzhou Mu",
                        "affiliation": "University of Wisconsin, Madison"
                    },
                    {
                        "name": "Federico Perazzi",
                        "affiliation": "Bending Spoons"
                    },
                    {
                        "name": "Francesco Cappio Borlino",
                        "affiliation": "Istituto Italiano di Tecnologia; Politecnico di Torino"
                    },
                    {
                        "name": "Francesco Croce",
                        "affiliation": "University of Tuebingen"
                    },
                    {
                        "name": "Gaku Nakano",
                        "affiliation": "NEC Corporation"
                    },
                    {
                        "name": "Gilles Puy",
                        "affiliation": "INRIA; valeo.ai"
                    },
                    {
                        "name": "Guillermo Gallego",
                        "affiliation": "TU Berlin"
                    },
                    {
                        "name": "Gukyeong Kwon",
                        "affiliation": "Amazon Web Services"
                    },
                    {
                        "name": "Gyeongsik Moon",
                        "affiliation": "Facebook"
                    },
                    {
                        "name": "Hannah Bull",
                        "affiliation": "Université Paris-Saclay"
                    },
                    {
                        "name": "Haoran Bai",
                        "affiliation": "Nanjing University of Science and Technology"
                    },
                    {
                        "name": "Haotong Qin",
                        "affiliation": "ETH Zurich; Beihang University"
                    },
                    {
                        "name": "Hazel Doughty",
                        "affiliation": "University of Amsterdam"
                    },
                    {
                        "name": "Henghui Ding",
                        "affiliation": "Nanyang Technological University"
                    },
                    {
                        "name": "Hongbo Fu",
                        "affiliation": "City University of Hong Kong"
                    },
                    {
                        "name": "Hossein Rahmani",
                        "affiliation": "Lancaster University"
                    },
                    {
                        "name": "Huan Liu",
                        "affiliation": "Huawei Technologies Ltd."
                    },
                    {
                        "name": "Huan Wang",
                        "affiliation": "Northeastern University"
                    },
                    {
                        "name": "Huanrui Yang",
                        "affiliation": "University of California, Berkeley"
                    },
                    {
                        "name": "Hung-Jin Lin",
                        "affiliation": "MediaTek Inc."
                    },
                    {
                        "name": "Idil Esen Zulfikar",
                        "affiliation": "RWTH Aachen University"
                    },
                    {
                        "name": "Ioana Croitoru",
                        "affiliation": "imar"
                    },
                    {
                        "name": "Iro Laina",
                        "affiliation": "University of Oxford"
                    },
                    {
                        "name": "Itai Lang",
                        "affiliation": "University of Chicago"
                    },
                    {
                        "name": "Ivan Skorokhodov",
                        "affiliation": "KAUST"
                    },
                    {
                        "name": "Jaime Spencer",
                        "affiliation": "University of Surrey"
                    },
                    {
                        "name": "Jamie Watson",
                        "affiliation": "Niantic"
                    },
                    {
                        "name": "Janne Heikkilä",
                        "affiliation": "University of Oulu"
                    },
                    {
                        "name": "Jason Saragih",
                        "affiliation": "Facebook"
                    },
                    {
                        "name": "Jens Behley",
                        "affiliation": "Rheinische Friedrich-Wilhelms-Universität Bonn, Rheinische Friedrich-Wilhelms Universität Bonn"
                    },
                    {
                        "name": "Jerome Revaud",
                        "affiliation": "Naver Labs Europe"
                    },
                    {
                        "name": "Jiahao Xie",
                        "affiliation": "Nanyang Technological University"
                    },
                    {
                        "name": "Jiangxin Dong",
                        "affiliation": "Nanjing University of Science and Technology"
                    },
                    {
                        "name": "Jianmin Bao",
                        "affiliation": "Microsoft"
                    },
                    {
                        "name": "Jiawei Zhang",
                        "affiliation": "Sensetime"
                    },
                    {
                        "name": "Jiayi Ma",
                        "affiliation": "Wuhan University"
                    },
                    {
                        "name": "Jie Cao",
                        "affiliation": "Institute of automation, Chinese academy of science, Chinese Academy of Sciences"
                    },
                    {
                        "name": "Jindong Gu",
                        "affiliation": "University of Oxford"
                    },
                    {
                        "name": "Jinlong Yang",
                        "affiliation": "Max Planck Institute for Intelligent Systems, Max-Planck Institute; Google"
                    },
                    {
                        "name": "Josep Llados",
                        "affiliation": "Universitat Autónoma de Barcelona; Computer Vision Center, Universitat Autónoma de Barcelona"
                    },
                    {
                        "name": "Joseph Boyd",
                        "affiliation": "CentraleSupelec"
                    },
                    {
                        "name": "Juan Camilo Perez",
                        "affiliation": "KAUST"
                    },
                    {
                        "name": "Julian Ost",
                        "affiliation": "Princeton University; Algolux Inc"
                    },
                    {
                        "name": "Jyh-Jing Hwang",
                        "affiliation": "Waymo"
                    },
                    {
                        "name": "Kacper Kania",
                        "affiliation": "University of British Columbia; Warsaw University of Technology"
                    },
                    {
                        "name": "Karan Desai",
                        "affiliation": "University of Michigan"
                    },
                    {
                        "name": "Karsten Roth",
                        "affiliation": "University of Tuebingen"
                    },
                    {
                        "name": "Kashyap Chitta",
                        "affiliation": "Eberhard-Karls-Universität Tübingen"
                    },
                    {
                        "name": "Kevin J Liang",
                        "affiliation": "Meta"
                    },
                    {
                        "name": "Kewei Wang",
                        "affiliation": "Huazhong University of Science and Technology; Nanyang Technological University"
                    },
                    {
                        "name": "Kha Gia Quach",
                        "affiliation": "pdActive Inc."
                    },
                    {
                        "name": "Koki Nagano",
                        "affiliation": "NVIDIA"
                    },
                    {
                        "name": "Krystian Mikolajczyk",
                        "affiliation": "Imperial College London"
                    },
                    {
                        "name": "Kunal Swami",
                        "affiliation": "Indian Institute of Science; Samsung Research India Bangalore"
                    },
                    {
                        "name": "Kushal Kafle",
                        "affiliation": "Adobe Systems"
                    },
                    {
                        "name": "Li Chen",
                        "affiliation": "Shanghai AI Laboratory"
                    },
                    {
                        "name": "Li Niu",
                        "affiliation": "Shanghai Jiao Tong University"
                    },
                    {
                        "name": "Long Sun",
                        "affiliation": "Nanjing University of Science and Technology"
                    },
                    {
                        "name": "Luca Cosmo",
                        "affiliation": "University of Venice"
                    },
                    {
                        "name": "Luca Weihs",
                        "affiliation": "Allen Institute for Artificial Intelligence"
                    },
                    {
                        "name": "Lucas Beyer",
                        "affiliation": "Google Brain"
                    },
                    {
                        "name": "M. Saquib Sarfraz",
                        "affiliation": "Karlsruhe Institute of Technology"
                    },
                    {
                        "name": "M. Usman Rafique",
                        "affiliation": "Kitware Inc."
                    },
                    {
                        "name": "Mandi Luo",
                        "affiliation": "the Technology and Standards Research Institute, China Academy of Information and Communications Technology"
                    },
                    {
                        "name": "Marcel Buehler",
                        "affiliation": "Google; ETHZ - ETH Zurich"
                    },
                    {
                        "name": "Marco Cristani",
                        "affiliation": "Università degli Studi di Verona"
                    },
                    {
                        "name": "Marco Fumero",
                        "affiliation": "Sapienza University of Rome"
                    },
                    {
                        "name": "Marcus Rohrbach",
                        "affiliation": "Facebook"
                    },
                    {
                        "name": "Maria A Zuluaga",
                        "affiliation": "Eurecom; King's College London, University of London"
                    },
                    {
                        "name": "Mark Sheinin",
                        "affiliation": "Carnegie Mellon University"
                    },
                    {
                        "name": "Martin Weinmann",
                        "affiliation": "Karlsruher Institut für Technologie"
                    },
                    {
                        "name": "Mathis Petrovich",
                        "affiliation": "Max Planck Institute for Intelligent Systems, Max Planck Institute for Intelligent Systems; ENPC"
                    },
                    {
                        "name": "Matt Deitke",
                        "affiliation": "Allen Institute for Artificial Intelligence; Department of Computer Science, University of Washington"
                    },
                    {
                        "name": "Matteo Poggi",
                        "affiliation": "Università di Bologna"
                    },
                    {
                        "name": "Matteo Ruggero Ronchi",
                        "affiliation": "California Institute of Technology"
                    },
                    {
                        "name": "Matthew Chan",
                        "affiliation": "NVIDIA"
                    },
                    {
                        "name": "Melinos Averkiou",
                        "affiliation": "University of Cyprus; CYENS Centre of Excellence"
                    },
                    {
                        "name": "Mengtian Li",
                        "affiliation": "Waymo LLC"
                    },
                    {
                        "name": "Michael J. Black",
                        "affiliation": "University of Tübingen; Max Planck Institute for Intelligent Systems, Max-Planck Institute"
                    },
                    {
                        "name": "Michael Niemeyer",
                        "affiliation": "Google"
                    },
                    {
                        "name": "Michael Waechter",
                        "affiliation": "Meta, Inc."
                    },
                    {
                        "name": "Mina Ghadimi Atigh",
                        "affiliation": "University of Amsterdam"
                    },
                    {
                        "name": "Minesh Mathew",
                        "affiliation": "International Institute of Information Technology, Hyderabad"
                    },
                    {
                        "name": "Mingchen Zhuge",
                        "affiliation": "King Abdullah University of Science and Technology"
                    },
                    {
                        "name": "Mingdeng Cao",
                        "affiliation": "The University of Tokyo "
                    },
                    {
                        "name": "Muhammad Haris Khan",
                        "affiliation": "MBZUAI"
                    },
                    {
                        "name": "Mutian Xu",
                        "affiliation": "The Chinese University of Hong Kon"
                    },
                    "#VALUE!",
                    {
                        "name": "Nan Xue",
                        "affiliation": "Wuhan University"
                    },
                    {
                        "name": "Naoto Inoue",
                        "affiliation": "CyberAgent Inc."
                    },
                    {
                        "name": "Naveen Venkat",
                        "affiliation": "Runway AI, Inc."
                    },
                    {
                        "name": "Neal Wadhwa",
                        "affiliation": "Google"
                    },
                    {
                        "name": "Neel Dey",
                        "affiliation": "Massachusetts Institute of Technology"
                    },
                    {
                        "name": "Nico Lang",
                        "affiliation": "Copenhagen University"
                    },
                    {
                        "name": "Oleg Voynov",
                        "affiliation": "Skolkovo Institute of Science and Technology"
                    },
                    {
                        "name": "Orchid Majumder",
                        "affiliation": "Amazon Web Services"
                    },
                    {
                        "name": "Pablo Garrido",
                        "affiliation": "Flawless AI"
                    },
                    {
                        "name": "Paola Cascante-Bonilla",
                        "affiliation": "Rice University"
                    },
                    {
                        "name": "Paul Albert",
                        "affiliation": "Insight Centre for Data Analytics"
                    },
                    {
                        "name": "Peipei Li",
                        "affiliation": "Beijing University of Posts and Telecommunications"
                    },
                    {
                        "name": "Pirazh Khorramshahi",
                        "affiliation": "Johns Hopkins University; Qualcomm Inc, QualComm"
                    },
                    {
                        "name": "Piyush Nitin Bagad",
                        "affiliation": "University of Amsterdam"
                    },
                    {
                        "name": "Prateek Prasanna",
                        "affiliation": "State University of New York, Stony Brook"
                    },
                    {
                        "name": "Prithvijit Chattopadhyay",
                        "affiliation": "Georgia Institute of Technology"
                    },
                    {
                        "name": "Priyam Dey",
                        "affiliation": "Qualcomm Inc"
                    },
                    {
                        "name": "Qi Bi",
                        "affiliation": "University of Amsterdam"
                    },
                    {
                        "name": "Qiongjie Cui",
                        "affiliation": "Nanjing University of Science and Technology"
                    },
                    {
                        "name": "Relja Arandjelovic",
                        "affiliation": "DeepMind"
                    },
                    {
                        "name": "Renato Martins",
                        "affiliation": "Université de Bourgogne"
                    },
                    {
                        "name": "Richard J. Chen",
                        "affiliation": "Harvard University"
                    },
                    {
                        "name": "Rohan Chabra",
                        "affiliation": "Facebook"
                    },
                    {
                        "name": "Romain Brégier",
                        "affiliation": "Naver Labs Europe"
                    },
                    {
                        "name": "Ronghang Hu",
                        "affiliation": "Meta AI"
                    },
                    {
                        "name": "Rémi Pautrat",
                        "affiliation": "Swiss Federal Institute of Technology"
                    },
                    {
                        "name": "Samuele Salti",
                        "affiliation": "University of Bologna"
                    },
                    {
                        "name": "Samyak Jain",
                        "affiliation": "Indian Institute of Technolog"
                    },
                    "#VALUE!",
                    {
                        "name": "Sara Beery",
                        "affiliation": "Google; Massachusetts Institute of Technology"
                    },
                    {
                        "name": "Scott Wisdom",
                        "affiliation": "Google Research"
                    },
                    {
                        "name": "Seonwook Park",
                        "affiliation": "Lunit Inc."
                    },
                    {
                        "name": "Sergey Prokudin",
                        "affiliation": "ETHZ - ETH Zurich"
                    },
                    {
                        "name": "Shengcao Cao",
                        "affiliation": "University of Illinois at Urbana-Champaign"
                    },
                    {
                        "name": "Shengju Qian",
                        "affiliation": "The Chinese University of Hong Kong"
                    },
                    {
                        "name": "Shuai Yang",
                        "affiliation": "Nanyang Technological University"
                    },
                    {
                        "name": "Shuyang Gu",
                        "affiliation": "Research, Microsoft"
                    },
                    {
                        "name": "Simon Niklaus",
                        "affiliation": "Adobe Research"
                    },
                    {
                        "name": "Simone Melzi",
                        "affiliation": "University of Milan - Bicocca"
                    },
                    {
                        "name": "Simone Schaub-Meyer",
                        "affiliation": "TU Darmstadt"
                    },
                    {
                        "name": "Soonmin Hwang",
                        "affiliation": "CMU, Carnegie Mellon University"
                    },
                    {
                        "name": "Spyros Gidaris",
                        "affiliation": "Valeo.ai"
                    },
                    {
                        "name": "Stamatios Georgoulis",
                        "affiliation": "Huawei Technologies Ltd."
                    },
                    {
                        "name": "Stergios Christodoulidis",
                        "affiliation": "CentraleSupelec"
                    },
                    {
                        "name": "Suhas Lohit",
                        "affiliation": "Mitsubishi Electric Research Labs"
                    },
                    {
                        "name": "Sukrut Rao",
                        "affiliation": "Max Planck Institute for Informatics, Saarland Informatics Campus; Universität des Saarlandes"
                    },
                    {
                        "name": "Supasorn Suwajanakorn",
                        "affiliation": "Vidyasirimedhi Institute of Science and Technology"
                    },
                    {
                        "name": "Suvaansh Bhambri",
                        "affiliation": "Indian Institute of Science, Dhirubhai Ambani Institute Of Information and Communication Technology"
                    },
                    {
                        "name": "Taras Kucherenko",
                        "affiliation": "Electronic Arts"
                    },
                    {
                        "name": "Tatsunori Taniai",
                        "affiliation": "OMRON SINIC X"
                    },
                    {
                        "name": "Thomas Eboli",
                        "affiliation": "Ecole Normale Superieure"
                    },
                    {
                        "name": "Thomas Fel",
                        "affiliation": "Brown University"
                    },
                    {
                        "name": "Timo Bolkart",
                        "affiliation": "Amazon; Max Planck Institute for Intelligent Systems"
                    },
                    {
                        "name": "Tomas Jakab",
                        "affiliation": "University of Oxford"
                    },
                    {
                        "name": "Tomas Vojir",
                        "affiliation": "Czech Technical University of Prague"
                    },
                    {
                        "name": "Tony Ng",
                        "affiliation": "Imperial College London"
                    },
                    {
                        "name": "True Price",
                        "affiliation": "Meta"
                    },
                    {
                        "name": "Valentin Gabeur",
                        "affiliation": "Google; INRIA"
                    },
                    {
                        "name": "Vivien Sainte Fare Garnot",
                        "affiliation": "University of Zurich"
                    },
                    {
                        "name": "Weinan Song",
                        "affiliation": "University of California, Los Angeles"
                    },
                    {
                        "name": "Weiwei Sun",
                        "affiliation": "University of British Columbia"
                    },
                    {
                        "name": "Williem Williem",
                        "affiliation": "Verihubs"
                    },
                    {
                        "name": "Wouter Van Gansbeke",
                        "affiliation": "KU Leuven"
                    },
                    {
                        "name": "Xiaohan Ding",
                        "affiliation": "Tencent AI Lab"
                    },
                    {
                        "name": "Xiaohan Wang",
                        "affiliation": "Zhejiang University"
                    },
                    {
                        "name": "Xiaolong Li",
                        "affiliation": "Virginia Tech; Amazon"
                    },
                    {
                        "name": "Xiaoqing Guo",
                        "affiliation": "University of Oxford, University of Oxford"
                    },
                    {
                        "name": "Xiaoyang Wu",
                        "affiliation": "the University of Hong Kong, University of Hong Kong"
                    },
                    {
                        "name": "Xiaoyi Dong",
                        "affiliation": "Microsoft; University of Science and Technology of China"
                    },
                    {
                        "name": "Xin Lai",
                        "affiliation": "The Chinese University of Hong Kong"
                    },
                    {
                        "name": "Xintong Han",
                        "affiliation": "Huya Inc"
                    },
                    {
                        "name": "Xu Chen",
                        "affiliation": "Swiss Federal Institute of Technology"
                    },
                    {
                        "name": "Xu Ma",
                        "affiliation": "Northeastern University"
                    },
                    {
                        "name": "Xuan Bac Nguyen",
                        "affiliation": "University of Arkansas - Fayetteville"
                    },
                    {
                        "name": "Xucong Zhang",
                        "affiliation": "Delft University of Technology"
                    },
                    {
                        "name": "Yan Huang",
                        "affiliation": "Institute of automation, Chinese academy of science, Chinese Academy of Sciences"
                    },
                    {
                        "name": "Yan Zhao",
                        "affiliation": "Peking University"
                    },
                    {
                        "name": "Yang He",
                        "affiliation": "Amazon"
                    },
                    {
                        "name": "Yangyan Li",
                        "affiliation": "Alibaba Group"
                    },
                    {
                        "name": "Yannick Strümpler",
                        "affiliation": "Google"
                    },
                    {
                        "name": "Yasamin Jafarian",
                        "affiliation": "University of Minnesota - Twin Cities"
                    },
                    {
                        "name": "Yi Li",
                        "affiliation": "University of California, San Diego"
                    },
                    {
                        "name": "Yifan Liu",
                        "affiliation": "University of Adelaide"
                    },
                    {
                        "name": "Yihua Zhang",
                        "affiliation": "Michigan State University"
                    },
                    {
                        "name": "Yosuke Matsui",
                        "affiliation": "The University of Tokyo"
                    },
                    {
                        "name": "Yuanhao Cai",
                        "affiliation": "Shenzhen Internatioanl Graduate School, Tsinghua University"
                    },
                    {
                        "name": "Yumin Suh",
                        "affiliation": "NEC-Labs"
                    },
                    {
                        "name": "Yunzhong Hou",
                        "affiliation": "Australian National University"
                    },
                    {
                        "name": "Yutong Xie",
                        "affiliation": "University of Adelaide"
                    },
                    {
                        "name": "Zhan Tong",
                        "affiliation": "Tencent AI Lab"
                    },
                    {
                        "name": "Zheng Xu",
                        "affiliation": "Google"
                    },
                    {
                        "name": "Zhenzhi Wang",
                        "affiliation": "The Chinese University of Hong Kong"
                    },
                    {
                        "name": "Ziad Al-Halah",
                        "affiliation": "University of Texas at Austin"
                    },
                    {
                        "name": "Zikui Cai",
                        "affiliation": "University of California, Riverside"
                    },
                    {
                        "name": "Zixiang Zhao",
                        "affiliation": "Xi'an Jiaotong University"
                    },
                    {
                        "name": "Ziyi Wang",
                        "affiliation": "Tsinghua University, Tsinghua University"
                    },
                    {
                        "name": "Zuoyue Li",
                        "affiliation": "ETH Zürich"
                    }
                ],
                "All Reviewers": {}
            },
            "About ICML": {
                "introductions": [
                    "The International Conference on Machine Learning (ICML) is the premier gathering of professionals dedicated to the advancement of the branch of artificial intelligence known as machine learning.",
                    "ICML is globally renowned for presenting and publishing cutting-edge research on all aspects of machine learning used in closely related areas like artificial intelligence, statistics and data science, as well as important application areas such as machine vision, computational biology, speech recognition, and robotics.",
                    "ICML is one of the fastest growing artificial intelligence conferences in the world. Participants at ICML span a wide range of backgrounds, from academic and industrial researchers, to entrepreneurs and engineers, to graduate students and postdocs."
                ]
            }
        },
        "Schedule": [

        ],
        "Year(2023)": {
            "name": "ICML2023",
            "full name": "The Fortieth International Conference on Machine Learning",
            "date": "Sun Jul 23rd through Sat the 29th",
            "Twitter": "https://twitter.com/intent/tweet?text=Looking%20forward%20to%20the%20ICML%202023%20machine%20learning%20conference%20starting%20July%2017.",
            "location": "Hawaii Convention Center",
            "Registration": {
                "Pricing": {
                    "url": "https://icml.cc/Conferences/2023/Pricing",
                    "Choose your affiliation type and either Virtual Pass or a combination of Tutorials, Conference and Workshops.  A Virtual pass is included with any physical registration.": [
                        {
                            "Affiliation Type": "Full time student",
                            "Please check the events you wish to price ": "Tutorials",
                            "Early Student Tutorials Registration": "$50.00 USD",
                            "Student Tutorials Registration": "$65.00 USD"
                        },
                        {
                            "Affiliation Type": "Full time student",
                            "Please check the events you wish to price ": "Conference Sessions",
                            "Early Student Conference Sessions Registration": "$225.00 USD",
                            "Student Conference Sessions Registration": "$245.00 USD"
                        },
                        {
                            "Affiliation Type": "Full time student",
                            "Please check the events you wish to price ": "Workshops",
                            "Early Student Workshops Registration": "$200.00 USD",
                            "Student Workshops Registration": "$230.00 USD"
                        },
                        {
                            "Affiliation Type": "Full time student",
                            "Please check the events you wish to price ": " Virtual Pass",
                            "Early Student Virtual Pass Registration": "$40.00 USD",
                            "Student Virtual Pass Registration": "$40.00 USD"
                        },
                        {
                            "Affiliation Type": "Academic",
                            "Please check the events you wish to price ": "Tutorials",
                            "Early Academic Tutorials Registration": "$100.00 USD",
                            "Academic Tutorials Registration": "$130.00 USD"
                        },
                        {
                            "Affiliation Type": "Academic",
                            "Please check the events you wish to price ": "Conference Sessions",
                            "Early Academic Conference Sessions Registration": "$475.00 USD",
                            "Academic Conference Sessions Registration": "$500.00 USD"
                        },
                        {
                            "Affiliation Type": "Academic",
                            "Please check the events you wish to price ": "Workshops",
                            "Early Academic Workshops Registration": "$375.00 USD",
                            "Academic Workshops Registration": "$400.00 USD"
                        },
                        {
                            "Affiliation Type": "Academic",
                            "Please check the events you wish to price ": " Virtual Pass",
                            "Early Academic Virtual Pass Registration": "$165.00 USD",
                            "Academic Virtual Pass Registration": "$165.00 USD"
                        },
                        {
                            "Affiliation Type": "Industrial",
                            "Please check the events you wish to price ": "Tutorials",
                            "Early Industrial Tutorials Registration": "$150.00 USD",
                            "Industrial Tutorials Registration": "$165.00 USD"
                        },
                        {
                            "Affiliation Type": "Industrial",
                            "Please check the events you wish to price ": "Conference Sessions",
                            "Early Industrial Conference Sessions Registration": "$550.00 USD",
                            "Industrial Conference Sessions Registration": "$650.00 USD"
                        },
                        {
                            "Affiliation Type": "Industrial",
                            "Please check the events you wish to price ": "Workshops",
                            "Early Industrial Workshops Registration": "$450.00 USD",
                            "Industrial Workshops Registration": "$550.00 USD"
                        },
                        {
                            "Affiliation Type": "Industrial",
                            "Please check the events you wish to price ": " Virtual Pass",
                            "Early Industrial Virtual Pass Registration": "$195.00 USD",
                            "Industrial Virtual Pass Registration": "$195.00 USD"
                        }
                    ],
                    "*Full Time Student": "You must be a full time student in an accredited undergrad, masters or graduate program. You will be required to upload a digital version of your student ID at registration and to present your student ID as you check in. ",
                    "Industrial/Non-Academic": "If your expenses are being reimbursed by a corporation or other non-academic institution, please registration with Industrial pricing.",
                    "Opening Reception": "There will be an opening reception Monday, July 24th from at 6:15 -8:00 pm. The reception is available to anyone who has registered for at least one of the following: Tutorials, Conference Sessions, Workshops.",
                    "Opening Reception Guest Ticket": "If you are registered, you may bring a guest to the opening reception by buying a guest pass for $75.00 USD.",
                    "Affinity Workshops": "All registrations allow access to all Affinity Workshops.",
                    "Virtual Pass": "Virtual Pass includes virtual-only access to the live stream of the entire conference (tutorials, main conference, workshops) and the ability to interact using Rocket Chat. ",
                    "Registration Cancelation Policy": {
                        "introduction": "Registrations canceled before Jul 01, 2023 04:59 PM PDT or 01 weeks 02 days 21:09:48  Pacific time will receive a full refund. Refunds will be issued to your credit card and may take up to 10 business days to appear on your statement.  Registrations cannot be canceled or refunded after that time. Cancel instructions are on this page.",
                        "cancel instructions": {
                            "How to cancel my registration": [
                                "Click My Stuff\" in the navigation bar on the left.",
                                "Under Registration history click the current year.",
                                "Click 3. Payment and Receipt.",
                                "Click the red Cancel Registration button.",
                                "If you are before the Cancellation Deadline, you will get a full refund issued to your credit card. The refund can take 10 business days to post to your account. If you are after the Cancellation Deadline, you cannot get a refund."
                            ],
                            "How to cancel part of my registration": [
                                "Click My Stuff\" in the navigation bar on the left.",
                                "Under Registration history click the current year.",
                                "Click 2. Register and unselect the parts of your registration you want to cancel",
                                "Click the blue Payment button and follow the prompts.",
                                "If you are before the Cancellation Deadline, you will get a refund issued to your credit card. The refund can take 10 business days to post to your account. If you are after the Cancellation Deadline, you cannot get a refund."
                            ],
                            "How to switch from a in-person to a virtual registration": [
                                "Click My Stuff\" in the navigation bar on the left.",
                                "Under Registration history click the current year.",
                                "Click 2. Register",
                                "Unselect the in-person parts of your registration",
                                "click Virtual Only",
                                "Click the blue Payment button and follow the prompts.",
                                "If you are before the Cancellation Deadline, you will get a refund issued to your credit card. The refund can take 10 business days to post to your account. If you are after the Cancellation Deadline, you cannot get a refund."

                            ],
                            "How to switch from a virtual to a in-person": [
                                "Click My Stuff\" in the navigation bar on the left.",
                                "Under Registration history click the current year.",
                                "Click 2. Register",
                                "Unselect Virtual Only",
                                "click the in-persion sessions you want to attend",
                                "Click the blue Payment button and follow the prompts."
                            ],
                            "Cancellation Policy": {
                                "Registration Cancellation Policy": "Registrations canceled before Jul 01, 2023 04:59 PM PDT or 01 weeks 02 days 21:04:17  Pacific time will receive a full refund. Refunds will be issued to your credit card and may take up to 10 business days to appear on your statement.  Registrations cannot be canceled or refunded after that time. Cancel instructions are on this page.",
                                "Visa information for physical or hybrid conferences ": [
                                    "If your visa is denied before Jul 01, 2023 04:59 PM PDT or , you may cancel and refund your registration in the Payment and Receipt section of your registration for a full refund.",
                                    "After Jul 01, 2023 04:59 PM PDT or : You can still get a refund if you applied for your visa before May 4, 2023, and you are unable to attend because your visa was denied or you have not received a response. You must submit your  refund requests using our contact form within one week of the close of the meeting and include documentation showing a visa denial."
                                ]
                            },
                            "Contact": {
                                "Contact ICML": [
                                    "Use the form below to direct your question to the appropriate team",
                                    "Please check our FAQ for answers to many common questions"
                                ],
                                "FAQ(url)": "https://icml.cc/FAQ",
                                "Address": {
                                    "Attn": "Terri Auricchio",
                                    "location": "1269 Law Street San Diego, CA 92109",
                                    "Phone": "702-743-1827",
                                    "Email": "terri@icml.cc"
                                },
                                "Privacy Policy(url)": "https://icml.cc/public/PrivacyPolicy"

                            }
                        }
                    },
                    "Registrations are not transferrable.": "Registrations are linked to immigration documents, tax documents and credit card transactions and cannot be transferred to another person.",
                    "Visa information for physical or hybrid conferences ": [
                        "If your visa is denied before Jul 01, 2023 04:59 PM PDT or , you may cancel and refund your registration in the Payment and Receipt section of your registration for a full refund.",
                        "After Jul 01, 2023 04:59 PM PDT or : You can still get a refund if you applied for your visa before May 4, 2023, and you are unable to attend because your visa was denied or you have not received a response. You must submit your  refund requests using our contact form within one week of the close of the meeting and include documentation showing a visa denial.",
                        "Early pricing ends in 00 weeks 00 days 00:00:00 on June 17, 2023, 2:59 p.m. pacific time.",
                        "until the cancellation deadline."
                    ]
                },
                "Registration 2023(url)": "https://icml.cc/Register/view-registration",
                "Hotels(url)": "https://book.resiada.com/ICML2023",
                "Registration Cancelation Policy(url)": "https://icml.cc/FAQ/CancellationPolicy",
                "Linked": "https://www.linkedin.com/company/icmlconf/"
            },
            "Announcements": {
                "EXPO Raffle": "Attend the EXPO talks on Sunday for a chance to win prizes announced at the Monday Welcome Reception.",
                "Change in Location": "ICML 2023 has changed locations and will now be held in Honolulu, Hawai'i from July 23rd - July 29th. After much consideration, this change was made in light of uncertainty regarding COVID-19 and its possible implications on travel, attendance, and financial consequences. We look forward to holding the conference in Seoul in 2026, after Vienna in 2024 and Vancouver in 2025."
            },
            "Change in Location:": "ICML 2023 has changed locations and will now be held in Honolulu, Hawai'i from July 23rd - July 29th. After much consideration, this change was made in light of uncertainty regarding COVID-19 and its possible implications on travel, attendance, and financial consequences. We look forward to holding the conference in Seoul in 2026, after Vienna in 2024 and Vancouver in 2025.",
            "Exhibitors": {
                "introduction": [
                    "The generous support of our exhibitors allowed us to reduce our ticket prices and support diversity at the meeting with financial awards. In addition, many accepted papers at the conference were contributed by our exhibitors.",
                    "Currently, we are planning on ICML 2023 being a physical conference with some streaming elements.",
                    "Exhibitor applications are now open.",
                    "For the first time in ICML’s forty year history, we are offering additional sponsorship opportunities. This is an exciting new program exclusively offered to our current exhibitors. For contract and logistics information please email us directly."
                ],
                "2023 Exhibitors": {
                    "DIAMOND": [
                        "CITADEL Securities",
                        "Google Research"
                    ],
                    "Platinum": [
                        "Microsoft",
                        "Jane Street",
                        "Apple",
                        "DeShaw&Co",
                        "Colossal-AI",
                        "Google DeepMind"
                    ],
                    "GOLD": "Lambda",
                    "SILVER": [
                        "mosaicML",
                        "FriendliAI",
                        "CapitalOne",
                        "YOKOGAWA",
                        "Point72",
                        "Cubist",
                        "TikTok",
                        "SONY",
                        "PDT PARTNERS",
                        "SQUARE POINT",
                        "AI INIT",
                        "DVC",
                        "TWO SIGMA",
                        "cerebras",
                        "Baidu",
                        "DE Shaw Research",
                        "Meta AI"
                    ],
                    "Bronze": [
                        "quantco",
                        "CHEN INSTITUTE"
                    ],
                    "Book Publisher": [
                        "Intelligent Computing",
                        "Imperial College London",
                        "translated",
                        "COCALC"
                    ]
                }
            },
            "Important Dates": {
                "Expo (Industry) Day": "Sun July 23rd",
                "Tutorials": "Mon Jul 24th",
                "Conference Sessions": "Tue Jul 25th through Thu the 27th",
                "Workshops": "Fri Jul 28th through Sat the 29th",
                "Virtual Pass": "Sun Jul 23rd through Sat the 29th",
                "Registration Open": "Feb 03 '23 04:00 AM HST *",
                "Paper Decision notification": "Apr 24 '23 (Anywhere on Earth)",
                "Tutorial Proposal Announcements": "May 12 '23 (Anywhere on Earth)",
                "Camera-ready version deadline": "May 31 '23 (Anywhere on Earth)",
                "Social Deadline Date": "Jun 11 '23 (Anywhere on Earth)",
                "Early pricing before this date": "Jun 16 '23 08:59 PM HST *",
                "Social Notification Date": "Jun 18 '23 (Anywhere on Earth)",
                "Poster Printing Deadline": "Jun 22 '23 (Anywhere on Earth)",
                "Volunteer Available Dates Due": "Jun 22 '23 (Anywhere on Earth)",
                "SlidesLive Video Upload Deadline": "Jun 29 '23 (Anywhere on Earth)",
                "Last chance for a refund on registration fees": "Jul 01 '23 01:59 PM HST *"
            }
        },
        "Help": {
            "FAQ": {
                "Frequently Asked Questions": {
                    "Accounts": [
                        {
                            "question": "How to I create an ICML.cc account?",
                            "answer(url)": "https://icml.cc/FAQ/01Create-Account"
                        },
                        {
                            "question": "Where are unicode characters allowed?",
                            "answer(url)": "https://icml.cc/FAQ/UnicodeCharacters"
                        },
                        {
                            "question": "How do I reset my ICML.cc password?",
                            "answer(url)": "https://icml.cc/FAQ/04-Forgot-ICML-password"
                        },
                        {
                            "question": "I already have an account, but the system says I do not.",
                            "answer(url)": "https://icml.cc/FAQ/AccountButNoPassword"
                        },
                        {
                            "question": "How do I change my email address?",
                            "answer(url)": "https://icml.cc/FAQ/ChangeEmailAddress"
                        },
                        {
                            "question": "I have two icml.cc accounts, can they be merged?",
                            "answer(url)": "https://icml.cc/FAQ/MergeAccounts"
                        },
                        {
                            "question": "Why I am no longer receiving email from icml.cc?",
                            "answer(url)": "https://icml.cc/FAQ/WhyNoEmails"
                        },
                        {
                            "question": "I do not see all my events or papers, where are they?",
                            "answer(url)": "https://icml.cc/FAQ/MissingPapers"
                        }
                    ],
                    "At the Conference": [
                        {
                            "question": "Badge Replacement Policy",
                            "answer(url)": "https://icml.cc/FAQ/BadgeReplacementPolicy"
                        },
                        {
                            "question": "Baggage Check",
                            "answer(url)": "https://icml.cc/FAQ/BaggageCheck"
                        },
                        {
                            "question": "Lost and Found",
                            "answer(url)": "https://icml.cc/FAQ/LostAndFound"
                        },
                        {
                            "question": "Safety at the Conference",
                            "answer(url)": "https://icml.cc/FAQ/Safety"
                        }
                    ],
                    "Credit Card Payments": [
                        {
                            "question": "How is my credit card information protected?",
                            "answer(url)": "https://icml.cc/FAQ/CreditCardSecurity"
                        },
                        {
                            "question": "Where is my refund credit card?",
                            "answer(url)": "https://icml.cc/FAQ/CreditCardRefund"
                        },
                        {
                            "question": "Why was my credit card payment declined?",
                            "answer(url)": "https://icml.cc/FAQ/CreditCardDeclined"
                        }
                    ],
                    "Papers": [
                        {
                            "question": "Paper Copyrights",
                            "answer(url)": "https://icml.cc/FAQ/Copyright"
                        },
                        {
                            "question": "Required Author Registration",
                            "answer(url)": "https://icml.cc/FAQ/Author-Registration"
                        }
                    ],
                    "Posters": [
                        {
                            "question": "Poster Instructions",
                            "answer(url)": "https://icml.cc/FAQ/PosterInstructions"
                        }
                    ],
                    "Registration": [
                        {
                            "question": "Cancellation Policy",
                            "answer(url)": "https://icml.cc/FAQ/CancellationPolicy"
                        },
                        {
                            "question": "How do I cancel or change my registration?",
                            "answer(url)": "https://icml.cc/FAQ/CancelRegistration"
                        },
                        {
                            "question": "How do I get an updated Receipt/Invoice",
                            "answer(url)": "https://icml.cc/FAQ/Receipt"
                        },
                        {
                            "question": "Registration Discounts for Students",
                            "answer(url)": "https://icml.cc/FAQ/FullTimeStudent"
                        },
                        {
                            "question": "Transfer Policy",
                            "answer(url)": "https://icml.cc/FAQ/TransferRegistration"
                        }
                    ],
                    "Travel and Attendance Documents": [
                        {
                            "question": "Does ICML issue PE Certificates for India?",
                            "answer(url)": "https://icml.cc/FAQ/IndiaPECertificate"
                        },
                        {
                            "question": "How do get a Visa Letter of Invitation?",
                            "answer(url)": "https://icml.cc/FAQ/VISALetterOfInvitation"
                        },
                        {
                            "question": "How to I get a certificate of attendance?",
                            "answer(url)": "https://icml.cc/FAQ/CertificateOfAttendance"
                        }
                    ]
                }
            },
            "Conference Help(url)": "https://wiki.eventhosts.cc/",
            "Contact ICML": {
                "Contact ICML": [
                    "Use the form below to direct your question to the appropriate team",
                    "Please check our FAQ for answers to many common questions"
                ],
                "FAQ(url)": "https://icml.cc/FAQ",
                "Address": {
                    "Attn": "Terri Auricchio",
                    "location": "1269 Law Street San Diego, CA 92109",
                    "Phone": "702-743-1827",
                    "Email": "terri@icml.cc"
                },
                "Privacy Policy(url)": "https://icml.cc/public/PrivacyPolicy"
            },
            "About ICML": [
                "The International Conference on Machine Learning (ICML) is the premier gathering of professionals dedicated to the advancement of the branch of artificial intelligence known as machine learning.",
                "ICML is globally renowned for presenting and publishing cutting-edge research on all aspects of machine learning used in closely related areas like artificial intelligence, statistics and data science, as well as important application areas such as machine vision, computational biology, speech recognition, and robotics.",
                "ICML is one of the fastest growing artificial intelligence conferences in the world. Participants at ICML span a wide range of backgrounds, from academic and industrial researchers, to entrepreneurs and engineers, to graduate students and postdocs."
            ],
            "Create an Account": [
                "Your email address is your username",
                "Recover and update an existing account rather than creating a new one.",
                "If you need a new account, use the form below to create an account. An email will be sent with further instructions."
            ],
            "Reset Password": {
                "Password Reset ": "To reset or your password, please enter the email address you use to login to https://ICML.cc. If you have multiple ICML accounts, and you are not sure which of your email addresses is your active ICML.cc login, enter them all, one per line (max of 5) and we will send a password reset email to the active one. We cannot recover a password; we can only reset one. ",
                "If you need help, please visit our Contact page.(url)": "https://icml.cc/Help/Contact"
            },
            "Merge Profiles": "Use this page to merge an older or unneeded account into the account you're currently logged into.If you are not logged into the correct account, Change Users. When you press Request Email Merge, your older account will be sent an email with a link and instructions on how to complete the merge. If you no longer have access to the email of your older account, press Request Manual Merge, and a ICML staff member member will merge your account for you. ",
            "Privacy Policy": {
                "Information We Collect and How We Use It": "We collect certain information from you through your use of the Website, such as the information you provide to ICML by registering for a user account. ",
                "Information You Provide to Us": [
                    "When you use the ICML Website to register a user account, limited information is collected about you through a form. This information is for the purpose of identifying and communicating with you as supporters, conference registrants and community members.",
                    "We may need to send you announcements and account-related messages. These will be sent through the Website or by email."
                ],
                "We will not share the personal information we have collected from you, except as described below": [
                    "when you agree to share your information with our sponsors during registration in the Jobs and Recruitment section.",
                    "when auditing our books, your information may be shared temporarily with our partners in a very limited scope.",
                    "when we believe we are authorized or legally required to do so or that doing so is necessary or appropriate to comply with the law or legal processes or respond to lawful requests or legal authorities, including things like subpoenas, warrants or court orders.",
                    "to enforce or apply our Privacy Policy, our Terms of Use or our other policies or agreements.",
                    "if your company is one of our sponsors. Some sponsors have access to a report that shows who from their company is attending (including email addresses), what they've registered for, and what they are presenting. A sponsor can only see information for their own employees.",
                    "to facilitate and support visa applications, we may share a list of current year registrations with the immigration office of the current year host government",
                    "meeting organizers have access to user profile information to facilitate building the schedule, and communicating with speakers and presenters"

                ],
                "Accessing Your Information": "If you would like ICML to delete your personal information that has been collected, please contact us with your request. ",
                "How We Protect Your Information": "We employ administrative, physical, and electronic measures designed to protect your information from unauthorized access. However, despite those efforts, no security measures are perfect or impenetrable. ",
                "Links to Other Sites": "The ICML Website may contain links to other services, apps, and sites not operated by us (we refer to these as Other Sites). Any information you provide on those Other Sites is provided directly to the owner of that site. Our Privacy Policy does not apply to those Other Sites, and we are not responsible for the content you provide to, or the privacy and security practices and policies of, Other Sites. CMT and OpenReview are examples of Other Sites. ",
                "Changes to Our Privacy Policy": "Any information that is collected is subject to our Privacy Policy in effect at the time such information is collected. We may, however, modify and revise our Privacy Policy from time-to-time. In the event of a modification to the Privacy Policy, ICML will send notification to you that a change has occurred via the Website or Email. It is required that you accept the revised Privacy Policy before continuing to use the Website. By accepting changes to the policy, you are agreeing to be bound by the revised policy. ",
                "Questions or Concerns": "Please contact us if you have any questions or concerns about our Privacy Policy. "
            }
        },
        "My Stuff/Registrations(url)": "https://icml.cc/MyStuff",
        "Profile": {
            "Edit Profile(url)": "https://icml.cc/EditProfile",
            "Change Password(url)": "https://icml.cc/Profile/change-password",
            "Merge Profiles": {
                "Merge Accounts": "Use this page to merge an older or unneeded account into the account you're currently logged into. If you are not logged into the correct account, Change Users. When you press Request Email Merge, your older account will be sent an email with a link and instructions on how to complete the merge. If you no longer have access to the email of your older account, press Request Manual Merge, and a ICML staff member member will merge your account for you. ",
                "Change Users(url)": "https://icml.cc/logout?next=/MergeAccounts"
            },
            "Create New Profile": {
                "url": "https://icml.cc/Profile/create",
                "Create Profile": [
                    "Your email address is your username",
                    "Recover and update an existing account rather than creating a new one.",
                    "If you need a new account, use the form below to create an account. An email will be sent with further instructions."
                ]
            },
            "Reset Password": {
                "Password Reset ": "To reset or your password, please enter the email address you use to login to https://ICML.cc. If you have multiple ICML accounts, and you are not sure which of your email addresses is your active ICML.cc login, enter them all, one per line (max of 5) and we will send a password reset email to the active one. We cannot recover a password; we can only reset one. ",
                "If you need help, please visit our Contact page.(url)": "https://icml.cc/Help/Contact"
            },
            "Log in(url)": "https://icml.cc/accounts/login?nextp=/",
            "Log out": {}
        },
        "Exhibitor Info": {
            "title": "Exhibitor Information for ICML 2023",
            "Exhibitor Floor Plan(url)": "https://media.icml.cc/Conferences/ICML2023/ICML2023-Exhibit.pdf",
            "View ICML 2023 Exhibitors": {
                "DIAMOND": [
                    "CITADEL Securities",
                    "Google Research"
                ],
                "Platinum": [
                    "Microsoft",
                    "Jane Street",
                    "Apple",
                    "DeShaw&Co",
                    "Colossal-AI",
                    "Google DeepMind"
                ],
                "GOLD": "Lambda",
                "SILVER": [
                    "mosaicML",
                    "FriendliAI",
                    "CapitalOne",
                    "YOKOGAWA",
                    "Point72",
                    "Cubist",
                    "TikTok",
                    "SONY",
                    "PDT PARTNERS",
                    "SQUARE POINT",
                    "AI INIT",
                    "DVC",
                    "TWO SIGMA",
                    "cerebras",
                    "Baidu",
                    "DE Shaw Research",
                    "Meta AI"
                ],
                "Bronze": [
                    "quantco",
                    "CHEN INSTITUTE"
                ],
                "Book Publisher": [
                    "Intelligent Computing",
                    "Imperial College London",
                    "translated",
                    "COCALC"
                ]
            },
            "introduction": [
                "Exhibitor payments are due Jun 23, 2023 06:00 PM PDT or 00 weeks 01 days 08:34:38 (anywhere on earth).",
                "Read the information below and then",
                "The International Conference on Machine Learning is globally renowned for presenting and publishing cutting-edge research on all aspects of machine learning used in closely related areas like artificial intelligence, statistics and data science, as well as important application areas such as machine vision, computational biology, speech recognition, and robotics. ICML is the premier academic conference in the branch of artificial intelligence known as machine learning.",
                "ICML exhibitors have been critical in ensuring the continued success of the conference. Most importantly, exhibitor funds make it possible for students to attend and present their research. Due to our exhibitors’ generosity we’ve been able to offer grant awards to many students across the world. It is our goal to replicate that success again this year. We are pleased to announce that we will join in-person Sun Jul 23rd through Sat the 29th in Honolulu, Hawai‘i.",
                "The EXPO is a potential opportunity for your company to give a talk, panel discussion, workshop, or demonstration. Diamond and Platinum exhibitor levels may apply in their exhibitor portal. The EXPO will take place on Sunday, July 23rd.",
                "Every exhibitor will have 20% of their funds directed to the need-based program to support hotel, food, and registration costs for those in financial need, particularly graduate students and Diversity, Equality and Inclusion efforts. Additionally, each exhibitor will receive access to the opt-in recruitment database.",
                "Thank you for your consideration to support ICML 2023.",
                "When you are ready, please Enter the Exhibitor - Sponsor Portal to begin the application process."
            ],
            "Exhibitor - Sponsor Portal": [
                "To become an Exhibitor at ICML 2023, please review and complete each section below.",
                "1. Review exhibitor level",
                "2. Complete “Your Information” in portal",
                "3. Add available times for the onboarding meeting",
                "4. “Send Invoice” from portal",
                "5. Upload signed contract in portal or send via email",
                "6. Send Payment. Due by June 23, 2023",
                "7. Upload your proof of insurance (COI), or purchase it from RainProtection",
                "8. Assign Exhibitor and Full Access Badges in portal",
                "Upon receipt of the signed contract and payment, your company description and logo will be posted to the ICML website. At this point, you will also have access to the recruitment database and complimentary registrations.",
                "The EXPO is a potential opportunity for your company to give a talk, panel discussion, workshop, or demonstration. Diamond and Platinum exhibitor levels may apply by clicking on the ICML Expo Day Application tab below. The EXPO will take place on Sun Jul 23, 2023.",
                "See Exhibitor Info for venue information on setup, hours, shipping and customs, contractors, service providers, and badges.",
                "For the first time in ICML’s forty year history, we are offering additional sponsorship opportunities. This is an exciting new program exclusively offered to our current exhibitors. For contract and logistics information please email us directly.",
                "Exhibitor Questions: Terri Auricchio or Stephanie Willes",
                "Technical Help: Brad Brockmeyer or Max Wiesner"
            ],
            "Exhibitor Levels": {
                "Diamond": {
                    "money": "$100,000 USD",
                    "treatment": [
                        "20’ x 20’ island booth space; standard IAEE regulations",
                        "Access to ICML Recruitment Database",
                        "Dedicated interview room by reservation",
                        "Recruitment row space in exhibit hall (draped rooms included)",
                        "Complimentary: (20) full-access registrations; (20) exhibitor booth badges",
                        "Acknowledgement at the opening reception",
                        "Company logo on website with link and on welcome units",
                        "EXPO – opportunity to apply to give a talk, workshop, or demonstration"
                    ]
                },
                "Platinum": {
                    "money": "$80,000 USD",
                    "treatment": [
                        "20’ x 20’ island booth space; standard IAEE regulations -Access to ICML Recruitment Database",
                        "Dedicated interview room",
                        "Recruitment row space in exhibit hall (draped rooms included)",
                        "Complimentary:(16) full-access registrations; (15) exhibitor booth badges",
                        "Acknowledgement at the opening reception",
                        "Company logo on website with link and on welcome units",
                        "EXPO – opportunity to apply to give a talk, workshop, or demonstration"
                    ]
                },
                "Gold": {
                    "money": "$50,000 USD",
                    "treatment": [
                        "1:1 Turnkey includes 8’x 10’ space, graphic kiosk w/counter, monitor, installation and dismantle",
                        "Access to ICML Recruitment Database",
                        "Recruitment row space in exhibit hall (draped rooms included)",
                        "Complimentary: (8) full-access registrations; (3) exhibitor booth badges",
                        "Acknowledgement at the opening reception",
                        "Company logo on website with link and on welcome units"
                    ]
                },
                "Silver": {
                    "money": "$20,000 USD",
                    "treatment": [
                        "10’ x 10’ booth space; standard IAEE regulations",
                        "Access to ICML Recruitment Database",
                        "Recruitment row space in exhibit hall (draped rooms included)",
                        "Complimentary:(4) full-access registrations; (3) exhibitor booth badges",
                        "Acknowledgement at the opening reception",
                        "Company logo on website with link and on welcome units"
                    ]
                },
                "Bronze": {
                    "money": "$12,000 USD",
                    "treatment": [
                        "6’ table top in shared space",
                        "Access to ICML Recruitment Database",
                        "Recruitment row space in exhibit hall (draped rooms included)",
                        "Complimentary:(2) full-access registrations; (2) exhibitor booth badges",
                        "Acknowledgement at the opening reception",
                        "Company logo on website with link and on welcome units"
                    ]
                },
                "Book Publisher": {
                    "money": "$1,000 USD",
                    "treatment": [
                        "10’ x 10’ booth space with table and chair",
                        "(1) exhibitor booth badge",
                        "Acknowledgement at the opening reception",
                        "Company logo on website with link and on welcome units"
                    ]
                }
            },
            "Venue Information": {
                "Setup, Exhibit Hours and Teardown": {
                    "Install": [
                        "Sat, July 22 8:00am-5:00pm",
                        "Sun, July 23 8:00am-12:00pm"
                    ],
                    "Exhibit Hall Hours": [
                        "Sun, July 23 2:00pm-6:00pm",
                        "Mon, July 24 10:00am-8:00pm *40th Anniversary Reception 6:15 PM",
                        "Tue, July 25 10:00am-6:00pm",
                        "Wed, July 26 10:00am-6:00pm"
                    ],
                    "Move Out": [
                        "Wed, July 26 6:00pm-9:00pm",
                        "Thu, July 27 8:00am-2:00pm"
                    ]
                },
                "Shipping & Customs Information": [
                    "SHIPPING INFORMATION IS AVAILABLE IN THE SERVICE KIT                                                                                                    June 8 - July 18 | Advance Shipment: (Exhibiting Company Name) (Booth #)",
                    "For: International Conf on Machine Learning c/o: T3 Expo / ICS",
                    "1004 Makepono St. Bldg A, Honolulu, HI 96819",
                    "July 22 | Direct to Show Site: (Exhibiting Company Name) (Booth #)",
                    "International Conference on Machine Learning c/o: T3 Expo / Hawaii Convention Center",
                    "Hall III, 1801 Kalakaua Avenue Honolulu, HI 96815",
                    "CARRIER & CUSTOMS: AIRWAYS FREIGHT AIRWAYS FREIGHT EMAIL USA PHONE INTL PHONE"
                ],
                "Exclusive Service Providers & Designated Official Contractors": [
                    "T3Expo is the Official Services Contractor. This year T3Expo has turnkey options available to help support sustainability. Exhibitor Service Kit",
                    "Island booths will be permitted to use hanging signs."
                ],
                "Exhibitor Appointed Contractors (EACs)": {},
                "Exhibitor Badges": {}
            }
        },
        "Contact ICML": {
            "Contact ICML": [
                "Use the form below to direct your question to the appropriate team",
                "Please check our FAQ for answers to many common questions"
            ],
            "FAQ(url)": "https://icml.cc/FAQ",
            "Address": {
                "Attn": "Terri Auricchio",
                "location": "1269 Law Street San Diego, CA 92109",
                "Phone": "702-743-1827",
                "Email": "terri@icml.cc"
            },
            "Privacy Policy(url)": "https://icml.cc/public/PrivacyPolicy"
        },
        "ICML Code of Conduct": {
            "introduction": "The open exchange of ideas, the freedom of thought and expression, and respectful scientific debate are central to the goals of this conference on machine learning; this requires a community and an environment that recognizes and respects the inherent worth of every person.",
            "Who": "All participants---attendees, organizers, reviewers, speakers, sponsors, and volunteers at our conference, workshops, and conference-sponsored social events---are required to agree with this code of conduct both during the event and on official communication channels, including social media. Organizers will enforce this code, and we expect cooperation from all participants to help ensure a safe and productive environment for everybody.",
            "Scope": [
                "The conference commits itself to providing an experience for all participants that is free from harassment, bullying, discrimination, and retaliation for all participants. This includes offensive comments related to gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion (or lack thereof), politics, technology choices, or any other personal characteristics. Bullying, intimidation, personal attacks, harassment, sustained disruption of talks or other events, and behavior that interferes with another's full participation will not be tolerated. This includes sexual harassment, stalking, following, harassing photography or recording, inappropriate physical contact, unwelcome sexual attention, public vulgar exchanges, and diminutive characterizations, which are all unwelcome in this community.",
                "This Code of Conduct applies to the actual meeting sites and conference venues where ICML business is being conducted, including both physical and official virtual engagement platforms, including video, virtual streaming, and chat-based interaction. ICML is not responsible for non-sponsored activity or behavior that may occur at non-sponsored locations such as hotels, restaurants, or locations not otherwise a sanctioned space for ICML sponsored events (including virtual spaces). ICML will not actively monitor social media platforms, but will follow up on issues of harassment and violations of the code of conduct that occur on those platforms that are specifically related to the ICML program, during the course of ICML, if and when they are brought to our attention.",
                "Sponsors are equally subject to this Code of Conduct. In particular, sponsors should not use images, activities, or other materials that are of a sexual, racial, or otherwise offensive nature. Booth staff (including volunteers) should not use sexualized clothing/uniforms/costumes, or otherwise create a sexualized environment. This code applies both to official sponsors as well as any organization that uses the conference name as branding as part of its activities at or around the conference."
            ],
            "Outcomes": "Participants asked by any member of the community to stop any such behavior are expected to comply immediately. If a participant engages in such behavior, the conference organizers may take any action they deem appropriate, including: a formal or informal warning to the offender, expulsion from the conference with no refund, barring from participation in future conferences or their organization, reporting the incident to the offender’s local institution or funding agencies, or reporting the incident to local law enforcement. A response of just joking will not be accepted; behavior can be harassing without an intent to offend. If action is taken, an appeals process will be made available.",
            "Reporting": [
                "If you have concerns related to your inclusion at that conference, or observe someone else's difficulties, or have any other concerns related to inclusion, please contact the Diversity and Inclusion co-chairs or the Conference HR Liaison.",
                "The Diversity and Inclusion co-chairs can be reached by email at diversity-chairs@icml.cc. The HR Liaison can be reached via the ICML Hotline at either ICMLhotline@gmail.com or 858-208-3810. Conference volunteers will also have this contact information and can assist with connecting you to the co-chairs or the HR Liaison. Complaints and violations will be handled at the discretion of the Diversity & Inclusion co-chairs, general chair, HR Liaison, and the conference board. Reports made during the conference will be responded to in less than 24 hours; those at other times in less than two weeks. We are prepared and eager to help participants contact relevant help services, to escort them to a safe location, or to otherwise assist those experiencing harassment to feel safe for the duration of the conference. We gratefully accept feedback from the community on policy and actions; please contact us."
            ]
        },
        "Journal to Conference Track": {
            "The NeurIPS/ICLR/ICML Journal-to-Conference Track": [
                "The Boards of machine learning conferences NeurIPS, ICLR and ICML have jointly agreed on experimenting with a new Journal-to-Conference track, through which the authors of published journal papers at selected journals would be given the opportunity to present their work at one of these 3 conferences, of their choosing. This initiative is inspired by the Transactions of the Association for Computational Linguistics (TACL) of the NLP community, where published papers are eligible for presentation at sponsoring NLP conferences.",
                "As an initial experiment, this track will be considering published papers from the Journal of Machine Learning Research (JMLR), for presentation at NeurIPS 2022, ICLR 2023, ICML 2023, NeurIPS 2023 and ICLR 2024. "
            ],
            "Eligibility": [
                "Eligible papers must:",
                "Have been published at JMLR no earlier than January 1st 2022. ",
                "Moving forward, the eligibility year will increase by 1 year on January 1st of each year, so that the eligibility period is of at most 2 years since publication.",
                "Not contain contributions that have already been published at a conference by the same authors. In other words, the journal paper cannot be an extension of a previous conference publication.",
                "This first cycle of 3 top ML conferences will be used to gather experience with this format and determine whether and how future cycles for this track should continue."
            ],
            "Request to present": {
                "To request a presentation, the author of an eligible JMLR published paper must submit their request through the following form:": "https://forms.gle/7baKjVfyaqPWp1nN6 ",
                "if for some reason you are not able to use this form, you may email us at": "journaltoconferencetrack@gmail.com",
                "Each conference has its own deadline for receiving requests, as follows": [
                    {
                        "conference": "NeurIPS 2022",
                        "deadline": "September 8th 2022"
                    },
                    {
                        "conference": "ICLR 2023",
                        "deadline": "January 13th 2023"
                    },
                    {
                        "conference": "ICML 2023",
                        "deadline": "April 24th 2023"
                    },
                    {
                        "conference": "NeurIPS 2023",
                        "deadline": "September 24th 2023"
                    },
                    {
                        "conference": "ICLR 2024",
                        "deadline": "TBD"
                    }
                ],
                "For more information, see the FAQ below or reach out to us at": "journaltoconferencetrack@gmail.com",
                "writer": "Barbara Engelhardt, Hugo Larochelle, Naila Murray",
                "affiliation": [
                    "Oversight Committee",
                    "NeurIPS/ICLR/ICML Journal to Conference Track"
                ],
                "FAQ": [
                    {
                        "Q": "Which journal(s) are eligible? ",
                        "A": "Only JMLR. This includes JMLR MLOSS (Machine Learning Open Source Software)."
                    },
                    {
                        "Q": "Does this track accept journal papers that are extensions of a previous conference publication by the same authors?",
                        "A": "No."
                    },
                    {
                        "Q": "How old can eligible journal papers be?",
                        "A": "The paper must have been published by JMLR no earlier than January 1st 2022."
                    },
                    {
                        "Q": "What is the deadline to submit a request to present at a chosen conference: ",
                        "A": [
                            "The deadlines are specific to each conference and are as follows:",
                            "NeurIPS 2022: September 8th 2022",
                            "ICLR 2023: January 13th 2023",
                            "ICML 2023: April 24th 2023",
                            "NeurIPS 2023: September 24th 2023",
                            "ICLR 2024: TBD"
                        ]
                    },
                    {
                        "Q": "Will the paper be included in the chosen conference’s proceedings?",
                        "A": "No. This track only provides an additional opportunity to present the work. It shall not be considered as being published in the proceedings of the chosen conference."
                    },
                    {
                        "Q": "Do I have to submit a version of the journal paper in the conference’s publication style format? ",
                        "A": "No. We will only require the journal in its JMLR paper format."
                    },
                    {
                        "Q": "The journal has confirmed my paper is accepted by email, however the paper doesn't yet appear in the proceedings. Can I still submit a request?",
                        "A": "No. We require that you provide a valid and working link to the PDF of your paper from the journal's proceedings site."
                    },
                    {
                        "Q": "What type of presentation will be provided by the chosen conference? ",
                        "A": "Generally, the presentation offered will follow the format of a typical poster presentation at the chosen conference. The exact session that will include the presentation will be decided by each conference committee while creating the conference program."
                    },
                    {
                        "Q": "What is the review process, how are papers selected?",
                        "A": "There is no further peer review done on submitted papers; they are only checked to ensure they meet the eligibility criteria (see Eligibility above)."
                    },
                    {
                        "Q": "May the deadline be extended / can I request a deadline extension?",
                        "A": "No; the deadline is already as late as possible (for venue planning, visa purposes etc.) and is firm. Extensions will not be made for any reason."
                    }
                ]
            }
        },
        "Future Meetings": [
            {
                "meeting name": "ICML 2023",
                "location": "Honolulu, Hawai'i, USA"
            },
            {
                "meeting name": "ICML 2024",
                "location": "Vienna, Austria, July 21-27"
            },
            {
                "meeting name": "ICML 2025",
                "location": "Vancouver, BC, Canada"
            }
        ],
        "Press": {
            "Media Kit": {
                "ICML Logo": {
                    "svg(vector)": "https://icml.cc/media/Press/ICML-logo.svg",
                    "png(bitmap)": "https://icml.cc/media/Press/ICML-logo.png"
                },
                "Press Policy:": [
                    "You can apply for a press pass to ICML 2023 here. The deadline is July 10",
                    "Notification of acceptance or denial of the press pass will take place on a rolling basis.",
                    "Journalists receiving a press pass will receive an email and will be directed to register for the",
                    "conference. The review of applications ends on July 10, no passes will be granted after that",
                    "time. Information regarding how to obtain your virtual credentials will be sent to you via email",
                    "once the press pass is approved. Each member of your team attending the conference needs to",
                    "submit an application.",
                    "Journalists who are given accreditation will receive complimentary registration for the Main",
                    "Conference, as well as to Tutorials and Workshops where speakers/organizing groups have",
                    "decided to allow in the press. All accredited journalists will be given the same level of access to",
                    "the conference and its activities. Accredited journalists will also get access to certain additional",
                    "information. Given the virtual nature of the conference this year, additional resources, such as",
                    "facilitating requests for meetings with specific researchers, may be considered. Such requests",
                    "should be sent to press@icml.cc",
                    "Some information presented at ICML may be proprietary or off the record. Accredited journalists",
                    "attending the conference will be provided guidelines in advance of the conference. On the",
                    "record taping, if permitted, will be restricted to specific events and times, and only in agreement",
                    "with the recorded people. Interviews should be scheduled with the communications teams of the",
                    "interviewee and take place separately. If you want to write about a conversation with a",
                    "researcher, please ask for their consent first, and clearly identify yourself as a journalist.",
                    "Journalists will have access to most workshops. However, please keep in mind that workshops",
                    "are a forum for research work in progress. Workshop papers are only lightly reviewed, and the",
                    "presented work is typically not as complete as the main conference papers. Please keep this in",
                    "mind, add the above note to any reports that are based on workshop contents, and do not report",
                    "about workshop papers at the same level as main conference papers."
                ]
            }
        },
        "Diversity & Inclusion": {
            "introduction": [
                "The International Conference in Machine Learning aspires to foster an inclusive and welcoming community that recognizes and respects the inherent worth of every person. We take several steps to improve diversity, equity, and inclusion across several facets of conference participation.",
                "We work with grassroots organizations like Women in Machine Learning, Black in AI, Queer in AI, LatinX in AI, and Indigenous in AI to increase participation of underrepresented groups at the conference and to make the conference welcoming to everyone, regardless of their gender identity and expression, sexual orientation, race, disability, neurodivergence, religion, nationality, etc.",
                "In collaboration with affinity groups we organize affinity events including workshops, mentoring sessions, and socials. We are actively working to make the conference event itself more inclusive, for example, by promoting gender inclusive measures and supporting childcare, nursing mothers, and attendees with disabilities. We are also exploring options with the venue and caterers to ensure that everyone can have a positive, equitable experience while attending our conference.",
                "Finally, we work on implementing structural changes, such as the introduction of the Code of Conduct in 2018.",
                "If you have any questions, comments, or concerns, please reach out to diversity-chairs@icml.cc. "
            ],
            "Women in Machine Learning(url)": "wimlworkshop.org",
            "Black in AI(url)": "https://blackinai.github.io/",
            "Latinx in AI(url)": "www.latinxinai.org",
            "Queer in AI(url)": "queerinai.org",
            "{Dis}Ability in AI(url)": "https://elesa.github.io/ability_in_AI/"
        }
    }
}